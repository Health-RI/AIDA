@online{2023ai,
  title = {{{AI}} in Medical Care: {{A}} Map for Clinical Practice and Patient Protection},
  shorttitle = {{{AI}} in Medical Care},
  date = {2023-06-08},
  url = {https://www.medicaleconomics.com/view/ai-in-medical-care-a-map-for-clinical-practice-and-patient-protection},
  urldate = {2025-01-20},
  abstract = {Artificial intelligence (AI) has seen an exponential increase in the already rising interest within the medical field since the introduction of ChatGPT in November 2022.},
  langid = {english},
  organization = {MedicalEconomics},
  file = {/Users/dkapitan/Zotero/storage/PD3KR9RU/ai-in-medical-care-a-map-for-clinical-practice-and-patient-protection.html}
}

@online{2024ai,
  title = {The {{AI Factory}}: {{What It Is}} \& {{Its Key Components}} | {{HBS Online}}},
  shorttitle = {The {{AI Factory}}},
  date = {2024-09-12T12:00:00Z},
  url = {https://online.hbs.edu/blog/post/ai-factory},
  urldate = {2025-01-24},
  abstract = {In the digital age, you must understand the AI factory and how it can help you implement AI technologies into business operations.},
  langid = {english},
  organization = {Business Insights Blog},
  file = {/Users/dkapitan/Zotero/storage/XEYJ3WE6/ai-factory.html}
}

@online{2024european,
  title = {The {{European High Performance Computing Joint Undertaking}} | {{Shaping Europe}}’s Digital Future},
  date = {2024-12-10},
  url = {https://digital-strategy.ec.europa.eu/en/policies/high-performance-computing-joint-undertaking},
  urldate = {2025-01-24},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/8L3WPBF5/high-performance-computing-joint-undertaking.html}
}

@online{2024homepage,
  title = {Homepage - {{EuroHPC JU}}},
  date = {2024-12-19},
  url = {https://eurohpc-ju.europa.eu/index_en},
  urldate = {2025-01-24},
  abstract = {The European High Performance Computing Joint Undertaking (EuroHPC JU) is a joint initiative between the EU, European countries and private partners to develop a World Class Supercomputing Ecosystem in Europe.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/UENNPC2T/index_en.html}
}

@report{2024kikv,
  title = {{{KIK-V}} x {{GERDA}}},
  date = {2024-04-16},
  institution = {Zorginstituut},
  url = {https://populationhealthdata.nl/wp-content/uploads/2024/07/Whitepaper-GERDA-x-KIK-V_-databeschikbaarheid-door-hergebruik.pdf},
  file = {/Users/dkapitan/Zotero/storage/UD59GDH5/Whitepaper-GERDA-x-KIK-V_-databeschikbaarheid-door-hergebruik.pdf}
}

@standard{2024openhie,
  title = {{{OpenHIE Framework}} v5.2-En},
  date = {2024-08-01},
  url = {https://ohie.org/},
  urldate = {2024-08-27},
  abstract = {OpenHIE is a community of individuals who strive to develop health information exchanges that improve patient care, health, and so much more.},
  langid = {american},
  file = {/Users/dkapitan/Zotero/storage/55NPDMZ3/ohie.org.html}
}

@online{2024reference,
  title = {Reference {{Architecture}} | {{Public}}},
  date = {2024-09-25},
  url = {https://bdi.gitbook.io/public},
  urldate = {2025-05-06},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/ADMWKNN9/public.html}
}

@software{2025mappingcommons,
  title = {Mapping-Commons/Semantic-Mapping-Vocabulary},
  date = {2025-07-01T18:32:22Z},
  origdate = {2022-04-14T08:42:55Z},
  url = {https://github.com/mapping-commons/semantic-mapping-vocabulary},
  urldate = {2025-07-02},
  abstract = {https://mapping-commons.github.io/semantic-mapping-vocabulary/},
  organization = {Mapping Commons}
}

@article{abouzaid2025building,
  title = {Building a Modern Data Platform Based on the Data Lakehouse Architecture and Cloud-Native Ecosystem},
  author = {AbouZaid, Ahmed and Barclay, Peter J. and Chrysoulas, Christos and Pitropakis, Nikolaos},
  date = {2025-02-22},
  journaltitle = {Discover Applied Sciences},
  shortjournal = {Discov Appl Sci},
  volume = {7},
  number = {3},
  pages = {166},
  issn = {3004-9261},
  doi = {10.1007/s42452-025-06545-w},
  url = {https://doi.org/10.1007/s42452-025-06545-w},
  urldate = {2025-03-16},
  abstract = {In today’s Big Data world, organisations can gain a competitive edge by adopting data-driven decision-making. However, a modern data platform that is portable, resilient, and efficient is required to manage organisations’ data and support their growth. Furthermore, the change in the data management architectures has been accompanied by changes in storage formats, particularly open standard formats like Apache Hudi, Apache Iceberg, and Delta Lake. With many alternatives, organisations are unclear on how to combine these into an effective platform. Our work investigates capabilities provided by Kubernetes and other Cloud-Native software, using DataOps methodologies to build a generic data platform that follows the Data Lakehouse architecture. We define the data platform specification, architecture, and core components to build a proof of concept system. Moreover, we provide a clear implementation methodology by developing the core of the proposed platform, which are infrastructure (Kubernetes), ingestion and transport (Argo Workflows), storage (MinIO), and finally, query and processing (Dremio). We then conducted performance benchmarks using an industry-standard benchmark suite to compare cold/warm start scenarios and assess Dremio’s caching capabilities, demonstrating a 12\% median enhancement of query duration with caching.},
  langid = {english},
  keywords = {Artificial Intelligence,Big Data,Cloud-Native,Data Lakehouse,DataOps,Kubernetes},
  file = {/Users/dkapitan/Zotero/storage/DMLA553M/AbouZaid et al. - 2025 - Building a modern data platform based on the data lakehouse architecture and cloud-native ecosystem.pdf}
}

@online{aia,
  title = {{{AI Factories}} | {{Shaping Europe}}’s Digital Future},
  url = {https://digital-strategy.ec.europa.eu/en/policies/ai-factories},
  urldate = {2025-01-24},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/ZP55BPVM/ai-factories.html}
}

@inproceedings{akhtar2024croissant,
  title = {Croissant: {{A Metadata Format}} for {{ML-Ready Datasets}}},
  shorttitle = {Croissant},
  booktitle = {Proceedings of the {{Eighth Workshop}} on {{Data Management}} for {{End-to-End Machine Learning}}},
  author = {Akhtar, Mubashara and Benjelloun, Omar and Conforti, Costanza and Gijsbers, Pieter and Giner-Miguelez, Joan and Jain, Nitisha and Kuchnik, Michael and Lhoest, Quentin and Marcenac, Pierre and Maskey, Manil and Mattson, Peter and Oala, Luis and Ruyssen, Pierre and Shinde, Rajat and Simperl, Elena and Thomas, Goeffry and Tykhonov, Slava and Vanschoren, Joaquin and Van Der Velde, Jos and Vogler, Steffen and Wu, Carole-Jean},
  date = {2024-06-09},
  pages = {1--6},
  publisher = {ACM},
  location = {Santiago AA Chile},
  doi = {10.1145/3650203.3663326},
  url = {https://dl.acm.org/doi/10.1145/3650203.3663326},
  urldate = {2025-02-14},
  abstract = {Data is a critical resource for Machine Learning (ML), yet working with data remains a key friction point. This paper introduces Croissant, a metadata format for datasets that simplifies how data is used by ML tools and frameworks. Croissant makes datasets more discoverable, portable and interoperable, thereby addressing significant challenges in ML data management and responsible AI. Croissant is already supported by several popular dataset repositories, spanning hundreds of thousands of datasets, ready to be loaded into the most popular ML frameworks.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '24: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {979-8-4007-0611-0},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/7265AEDQ/Akhtar et al. - 2024 - Croissant A Metadata Format for ML-Ready Datasets.pdf}
}

@article{ali2023systematic,
  title = {A Systematic Literature Review of Artificial Intelligence in the Healthcare Sector: {{Benefits}}, Challenges, Methodologies, and Functionalities},
  shorttitle = {A Systematic Literature Review of Artificial Intelligence in the Healthcare Sector},
  author = {Ali, Omar and Abdelbaki, Wiem and Shrestha, Anup and Elbasi, Ersin and Alryalat, Mohammad Abdallah Ali and Dwivedi, Yogesh K},
  date = {2023-01-01},
  journaltitle = {Journal of Innovation \& Knowledge},
  shortjournal = {Journal of Innovation \& Knowledge},
  volume = {8},
  number = {1},
  pages = {100333},
  issn = {2444-569X},
  doi = {10.1016/j.jik.2023.100333},
  url = {https://www.sciencedirect.com/science/article/pii/S2444569X2300029X},
  urldate = {2025-01-20},
  abstract = {Administrative and medical processes of the healthcare organizations are rapidly changing because of the use of artificial intelligence (AI) systems. This change demonstrates the critical impact of AI at multiple activities, particularly in medical processes related to early detection and diagnosis. Previous studies suggest that AI can raise the quality of services in the healthcare industry. AI-based technologies have reported to improve human life quality, making life easier, safer and more productive. This study presents a systematic review of academic articles on the application of AI in the healthcare sector. The review initially considered 1,988 academic articles from major scholarly databases. After a careful review, the list was filtered down to 180 articles for full analysis to present a classification framework based on four dimensions: AI-enabled healthcare benefits, challenges, methodologies, and functionalities. It was identified that AI continues to significantly outperform humans in terms of accuracy, efficiency and timely execution of medical and related administrative processes. Benefits for patients’ map directly to the relevant AI functionalities in the categories of diagnosis, treatment, consultation and health monitoring for self-management of chronic conditions. Implications for future research directions are identified in the areas of value-added healthcare services for medical decision-making, security and privacy for patient data, health monitoring features, and creative IT service delivery models using AI.},
  keywords = {Artificial intelligence,Healthcare,Systematic literature review Technology benefits,Technology challenges},
  file = {/Users/dkapitan/Zotero/storage/K7HWLDES/Ali et al. - 2023 - A systematic literature review of artificial intelligence in the healthcare sector Benefits, challe.pdf;/Users/dkapitan/Zotero/storage/Y8IHINYK/S2444569X2300029X.html}
}

@article{antunesanalysis,
  title = {Analysis of {{Federated Enterprise Architecture Models}}},
  author = {Antunes, Goncalo and Barateiro, Jose and Caetano, Artur and Borbinha, Jose},
  abstract = {Enterprise architecture models support decision-making as they help organizations to understand, communicate and analyse how business processes are performed, the goals they achieve, the information they use, as well as the applications that realize the business, and the supporting technological infrastructure. The integrated analysis of these models is not straightforward because it cross-cuts different domains that are described using heterogeneous concepts. This paper explores the application of ontologies to analyse enterprise architecture models. Ontologies represent knowledge that can be analysed using computational inference. The contributions of this paper are (1) the specification of multiple enterprise architecture models as ontological schemas, (2) the integration of ontological schemas, and (3) the analysis of the integrated models. The solution artefact consists of a federated model specified as a set of ontological schemas described in OWL-DL that integrates multiple enterprise models and assists their analysis using computational inference. The paper demonstrates the application of the federated model to the ArchiMate language as a means to assess the compliance of business requirements in a civil engineering scenario.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/DD27IF3K/Antunes et al. - Analysis of Federated Enterprise Architecture Models.pdf}
}

@article{artificial,
  title = {Artificial {{Intelligence}} in {{Health}}},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/N8VMKG7K/Artificial Intelligence in Health.pdf}
}

@article{avraam2025datashield,
  title = {{{DataSHIELD}}: Mitigating Disclosure Risk in a Multi-Site Federated Analysis Platform},
  shorttitle = {{{DataSHIELD}}},
  author = {Avraam, Demetris and Wilson, Rebecca C and Aguirre Chan, Noemi and Banerjee, Soumya and Bishop, Tom R P and Butters, Olly and Cadman, Tim and Cederkvist, Luise and Duijts, Liesbeth and Escribà Montagut, Xavier and Garner, Hugh and Gonçalves, Gonçalo and González, Juan R and Haakma, Sido and Hartlev, Mette and Hasenauer, Jan and Huth, Manuel and Hyde, Eleanor and Jaddoe, Vincent W V and Marcon, Yannick and Mayrhofer, Michaela Th and Molnar-Gabor, Fruzsina and Morgan, Andrei Scott and Murtagh, Madeleine and Nestor, Marc and Nybo Andersen, Anne-Marie and Parker, Simon and Pinot de Moira, Angela and Schwarz, Florian and Strandberg-Larsen, Katrine and Swertz, Morris A and Welten, Marieke and Wheater, Stuart and Burton, Paul},
  date = {2025-01-01},
  journaltitle = {Bioinformatics Advances},
  shortjournal = {Bioinformatics Advances},
  volume = {5},
  number = {1},
  pages = {vbaf046},
  issn = {2635-0041},
  doi = {10.1093/bioadv/vbaf046},
  url = {https://doi.org/10.1093/bioadv/vbaf046},
  urldate = {2025-06-11},
  abstract = {The validity of epidemiologic findings can be increased using triangulation, i.e. comparison of findings across contexts, and by having sufficiently large amounts of relevant data to analyse. However, access to data is often constrained by practical considerations and by ethico-legal and data governance restrictions. Gaining access to such data can be time-consuming due to the governance requirements associated with data access requests to institutions in different jurisdictions.DataSHIELD is a software solution that enables remote analysis without the need for data transfer (federated analysis). DataSHIELD is a scientifically mature, open-source data access and analysis platform aligned with the ‘Five Safes’ framework, the international framework governing safe research access to data. It allows real-time analysis while mitigating disclosure risk through an active multi-layer system of disclosure-preventing mechanisms. This combination of real-time remote statistical analysis, disclosure prevention mechanisms, and federation capabilities makes DataSHIELD a solution for addressing many of the technical and regulatory challenges in performing the large-scale statistical analysis of health and biomedical data. This paper describes the key components that comprise the disclosure protection system of DataSHIELD. These broadly fall into three classes: (i) system protection elements, (ii) analysis protection elements, and (iii) governance protection elements.Information about the DataSHIELD software is available in https://datashield.org/ and https://github.com/datashield.},
  file = {/Users/dkapitan/Zotero/storage/JI3FX63E/Avraam et al. - 2025 - DataSHIELD mitigating disclosure risk in a multi-site federated analysis platform.pdf;/Users/dkapitan/Zotero/storage/Y88VAUQG/8068803.html}
}

@incollection{bader2020international,
  title = {The {{International Data Spaces Information Model}} – {{An Ontology}} for {{Sovereign Exchange}} of {{Digital Content}}},
  booktitle = {The {{Semantic Web}} – {{ISWC}} 2020},
  author = {Bader, Sebastian and Pullmann, Jaroslav and Mader, Christian and Tramp, Sebastian and Quix, Christoph and Müller, Andreas W. and Akyürek, Haydar and Böckmann, Matthias and Imbusch, Benedikt T. and Lipp, Johannes and Geisler, Sandra and Lange, Christoph},
  editor = {Pan, Jeff Z. and Tamma, Valentina and family=Amato, given=Claudia, prefix=d’, useprefix=true and Janowicz, Krzysztof and Fu, Bo and Polleres, Axel and Seneviratne, Oshani and Kagal, Lalana},
  date = {2020},
  volume = {12507},
  pages = {176--192},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-62466-8_12},
  url = {https://link.springer.com/10.1007/978-3-030-62466-8_12},
  urldate = {2025-06-12},
  abstract = {The International Data Spaces initiative (IDS) is building an ecosystem to facilitate data exchange in a secure, trusted, and semantically interoperable way. It aims at providing a basis for smart services and cross-company business processes, while at the same time guaranteeing data owners’ sovereignty over their content. The IDS Information Model is an RDFS/OWL ontology defining the fundamental concepts for describing actors in a data space, their interactions, the resources exchanged by them, and data usage restrictions. After introducing the conceptual model and design of the ontology, we explain its implementation on top of standard ontologies as well as the process for its continuous evolution and quality assurance involving a community driven by industry and research organisations. We demonstrate tools that support generation, validation, and usage of instances of the ontology with the focus on data control and protection in a federated ecosystem.},
  isbn = {978-3-030-62465-1 978-3-030-62466-8},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/3SPYNRRS/Bader et al. - 2020 - The International Data Spaces Information Model – An Ontology for Sovereign Exchange of Digital Cont.pdf}
}

@incollection{bader2020internationala,
  title = {The {{International Data Spaces Information Model}} – {{An Ontology}} for {{Sovereign Exchange}} of {{Digital Content}}},
  booktitle = {The {{Semantic Web}} – {{ISWC}} 2020},
  author = {Bader, Sebastian and Pullmann, Jaroslav and Mader, Christian and Tramp, Sebastian and Quix, Christoph and Müller, Andreas W. and Akyürek, Haydar and Böckmann, Matthias and Imbusch, Benedikt T. and Lipp, Johannes and Geisler, Sandra and Lange, Christoph},
  editor = {Pan, Jeff Z. and Tamma, Valentina and family=Amato, given=Claudia, prefix=d’, useprefix=true and Janowicz, Krzysztof and Fu, Bo and Polleres, Axel and Seneviratne, Oshani and Kagal, Lalana},
  date = {2020},
  volume = {12507},
  pages = {176--192},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-62466-8_12},
  url = {https://link.springer.com/10.1007/978-3-030-62466-8_12},
  urldate = {2025-06-26},
  abstract = {The International Data Spaces initiative (IDS) is building an ecosystem to facilitate data exchange in a secure, trusted, and semantically interoperable way. It aims at providing a basis for smart services and cross-company business processes, while at the same time guaranteeing data owners’ sovereignty over their content. The IDS Information Model is an RDFS/OWL ontology defining the fundamental concepts for describing actors in a data space, their interactions, the resources exchanged by them, and data usage restrictions. After introducing the conceptual model and design of the ontology, we explain its implementation on top of standard ontologies as well as the process for its continuous evolution and quality assurance involving a community driven by industry and research organisations. We demonstrate tools that support generation, validation, and usage of instances of the ontology with the focus on data control and protection in a federated ecosystem.},
  isbn = {978-3-030-62465-1 978-3-030-62466-8},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/VCISXZ4K/Bader et al. - 2020 - The International Data Spaces Information Model – An Ontology for Sovereign Exchange of Digital Cont.pdf}
}

@article{bak2025ethical,
  title = {Ethical {{Design}} of {{Data-Driven Decision Support Tools}} for {{Improving Cancer Care}}: {{Embedded Ethics Review}} of the {{4D PICTURE Project}}},
  shorttitle = {Ethical {{Design}} of {{Data-Driven Decision Support Tools}} for {{Improving Cancer Care}}},
  author = {Bak, Marieke and Hartman, Laura and Graafland, Charlotte and Korfage, Ida J. and Buyx, Alena and Schermer, Maartje and Consortium, 4d Picture},
  date = {2025-04-10},
  journaltitle = {JMIR Cancer},
  volume = {11},
  number = {1},
  pages = {e65566},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/65566},
  url = {https://cancer.jmir.org/2025/1/e65566},
  urldate = {2025-04-15},
  abstract = {Oncology patients often face complex choices between treatment regimens with different risk-benefit ratios. The 4D PICTURE (Producing Improved Cancer Outcomes Through User-Centered Research) project aims to support patients, their families, and clinicians with these complex decisions by developing data-driven decision support tools (DSTs) for patients with breast cancer, prostate cancer, and melanoma as part of care path redesign using a methodology called MetroMapping. There are myriad ethical issues to consider as the project will create data-driven prognostic models and develop conversation tools using artificial intelligence while including patient perspectives by setting up boards of experiential experts in 8 different countries. This paper aims to review the key ethical challenges related to the design and development of DSTs in oncology. To explore the ethics of DSTs in cancer care, the project adopted the Embedded Ethics approach—embedding ethicists into research teams to sensitize team members to ethical aspects and assist in reflecting on those aspects throughout the project. We conducted what we call an embedded review of the project drawing from key literature on topics related to the different work packages of the 4D PICTURE project, whereas the analysis was an iterative process involving discussions with researchers in the project. Our review identified 13 key ethical challenges related to the development of DSTs and the redesigning of care paths for more personalized cancer care. Several ethical aspects were related to general potential issues of data bias and privacy but prompted specific research questions, for instance, about the inclusion of certain demographic variables in models. Design methodology in the 4D PICTURE project can provide insights related to design justice, a novel consideration in health care DSTs. Ethical points of attention related to health care policy, such as cost-effectiveness, financial sustainability, and environmental impact, were also identified, along with challenges in the research process itself, emphasizing the importance of epistemic justice, the role of embedded ethicists, and psychological safety. This viewpoint highlights ethical aspects previously neglected in the digital health ethics literature and zooms in on real-world challenges in an ongoing project. It underscores the need for researchers and leaders in data-driven medical research projects to address ethical challenges beyond the scientific core of the project. More generally, our tailored review approach provides a model for embedding ethics into large data-driven oncology research projects from the start, which helps ensure that technological innovations are designed and developed in an appropriate and patient-centered manner.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/XM367NS8/e65566.html}
}

@article{baker2023story,
  title = {The {{Story Behind}} the {{HL7 FHIR}} to {{CDISC Mapping Implementation Guide}}},
  author = {Baker, Rebecca L. and Hamidi, Mike and McKenzie, Lloyd and Denney, Christine K. and Edgar, Theresia D.},
  date = {2023-08-09},
  journaltitle = {Journal of the Society for Clinical Data Management},
  volume = {4},
  number = {1},
  publisher = {Society for Clinical Data Management},
  issn = {2694-1473},
  doi = {10.47912/jscdm.162},
  url = {https://www.jscdm.org/article/id/162/},
  urldate = {2025-05-06},
  abstract = {BackgroundHealth data has become an abundant and rich source of information that can be leveraged for clinical trials. Health Level Seven (HL7) provides standards for health care data, while the Clinical Data Interchange Standards Consortium (CDISC) provides standards for research data. Bridging these worlds and leveraging health data has the potential to enhance knowledge and data quality, while reducing delays and cost in clinical trials.Objectives The aim was to provide an overview of the HL7 Fast Healthcare Interoperability Resources (FHIR®) to CDISC Joint Mapping Implementation Guide (IG) development. The ultimate aim is to increase awareness of this rich resource.MethodsA gap analysis was performed to assess the possibility and feasibility of mapping from FHIR to the CDISC’s Study Data Tabulation Model (SDTM) and Clinical Data Acquisition Standards Harmonization (CDASH) standards. The mapping of CDISC domains commenced using FHIRPath, a path-based navigation and extraction language. The domains mapped were Medical History (MH), Concomitant Medications (CM), Procedures (PR), Vital Signs (VS), Laboratory (LB), Adverse Events (AE), and Demographics (DM). The proposed mappings were evaluated through a formal review process.ResultsThe review process consisted of a CDISC Internal Review and a simultaneous CDISC Public Review and HL7 Ballot Review.\&nbsp; A total of 363 comments were obtained from the following reviews: 1) CDISC Internal Review (268), and 2) simultaneous Public Review (95) - CDISC (37), HL7 (58). The predominant gathered in the review included mapping updates, terminology, and requests for greater detail.ConclusionThe HL7 FHIR®\&nbsp;to CDISC Joint Mapping Implementation Guide (IG) provides a rich resource for bridging health care and research standards that can be used with CDISC LB to LOINC mapping guide for leveraging real-world data for clinical trials. The guide assists stakeholders in utilizing health data through the HL7 FHIR® resources to CDISC, CDASH, and SDTM variables. As the community uses this resource, it will continue to mature and potentially expand into new domains.},
  issue = {1},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/9RKTDFET/Baker et al. - 2023 - The Story Behind the HL7 FHIR to CDISC Mapping Implementation Guide.pdf}
}

@article{beck2019hourglass,
  title = {On the Hourglass Model},
  author = {Beck, Micah},
  date = {2019-06},
  journaltitle = {Communications of the ACM},
  volume = {62},
  number = {7},
  pages = {48--57},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3274770},
  abstract = {Used in the design of the Internet and Unix, the layered services of the hourglass model have enabled viral adoption and deployment scalability.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/NKGQZL5V/Beck - 2019 - On the hourglass model.pdf}
}

@article{bernabe2023use,
  title = {The Use of Foundational Ontologies in Biomedical Research},
  author = {Bernabé, César H. and Queralt-Rosinach, Núria and Silva Souza, Vítor E. and Bonino Da Silva Santos, Luiz Olavo and Mons, Barend and Jacobsen, Annika and Roos, Marco},
  date = {2023-12-11},
  journaltitle = {Journal of Biomedical Semantics},
  shortjournal = {J Biomed Semant},
  volume = {14},
  number = {1},
  pages = {21},
  issn = {2041-1480},
  doi = {10.1186/s13326-023-00300-z},
  url = {https://jbiomedsem.biomedcentral.com/articles/10.1186/s13326-023-00300-z},
  urldate = {2025-04-07},
  abstract = {Abstract                            Background               The FAIR principles recommend the use of controlled vocabularies, such as ontologies, to define data and metadata concepts. Ontologies are currently modelled following different approaches, sometimes describing conflicting definitions of the same concepts, which can affect interoperability. To cope with that, prior literature suggests organising ontologies in levels, where domain specific (low-level) ontologies are grounded in domain independent high-level ontologies (i.e., foundational ontologies). In this level-based organisation, foundational ontologies work as translators of intended meaning, thus improving interoperability. Despite their considerable acceptance in biomedical research, there are very few studies testing foundational ontologies. This paper describes a systematic literature mapping that was conducted to understand how foundational ontologies are used in biomedical research and to find empirical evidence supporting their claimed (dis)advantages.                                         Results               From a set of 79 selected papers, we identified that foundational ontologies are used for several purposes: ontology construction, repair, mapping, and ontology-based data analysis. Foundational ontologies are claimed to improve interoperability, enhance reasoning, speed up ontology development and facilitate maintainability. The complexity of using foundational ontologies is the most commonly cited downside. Despite being used for several purposes, there were hardly any experiments (1 paper) testing the claims for or against the use of foundational ontologies. In the subset of 49 papers that describe the development of an ontology, it was observed a low adherence to ontology construction (16 papers) and ontology evaluation formal methods (4 papers).                                         Conclusion               Our findings have two main implications. First, the lack of empirical evidence about the use of foundational ontologies indicates a need for evaluating the use of such artefacts in biomedical research. Second, the low adherence to formal methods illustrates how the field could benefit from a more systematic approach when dealing with the development and evaluation of ontologies. The understanding of how foundational ontologies are used in the biomedical field can drive future research towards the improvement of ontologies and, consequently, data FAIRness. The adoption of formal methods can impact the quality and sustainability of ontologies, and reusing these methods from other fields is encouraged.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/I59ANSP3/Bernabé et al. - 2023 - The use of foundational ontologies in biomedical research.pdf}
}

@article{bernabe2024building,
  title = {Building {{Expertise}} on {{FAIR Through Evolving Bring Your Own Data}} ({{BYOD}}) {{Workshops}}: {{Describing}} the {{Data}}, {{Software}}, and {{Management-focused Approaches}} and {{Their Evolution}}},
  shorttitle = {Building {{Expertise}} on {{FAIR Through Evolving Bring Your Own Data}} ({{BYOD}}) {{Workshops}}},
  author = {Bernabé, César H. and Thielemans, Lieze and Kaliyaperumal, Rajaram and Carta, Claudio and Zhang, Shuxin and family=Gelder, given=Celia W.G., prefix=van, useprefix=true and Benis, Nirupama and family=Silva Santos, given=Luiz Olavo Bonino, prefix=da, useprefix=true and Cornet, Ronald and family=Santos Vieira, given=Bruna, prefix=dos, useprefix=true and Lalout, Nawel and Henriques, Ines and Ballesteros, Alberto Cámara and Burger, Kees and Kersloot, Martijn G. and Ehrhart, Friederike and family=Enckevort, given=Esther, prefix=van, useprefix=true and Evelo, Chris T. and Gray, Alasdair J. G. and Hanauer, Marc and Hettne, Kristina and family=Ligt, given=Joep, prefix=de, useprefix=true and Pereira, Arnaldo and Queralt-Rosinach, Núria and Schultes, Erik and Taruscio, Domenica and Waagmeester, Andra and Wilkinson, Mark D. and Willighagen, Egon L. and Jansen, Mascha and Mons, Barend and Roos, Marco and Jacobsen, Annika},
  date = {2024-05-01},
  journaltitle = {Data Intelligence},
  shortjournal = {Data Intelligence},
  volume = {6},
  number = {2},
  pages = {429--456},
  issn = {2641-435X},
  doi = {10.1162/dint_a_00236},
  url = {https://doi.org/10.1162/dint_a_00236},
  urldate = {2025-03-31},
  abstract = {Since 2014, “Bring Your Own Data” workshops (BYODs) have been organised to inform people about the process and benefits of making resources Findable, Accessible, Interoperable, and Reusable (FAIR, and the FAIRification process). The BYOD workshops’ content and format differ depending on their goal, context, and the background and needs of participants. Data-focused BYODs educate domain experts on how to make their data FAIR to find new answers to research questions. Management-focused BYODs promote the benefits of making data FAIR and instruct project managers and policy-makers on the characteristics of FAIRification projects. Software-focused BYODs gather software developers and experts on FAIR to implement or improve software resources that are used to support FAIRification. Overall, these BYODs intend to foster collaboration between different types of stakeholders involved in data management, curation, and reuse (e.g. domain experts, trainers, developers, data owners, data analysts, FAIR experts). The BYODs also serve as an opportunity to learn what kind of support for FAIRification is needed from different communities and to develop teaching materials based on practical examples and experience. In this paper, we detail the three different structures of the BYODs and describe examples of early BYODs related to plant breeding data, and rare disease registries and biobanks, which have shaped the structure of the workshops. We discuss the latest insights into making BYODs more productive by leveraging our almost ten years of training experience in these workshops, including successes and encountered challenges. Finally, we examine how the participants’ feedback has motivated the research on FAIR, including the development of workflows and software.},
  file = {/Users/dkapitan/Zotero/storage/WR6W5VJL/Bernabé et al. - 2024 - Building Expertise on FAIR Through Evolving Bring Your Own Data (BYOD) Workshops Describing the Dat.pdf;/Users/dkapitan/Zotero/storage/UCP6IQ4L/Building-Expertise-on-FAIR-Through-Evolving-Bring.html}
}

@article{beyan2020distributed,
  title = {Distributed {{Analytics}} on {{Sensitive Medical Data}}: {{The Personal Health Train}}},
  shorttitle = {Distributed {{Analytics}} on {{Sensitive Medical Data}}},
  author = {Beyan, Oya and Choudhury, Ananya and family=Soest, given=Johan, prefix=van, useprefix=true and Kohlbacher, Oliver and Zimmermann, Lukas and Stenzhorn, Holger and Karim, Md. Rezaul and Dumontier, Michel and Decker, Stefan and family=Silva Santos, given=Luiz Olavo Bonino, prefix=da, useprefix=true and Dekker, Andre},
  date = {2020-01-01},
  journaltitle = {Data Intelligence},
  shortjournal = {Data Intelligence},
  volume = {2},
  number = {1--2},
  pages = {96--107},
  issn = {2641-435X},
  doi = {10.1162/dint_a_00032},
  url = {https://doi.org/10.1162/dint_a_00032},
  urldate = {2023-02-16},
  abstract = {In recent years, as newer technologies have evolved around the healthcare ecosystem, more and more data have been generated. Advanced analytics could power the data collected from numerous sources, both from healthcare institutions, or generated by individuals themselves via apps and devices, and lead to innovations in treatment and diagnosis of diseases; improve the care given to the patient; and empower citizens to participate in the decision-making process regarding their own health and well-being. However, the sensitive nature of the health data prohibits healthcare organizations from sharing the data. The Personal Health Train (PHT) is a novel approach, aiming to establish a distributed data analytics infrastructure enabling the (re)use of distributed healthcare data, while data owners stay in control of their own data. The main principle of the PHT is that data remain in their original location, and analytical tasks visit data sources and execute the tasks. The PHT provides a distributed, flexible approach to use data in a network of participants, incorporating the FAIR principles. It facilitates the responsible use of sensitive and/or personal data by adopting international principles and regulations. This paper presents the concepts and main components of the PHT and demonstrates how it complies with FAIR principles.},
  file = {/Users/dkapitan/Zotero/storage/SGX995AZ/Beyan et al. - 2020 - Distributed Analytics on Sensitive Medical Data T.pdf}
}

@article{bhanbhro2024issues,
  title = {Issues in Federated Learning: Some Experiments and Preliminary Results},
  shorttitle = {Issues in Federated Learning},
  author = {Bhanbhro, Jamsher and Nisticò, Simona and Palopoli, Luigi},
  date = {2024-12-02},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {14},
  number = {1},
  pages = {29881},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-024-81732-0},
  url = {https://www.nature.com/articles/s41598-024-81732-0},
  urldate = {2025-06-30},
  abstract = {The growing need for data privacy and security in machine learning has led to exploring novel approaches like federated learning (FL) that allow collaborative training on distributed datasets, offering a decentralized alternative to traditional data collection methods. A prime benefit of FL is its emphasis on privacy, enabling data to stay on local devices by moving models instead of data. Despite its pioneering nature, FL faces issues such as diversity in data types, model complexity, privacy concerns, and the need for efficient resource distribution. This paper illustrates an empirical analysis of these challenges within specially designed scenarios, each aimed at studying a specific problem. In particular, differently from existing literature, we isolate the issues that can arise in an FL framework to observe their nature without the interference of external factors.},
  langid = {english},
  keywords = {Engineering,Mathematics and computing},
  file = {/Users/dkapitan/Zotero/storage/KP9MAB5G/Bhanbhro et al. - 2024 - Issues in federated learning some experiments and preliminary results.pdf}
}

@article{biedermann2021standardizing,
  title = {Standardizing Registry Data to the {{OMOP Common Data Model}}: Experience from Three Pulmonary Hypertension Databases},
  shorttitle = {Standardizing Registry Data to the {{OMOP Common Data Model}}},
  author = {Biedermann, Patricia and Ong, Rose and Davydov, Alexander and Orlova, Alexandra and Solovyev, Philip and Sun, Hong and Wetherill, Graham and Brand, Monika and Didden, Eva-Maria},
  date = {2021-11-02},
  journaltitle = {BMC Medical Research Methodology},
  shortjournal = {BMC Medical Research Methodology},
  volume = {21},
  number = {1},
  pages = {238},
  issn = {1471-2288},
  doi = {10.1186/s12874-021-01434-3},
  url = {https://doi.org/10.1186/s12874-021-01434-3},
  urldate = {2025-07-02},
  abstract = {The Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) can be used to transform observational health data to a common format. CDM transformation allows for analysis across disparate databases for the generation of new, real-word evidence, which is especially important in rare disease where data are limited. Pulmonary hypertension (PH) is a progressive, life-threatening disease, with rare subgroups such as pulmonary arterial hypertension (PAH), for which generating real-world evidence is challenging. Our objective is to document the process and outcomes of transforming registry data in PH to the OMOP CDM, and highlight challenges and our potential solutions.},
  keywords = {Common data model,Data mapping,Observational data,Pulmonary hypertension,Registry},
  file = {/Users/dkapitan/Zotero/storage/LM2QW6PZ/Biedermann et al. - 2021 - Standardizing registry data to the OMOP Common Data Model experience from three pulmonary hypertens.pdf;/Users/dkapitan/Zotero/storage/VTT8UXEW/s12874-021-01434-3.html}
}

@misc{boninodasilvasantos2022fair,
  title = {{{FAIR Digital Object Framework}}},
  author = {Bonino da Silva Santos, Luiz Olavo and Guizzardi, Giancarlo and Prince Sales, Tiago},
  date = {2022-10-27},
  url = {https://fairdigitalobjectframework.org/},
  urldate = {2025-06-19}
}

@article{boninodasilvasantos2022personal,
  title = {Personal {{Health Train Architecture}} with {{Dynamic Cloud Staging}}},
  author = {Bonino da Silva Santos, Luiz Olavo and Ferreira Pires, Luis and Martinez, Virginia and Moreira, João and Guizzardi, Renata},
  date = {2022-10-17},
  journaltitle = {SN Computer Science},
  shortjournal = {SN Computer Science},
  volume = {4},
  doi = {10.1007/s42979-022-01422-4},
  abstract = {Scientific advances, especially in the healthcare domain, can be accelerated by making data available for analysis. However, in traditional data analysis systems, data need to be moved to a central processing unit that performs analyses, which may be undesirable, e.g. due to privacy regulations in case these data contain personal information. This paper discusses the Personal Health Train (PHT) approach in which data processing is brought to the (personal health) data rather than the other way around, allowing (private) data accessed to be controlled, and to observe ethical and legal concerns. This paper introduces the PHT architecture and discusses the data staging solution that allows processing to be delegated to components spawned in a private cloud environment in case the (health) organisation hosting the data has limited resources to execute the required processing. This paper shows the feasibility and suitability of the solution with a relatively simple, yet representative, case study of data analysis of Covid-19 infections, which is performed by components that are created on demand and run in the Amazon Web Services platform. This paper also shows that the performance of our solution is acceptable, and that our solution is scalable. This paper demonstrates that the PHT approach enables data analysis with controlled access, preserving privacy and complying with regulations such as GDPR, while the solution is deployed in a private cloud environment.},
  file = {/Users/dkapitan/Zotero/storage/VSEU4UGA/Bonino da Silva Santos et al. - 2022 - Personal Health Train Architecture with Dynamic Cloud Staging.pdf}
}

@article{boylesecond,
  title = {{{THE SECOND ENCLOSURE MOVEMENT AND THE CONSTRUCTION OF THE PUBLIC DOMAIN}}},
  author = {Boyle, James},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/3EY7YA9R/Boyle - THE SECOND ENCLOSURE MOVEMENT AND THE CONSTRUCTION OF THE PUBLIC DOMAIN.pdf}
}

@article{brancato2024standardizing,
  title = {Standardizing Digital Biobanks: Integrating Imaging, Genomic, and Clinical Data for Precision Medicine},
  shorttitle = {Standardizing Digital Biobanks},
  author = {Brancato, Valentina and Esposito, Giuseppina and Coppola, Luigi and Cavaliere, Carlo and Mirabelli, Peppino and Scapicchio, Camilla and Borgheresi, Rita and Neri, Emanuele and Salvatore, Marco and Aiello, Marco},
  date = {2024-02-05},
  journaltitle = {Journal of Translational Medicine},
  shortjournal = {Journal of Translational Medicine},
  volume = {22},
  number = {1},
  pages = {136},
  issn = {1479-5876},
  doi = {10.1186/s12967-024-04891-8},
  url = {https://doi.org/10.1186/s12967-024-04891-8},
  urldate = {2025-04-04},
  abstract = {Advancements in data acquisition and computational methods are generating a large amount of heterogeneous biomedical data from diagnostic domains such as clinical imaging, pathology, and next-generation sequencing (NGS), which help characterize individual differences in patients. However, this information needs to be available and suitable to promote and support scientific research and technological development, supporting the effective adoption of the precision medicine approach in clinical practice.~Digital biobanks can catalyze this process, facilitating the sharing of curated and standardized imaging data, clinical, pathological and molecular data, crucial to enable the development of a comprehensive and personalized data-driven diagnostic approach in disease management and fostering the development of computational predictive models.~This work aims to frame this perspective, first by evaluating the state of standardization of individual diagnostic domains and then by identifying challenges and proposing a possible solution towards an integrative approach that can guarantee the suitability of information that can be shared through a digital biobank.~Our analysis of the state of the art shows the presence and use of reference standards in biobanks and, generally, digital repositories for each specific domain. Despite this, standardization to guarantee the integration and reproducibility of the numerical descriptors generated by each domain, e.g. radiomic, pathomic and -omic features, is still an open challenge. Based on specific use cases and scenarios, an integration model, based on the JSON format, is proposed that can help address this problem.~Ultimately, this work shows how, with specific standardization and promotion efforts, the digital biobank model can become an enabling technology for the comprehensive study of diseases and the effective development of data-driven technologies at the service of precision medicine.},
  keywords = {Big data,Biobanking,Clinical decision support systems (CDSS),Data integration,Imaging,NGS,Pathomics,Precision medicine,Radiomics,Standardization},
  file = {/Users/dkapitan/Zotero/storage/Y6DH8J4M/Brancato et al. - 2024 - Standardizing digital biobanks integrating imaging, genomic, and clinical data for precision medici.pdf;/Users/dkapitan/Zotero/storage/L2CQUC7J/s12967-024-04891-8.html}
}

@article{braun2025how,
  title = {How Predictive Medicine Leads to Solidarity Gaps in Health},
  author = {Braun, Matthias},
  date = {2025-02-18},
  journaltitle = {npj Digital Medicine},
  shortjournal = {npj Digit. Med.},
  volume = {8},
  number = {1},
  pages = {1--3},
  publisher = {Nature Publishing Group},
  issn = {2398-6352},
  doi = {10.1038/s41746-025-01497-2},
  url = {https://www.nature.com/articles/s41746-025-01497-2},
  urldate = {2025-02-20},
  abstract = {The current shift in healthcare towards AI-driven P4 medicine challenges practices of solidarity, with implications for EU health policy.},
  langid = {english},
  keywords = {Ethics,Society},
  file = {/Users/dkapitan/Zotero/storage/6EYGUDFY/Braun - 2025 - How predictive medicine leads to solidarity gaps in health.pdf}
}

@article{brohet2025using,
  title = {Using {{Real-World Data}} for {{Machine-Learning Algorithms}} to {{Predict}} the {{Treatment Response}} in {{Advanced Melanoma}}: {{A Pilot Study}} for {{Personalizing Cancer Care}}},
  shorttitle = {Using {{Real-World Data}} for {{Machine-Learning Algorithms}} to {{Predict}} the {{Treatment Response}} in {{Advanced Melanoma}}},
  author = {Brohet, Richard M. and family=Boer, given=Elianne C.S., prefix=de, useprefix=true and Mossink, Joram M. and family=Eerden, given=Joni J.N., prefix=van der, useprefix=true and Oostmeyer, Alexander and Idzerda, Luuk H.W. and Maring, Jan Gerard and Paardekooper, Gabriel M.R.M. and Beld, Michel and Lijffijt, Fiona and Dille, Joep and family=Groot, given=Jan Willem B., prefix=de, useprefix=true},
  date = {2025-04},
  journaltitle = {JCO Clinical Cancer Informatics},
  shortjournal = {JCO Clin Cancer Inform},
  number = {9},
  pages = {e2400181},
  publisher = {Wolters Kluwer},
  doi = {10.1200/CCI-24-00181},
  url = {https://ascopubs.org/doi/10.1200/CCI-24-00181},
  urldate = {2025-06-30},
  abstract = {PurposeThe use of real-world data (RWD) in oncology is becoming increasingly important for clinical decision making and tailoring treatment. Despite the significant success of targeted therapy and immunotherapy in advanced melanoma, substantial variability in clinical responses to these treatments emphasizes the need for personalized approaches to therapy.Materials and MethodsIn this pilot study, 239 patients with melanoma were included to predict the response to both targeted therapies and immunotherapies. We used machine learning (ML) to incorporate RWD and applied explainable artificial intelligence (XAI) to explain the individual predictions.ResultsWe developed, validated, and compared four ML models to evaluate 2-year survival using RWD. Our research showed encouraging outcomes, achieving an AUC of more than 80\% and an estimated accuracy of over 74\% across the four ML models. The random forest model exhibited the highest performance in predicting 2-year survival with an AUC of 0.85. Local interpretable model-agnostic explanations was used to explain individual predictions and provide trust and insights into the clinical implications of the ML model.ConclusionWith this proof-of-concept, we integrated RWD into predictive modeling using ML techniques to predict clinical outcomes and explore their potential implications for clinical decision making. The potential of XAI was demonstrated to enhance trust and improve the usability of the model in clinical settings. Further research, including foundation modeling and generative AI, will likely increase the predictive power of prognostic and predictive ML models in advanced melanoma.}
}

@book{buschmann1996system,
  title = {A {{System}} of {{Patterns}}},
  author = {Buschmann, Frank and Meunier, Regine and Rohnert, Hans and Sommerlad, Peter and Stal, Michael},
  date = {1996},
  series = {Pattern-{{Oriented Software Architecture}}},
  volume = {1},
  publisher = {Wiley}
}

@article{cadavid2024docker,
  title = {Beyond {{Docker}}: {{Enhancing}} Vantage6 with {{Kubernetes}} for {{Federated Learning}}},
  shorttitle = {Beyond {{Docker}}},
  author = {Cadavid, Héctor and Geng, Cunliang},
  date = {2024-08-22},
  journaltitle = {Studies in Health Technology and Informatics},
  shortjournal = {Stud Health Technol Inform},
  volume = {316},
  eprint = {39176516},
  eprinttype = {pubmed},
  pages = {1603--1604},
  issn = {1879-8365},
  doi = {10.3233/SHTI240729},
  abstract = {Vantage6, a powerful platform for privacy-preserving analysis in the life-sciences domain, employs Docker in its data nodes when performing tasks like federated learning. This tight bond to Docker poses challenges on infrastructure security, efficient computing resources usage, and integration of alternative container technologies. To overcome these challenges, we explored the integration of Kubernetes into vantage6 through a Proof-of-Concept (PoC) approach. The PoC designed and implemented a Kubernetes-based architecture for vantage6, which can be easily deployed on a single machine or a cluster. This PoC serves as the reference to accelerate the adoption of Kubernetes in vantage6.},
  langid = {english},
  keywords = {Biological Science Disciplines,Computer Security,Containers,Docker,Federated learning,Humans,Kubernetes,Machine Learning,Software,vantage6},
  file = {/Users/dkapitan/Zotero/storage/ZGKKEMBM/Cadavid and Geng - 2024 - Beyond Docker Enhancing vantage6 with Kubernetes for Federated Learning.pdf}
}

@article{cascini2024health,
  title = {Health Data Sharing Attitudes towards Primary and Secondary Use of Data: A Systematic Review},
  shorttitle = {Health Data Sharing Attitudes towards Primary and Secondary Use of Data},
  author = {Cascini, Fidelia and Pantovic, Ana and Al-Ajlouni, Yazan A. and Puleo, Valeria and De Maio, Lucia and Ricciardi, Walter},
  date = {2024-05-01},
  journaltitle = {eClinicalMedicine},
  shortjournal = {eClinicalMedicine},
  volume = {71},
  pages = {102551},
  issn = {2589-5370},
  doi = {10.1016/j.eclinm.2024.102551},
  url = {https://www.sciencedirect.com/science/article/pii/S2589537024001305},
  urldate = {2024-03-21},
  abstract = {Background To receive the best care, people share their health data (HD) with their health practitioners (known as sharing HD for primary purposes). However, during the past two decades, sharing for other (i.e., secondary) purposes has become of great importance in numerous fields, including public health, personalized medicine, research, and development. We aimed to conduct the first comprehensive overview of all studies that investigated people's HD sharing attitudes—along with associated barriers/motivators and significant influencing factors—for all data types and across both primary and secondary uses. Methods We searched PubMed, MEDLINE, PsycINFO, Web of Science, EMBASE, and CINAHL for relevant studies published in English between database inception and February 28, 2023, using a predefined set of keywords. Studies were included, regardless of their design, if they reported outcomes related to attitudes towards sharing HD. We extracted key data from the included studies, including the type of HD involved and findings related to: HD sharing attitudes (either in general or depending on type of data/user); barriers/motivators/benefits/concerns of the study participants; and sociodemographic and other variables that could impact HD sharing behaviour. The qualitative synthesis was conducted by dividing the studies according to the data type (resulting in five subgroups) as well as the purpose the data sharing was focused on (primary, secondary or both). The Newcastle–Ottawa Scale (NOS) was used to assess the quality of non-randomised studies. This work was registered with PROSPERO, CRD42023413822. Findings Of 2109 studies identified through our search, 116 were included in the qualitative synthesis, yielding a total of 228,501 participants and various types of HD represented: person-generated HD (n~=~17 studies and 10,771 participants), personal HD in general (n~=~69 studies and 117,054 participants), Biobank data (n~=~7 studies and 27,073 participants), genomic data (n~=~13 studies and 54,716 participants), and miscellaneous data (n~=~10 studies and 18,887 participants). The majority of studies had a moderate level of quality (83 [71.6\%] of 116 studies), but varying levels of quality were observed across the included studies. Overall, studies suggest that sharing intentions for primary purposes were observed to be high regardless of data type, and it was higher than sharing intentions for secondary purposes. Sharing for secondary purposes yielded variable findings, where both the highest and the lowest intention rates were observed in the case of studies that explored sharing biobank data (98\% and 10\%, respectively). Several influencing factors on sharing intentions were identified, such as the type of data recipient, data, consent. Further, concerns related to data sharing that were found to be mutual for all data types included privacy, security, and data access/control, while the perceived benefits included those related to improvements in healthcare. Findings regarding attitudes towards sharing varied significantly across sociodemographic factors and depended on data type and type of use. In most cases, these findings were derived from single studies and therefore warrant confirmations from additional studies. Interpretation Sharing health data is a complex issue that is influenced by various factors (the type of health data, the intended use, the data recipient, among others) and these insights could be used to overcome barriers, address people's concerns, and focus on spreading awareness about the data sharing process and benefits. Funding None.},
  keywords = {Biobank,Data sharing,Genomic data,Person-generated data,Personal health data,Secondary use},
  file = {/Users/dkapitan/Zotero/storage/VILMTDEP/cascini2024health.pdf;/Users/dkapitan/Zotero/storage/2CFANZZK/S2589537024001305.html}
}

@online{choosing,
  title = {Choosing {{Between Microsoft Fabric}} and {{Databricks}}: {{A Guide}} for {{Your Data Analytics Needs}}},
  shorttitle = {Choosing {{Between Microsoft Fabric}} and {{Databricks}}},
  url = {https://www.element61.be/en/resource/choosing-between-microsoft-fabric-and-databricks-guide-your-data-analytics-needs},
  urldate = {2025-01-28},
  abstract = {Feeling torn between Microsoft Fabric and Databricks for data analytics? You're not alone! Let us guide you through their features, functionalities, and benefits to help you make the right choice for your organization.},
  langid = {english},
  organization = {element61},
  file = {/Users/dkapitan/Zotero/storage/QYJW8CWA/choosing-between-microsoft-fabric-and-databricks-guide-your-data-analytics-needs.html}
}

@inproceedings{choudhury2020personal,
  title = {Personal {{Health Train}} on {{FHIR}}: {{A Privacy Preserving Federated Approach}} for {{Analyzing FAIR Data}} in {{Healthcare}}},
  shorttitle = {Personal {{Health Train}} on {{FHIR}}},
  booktitle = {Machine {{Learning}}, {{Image Processing}}, {{Network Security}} and {{Data Sciences}}},
  author = {Choudhury, Ananya and family=Soest, given=Johan, prefix=van, useprefix=true and Nayak, Stuti and Dekker, Andre},
  editor = {Bhattacharjee, Arup and Borgohain, Samir Kr. and Soni, Badal and Verma, Gyanendra and Gao, Xiao-Zhi},
  date = {2020},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {85--95},
  publisher = {Springer},
  location = {Singapore},
  doi = {10.1007/978-981-15-6315-7_7},
  abstract = {Big data and machine learning applications focus on retrieving data on a central location for analysis. However, healthcare data can be sensitive in nature and as such difficult to share and make use for secondary purposes. Healthcare vendors are restricted to share data without proper consent from the patient. There is a rising awareness among individual patients as well regarding sharing their personal information due to ethical, legal and societal problems. The current data-sharing platforms in healthcare do not sufficiently handle these issues. The rationale of the Personal Health Train (PHT) approach shifts the focus from sharing data to sharing processing/analysis applications and their respective results. A prerequisite of the PHT-infrastructure is that the data is FAIR (findable, accessible, interoperable, reusable). The aim of the paper is to describe a methodology of finding the number of patients diagnosed with hypertension and calculate cohort statistics in a privacy-preserving federated manner. The whole process completes without individual patient data leaving the source. For this, we rely on the Fast Healthcare Interoperability Resources (FHIR) standard.},
  isbn = {978-981-15-6315-7},
  langid = {english},
  keywords = {FAIR,FHIR,Personal health train},
  file = {/Users/dkapitan/Zotero/storage/MX4FY5MX/Choudhury et al. - 2020 - Personal Health Train on FHIR A Privacy Preservin.pdf}
}

@article{choudhury2025advancing,
  title = {Advancing {{Privacy-Preserving Health Care Analytics}} and {{Implementation}} of the {{Personal Health Train}}: {{Federated Deep Learning Study}}},
  shorttitle = {Advancing {{Privacy-Preserving Health Care Analytics}} and {{Implementation}} of the {{Personal Health Train}}},
  author = {Choudhury, Ananya and Volmer, Leroy and Martin, Frank and Fijten, Rianne and Wee, Leonard and Dekker, Andre and family=Soest, given=Johan, prefix=van, useprefix=false},
  date = {2025-02-06},
  journaltitle = {JMIR AI},
  volume = {4},
  number = {1},
  pages = {e60847},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/60847},
  url = {https://ai.jmir.org/2025/1/e60847},
  urldate = {2025-06-26},
  abstract = {Background: The rapid advancement of deep learning in health care presents significant opportunities for automating complex medical tasks and improving clinical workflows. However, widespread adoption is impeded by data privacy concerns and the necessity for large, diverse datasets across multiple institutions. Federated learning (FL) has emerged as a viable solution, enabling collaborative artificial intelligence model development without sharing individual patient data. To effectively implement FL in health care, robust and secure infrastructures are essential. Developing such federated deep learning frameworks is crucial to harnessing the full potential of artificial intelligence while ensuring patient data privacy and regulatory compliance. Objective: The objective is to introduce an innovative FL infrastructure called the Personal Health Train (PHT) that includes the procedural, technical, and governance components needed to implement FL on real-world health care data, including training deep learning neural networks. The study aims to apply this federated deep learning infrastructure to the use case of gross tumor volume segmentation on chest computed tomography images of patients with lung cancer and present the results from a proof-of-concept experiment. Methods: The PHT framework addresses the challenges of data privacy when sharing data, by keeping data close to the source and instead bringing the analysis to the data. Technologically, PHT requires 3 interdependent components: “tracks” (protected communication channels), “trains” (containerized software apps), and “stations” (institutional data repositories), which are supported by the open source “Vantage6” software. The study applies this federated deep learning infrastructure to the use case of gross tumor volume segmentation on chest computed tomography images of patients with lung cancer, with the introduction of an additional component called the secure aggregation server, where the model averaging is done in a trusted and inaccessible environment. Results: We demonstrated the feasibility of executing deep learning algorithms in a federated manner using PHT and presented the results from a proof-of-concept study. The infrastructure linked 12 hospitals across 8 nations, covering 4 continents, demonstrating the scalability and global reach of the proposed approach. During the execution and training of the deep learning algorithm, no data were shared outside the hospital. Conclusions: The findings of the proof-of-concept study, as well as the implications and limitations of the infrastructure and the results, are discussed. The application of federated deep learning to unstructured medical imaging data, facilitated by the PHT framework and Vantage6 platform, represents a significant advancement in the field. The proposed infrastructure addresses the challenges of data privacy and enables collaborative model development, paving the way for the widespread adoption of deep learning–based tools in the medical domain and beyond. The introduction of the secure aggregation server implied that data leakage problems in FL can be prevented by careful design decisions of the infrastructure. Trial Registration: ClinicalTrials.gov NCT05775068; https://clinicaltrials.gov/study/NCT05775068},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/2JCJLFIT/Choudhury et al. - 2025 - Advancing Privacy-Preserving Health Care Analytics and Implementation of the Personal Health Train.pdf;/Users/dkapitan/Zotero/storage/MXEUL77T/e60847.html}
}

@article{chustecki2024benefits,
  title = {Benefits and {{Risks}} of {{AI}} in {{Health Care}}: {{Narrative Review}}},
  shorttitle = {Benefits and {{Risks}} of {{AI}} in {{Health Care}}},
  author = {Chustecki, Margaret},
  date = {2024-11-18},
  journaltitle = {Interactive Journal of Medical Research},
  volume = {13},
  number = {1},
  pages = {e53616},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/53616},
  url = {https://www.i-jmr.org/2024/1/e53616},
  urldate = {2025-02-20},
  abstract = {Background: The integration of artificial intelligence (AI) into health care has the potential to transform the industry, but it also raises ethical, regulatory, and safety concerns. This review paper provides an in-depth examination of the benefits and risks associated with AI in health care, with a focus on issues like biases, transparency, data privacy, and safety. Objective: This study aims to evaluate the advantages and drawbacks of incorporating AI in health care. This assessment centers on the potential biases in AI algorithms, transparency challenges, data privacy issues, and safety risks in health care settings. Methods: Studies included in this review were selected based on their relevance to AI applications in health care, focusing on ethical, regulatory, and safety considerations. Inclusion criteria encompassed peer-reviewed articles, reviews, and relevant research papers published in English. Exclusion criteria included non–peer-reviewed articles, editorials, and studies not directly related to AI in health care. A comprehensive literature search was conducted across 8 databases: OVID MEDLINE, OVID Embase, OVID PsycINFO, EBSCO CINAHL Plus with Full Text, ProQuest Sociological Abstracts, ProQuest Philosopher’s Index, ProQuest Advanced Technologies \&amp; Aerospace, and Wiley Cochrane Library. The search was last updated on June 23, 2023. Results were synthesized using qualitative methods to identify key themes and findings related to the benefits and risks of AI in health care. Results: The literature search yielded 8796 articles. After removing duplicates and applying the inclusion and exclusion criteria, 44 studies were included in the qualitative synthesis. This review highlights the significant promise that AI holds in health care, such as enhancing health care delivery by providing more accurate diagnoses, personalized treatment plans, and efficient resource allocation. However, persistent concerns remain, including biases ingrained in AI algorithms, a lack of transparency in decision-making, potential compromises of patient data privacy, and safety risks associated with AI implementation in clinical settings. Conclusions: In conclusion, while AI presents the opportunity for a health care revolution, it is imperative to address the ethical, regulatory, and safety challenges linked to its integration. Proactive measures are required to ensure that AI technologies are developed and deployed responsibly, striking a balance between innovation and the safeguarding of patient well-being.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/YVN9K8XG/e53616.html}
}

@online{composable,
  title = {The {{Composable Codex}}},
  url = {https://voltrondata.com/codex.html},
  urldate = {2024-10-16},
  abstract = {The Composable Codex covers the trends, tools, and standards enabling composable data systems. Discover open data standards making composability possible and how they foster system interoperability and acceleration.},
  langid = {english},
  organization = {Voltron Data},
  file = {/Users/dkapitan/Zotero/storage/K89H8AWL/codex.html}
}

@book{curry2021elements,
  title = {The {{Elements}} of {{Big Data Value}}: {{Foundations}} of the {{Research}} and {{Innovation Ecosystem}}},
  shorttitle = {The {{Elements}} of {{Big Data Value}}},
  editor = {Curry, Edward and Metzger, Andreas and Zillner, Sonja and Pazzaglia, Jean-Christophe and García Robles, Ana},
  date = {2021},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-68176-0},
  url = {https://link.springer.com/10.1007/978-3-030-68176-0},
  urldate = {2025-01-23},
  isbn = {978-3-030-68175-3 978-3-030-68176-0},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/LN9HQFQR/Curry et al. - 2021 - The Elements of Big Data Value Foundations of the Research and Innovation Ecosystem.pdf}
}

@incollection{curry2021reference,
  title = {A {{Reference Model}} for {{Big Data Technologies}}},
  booktitle = {The {{Elements}} of {{Big Data Value}}: {{Foundations}} of the {{Research}} and {{Innovation Ecosystem}}},
  author = {Curry, Edward and Metzger, Andreas and Berre, Arne J. and Monzón, Andrés and Boggio-Marzet, Alessandra},
  editor = {Curry, Edward and Metzger, Andreas and Zillner, Sonja and Pazzaglia, Jean-Christophe and García Robles, Ana},
  date = {2021},
  pages = {127--151},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-68176-0_6},
  url = {https://doi.org/10.1007/978-3-030-68176-0_6},
  urldate = {2024-01-11},
  abstract = {The Big Data Value (BDV) Reference Model has been developed with input from technical experts and stakeholders along the whole big data value chain. The BDV Reference Model may serve as a common reference framework to locate big data technologies on the overall IT stack. It addresses the main technical concerns and aspects to be considered for big data value systems. The BDV Reference Model enables the mapping of existing and future data technologies within a common framework. Within this chapter, we detail the reference model in more detail and show how it can be used to manage a portfolio of research and innovation projects.},
  isbn = {978-3-030-68176-0},
  langid = {english},
  keywords = {Big data technologies,Data analysis,Data management,Data processing,Data protection,Data visualisation,Reference model},
  file = {/Users/dkapitan/Zotero/storage/3HMH2BE9/Curry et al. - 2021 - A Reference Model for Big Data Technologies.pdf}
}

@article{dasilvasantos2023fair,
  title = {{{FAIR Data Point}}: {{A FAIR-Oriented Approach}} for {{Metadata Publication}}},
  shorttitle = {{{FAIR Data Point}}},
  author = {family=Silva Santos, given=Luiz Olavo Bonino, prefix=da, useprefix=true and Burger, Kees and Kaliyaperumal, Rajaram and Wilkinson, Mark D.},
  date = {2023-03-08},
  journaltitle = {Data Intelligence},
  shortjournal = {Data Intelligence},
  volume = {5},
  number = {1},
  pages = {163--183},
  issn = {2641-435X},
  doi = {10.1162/dint_a_00160},
  url = {https://doi.org/10.1162/dint_a_00160},
  urldate = {2025-02-16},
  abstract = {Metadata, data about other digital objects, play an important role in FAIR with a direct relation to all FAIR principles. In this paper we present and discuss the FAIR Data Point (FDP), a software architecture aiming to define a common approach to publish semantically-rich and machine-actionable metadata according to the FAIR principles. We present the core components and features of the FDP, its approach to metadata provision, the criteria to evaluate whether an application adheres to the FDP specifications and the service to register, index and allow users to search for metadata content of available FDPs.},
  file = {/Users/dkapitan/Zotero/storage/Y34RNYYM/da Silva Santos et al. - 2023 - FAIR Data Point A FAIR-Oriented Approach for Metadata Publication.pdf;/Users/dkapitan/Zotero/storage/8P3WD4GA/FAIR-Data-Point-A-FAIR-Oriented-Approach-for.html}
}

@article{deist2020distributed,
  title = {Distributed Learning on 20 000+ Lung Cancer Patients – {{The Personal Health Train}}},
  author = {Deist, Timo M. and Dankers, Frank J.W.M. and Ojha, Priyanka and Scott Marshall, M. and Janssen, Tomas and Faivre-Finn, Corinne and Masciocchi, Carlotta and Valentini, Vincenzo and Wang, Jiazhou and Chen, Jiayan and Zhang, Zhen and Spezi, Emiliano and Button, Mick and Jan Nuyttens, Joost and Vernhout, René and Van Soest, Johan and Jochems, Arthur and Monshouwer, René and Bussink, Johan and Price, Gareth and Lambin, Philippe and Dekker, Andre},
  date = {2020-03},
  journaltitle = {Radiotherapy and Oncology},
  shortjournal = {Radiotherapy and Oncology},
  volume = {144},
  pages = {189--200},
  issn = {01678140},
  doi = {10.1016/j.radonc.2019.11.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167814019334899},
  urldate = {2025-05-27},
  abstract = {Background and purpose: Access to healthcare data is indispensable for scientific progress and innovation. Sharing healthcare data is time-consuming and notoriously difficult due to privacy and regulatory concerns. The Personal Health Train (PHT) provides a privacy-by-design infrastructure connecting FAIR (Findable, Accessible, Interoperable, Reusable) data sources and allows distributed data analysis and machine learning. Patient data never leaves a healthcare institute. Materials and methods: Lung cancer patient-specific databases (tumor staging and post-treatment survival information) of oncology departments were translated according to a FAIR data model and stored locally in a graph database. Software was installed locally to enable deployment of distributed machine learning algorithms via a central server. Algorithms (MATLAB, code and documentation publicly available) are patient privacy-preserving as only summary statistics and regression coefficients are exchanged with the central server. A logistic regression model to predict post-treatment two-year survival was trained and evaluated by receiver operating characteristic curves (ROC), root mean square prediction error (RMSE) and calibration plots. Results: In 4 months, we connected databases with 23 203 patient cases across 8 healthcare institutes in 5 countries (Amsterdam, Cardiff, Maastricht, Manchester, Nijmegen, Rome, Rotterdam, Shanghai) using the PHT. Summary statistics were computed across databases. A distributed logistic regression model predicting post-treatment two-year survival was trained on 14 810 patients treated between 1978 and 2011 and validated on 8 393 patients treated between 2012 and 2015. Conclusion: The PHT infrastructure demonstrably overcomes patient privacy barriers to healthcare data sharing and enables fast data analyses across multiple institutes from different countries with different regulatory regimens. This infrastructure promotes global evidence-based medicine while prioritizing patient privacy.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/AA3T8A2B/deist2020distributed-supplement.docx;/Users/dkapitan/Zotero/storage/AY8GRR9Q/Deist et al. - 2020 - Distributed learning on 20 000+ lung cancer patients – The Personal Health Train.pdf}
}

@article{demast2022analytical,
  title = {Analytical {{Problem Solving Based}} on {{Causal}}, {{Correlational}} and {{Deductive Models}}},
  author = {family=Mast, given=Jeroen, prefix=de, useprefix=true and Steiner, Stefan H. and Nuijten, Wim P. M. and Kapitan, Daniel},
  date = {2022-01-04},
  journaltitle = {The American Statistician},
  shortjournal = {null},
  pages = {1--11},
  publisher = {Taylor \& Francis},
  issn = {0003-1305},
  doi = {10.1080/00031305.2021.2023633},
  url = {https://doi.org/10.1080/00031305.2021.2023633},
  keywords = {Business analytics,Causal inference,Machine learning,Operations research,Predictive modeling,Prescriptive analytics,Problem solving},
  file = {/Users/dkapitan/Zotero/storage/TSQD6J5V/de Mast et al. - 2022 - Analytical Problem Solving Based on Causal, Correl.pdf;/Users/dkapitan/Zotero/storage/WBL5J2BZ/de Mast et al. - 2022 - Analytical Problem Solving Based on Causal, Correl.pdf;/Users/dkapitan/Zotero/storage/QKE3R3BT/00031305.2021.html}
}

@article{demello2022semantica,
  title = {Semantic Interoperability in Health Records Standards: A Systematic Literature Review},
  shorttitle = {Semantic Interoperability in Health Records Standards},
  author = {family=Mello, given=Blanda Helena, prefix=de, useprefix=true and Rigo, Sandro José and family=Costa, given=Cristiano André, prefix=da, useprefix=true and family=Rosa Righi, given=Rodrigo, prefix=da, useprefix=true and Donida, Bruna and Bez, Marta Rosecler and Schunke, Luana Carina},
  date = {2022},
  journaltitle = {Health and Technology},
  shortjournal = {Health Technol (Berl)},
  volume = {12},
  number = {2},
  eprint = {35103230},
  eprinttype = {pubmed},
  pages = {255--272},
  issn = {2190-7188},
  doi = {10.1007/s12553-022-00639-w},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8791650/},
  urldate = {2025-03-07},
  abstract = {The integration and exchange of information among health organizations and system providers are currently regarded as a challenge. Each organization usually has an internal ecosystem and a proprietary way to store electronic health records of the patient’s history. Recent research explores the advantages of an integrated ecosystem by exchanging information between the different inpatient care actors. Many efforts seek quality in health care, economy, and sustainability in process management. Some examples are reducing medical errors, disease control and monitoring, individualized patient care, and avoiding duplicate and fragmented entries in the electronic medical record. Likewise, some studies showed technologies to achieve this goal effectively and efficiently, with the ability to interoperate data, allowing the interpretation and use of health information. To that end, semantic interoperability aims to share data among all the sectors in the organization, clinicians, nurses, lab, the entire hospital. Therefore, avoiding data silos and keep data regardless of vendors, to exchange the information across organizational boundaries. This study presents a comprehensive systematic literature review of semantic interoperability in electronic health records. We searched seven databases of articles published between 2010 to September 2020. We showed the most chosen scenarios, technologies, and tools employed to solve interoperability problems, and we propose a taxonomy around semantic interoperability in health records. Also, we presented the main approaches to solve the exchange problem of legacy and heterogeneous data across healthcare organizations.},
  pmcid = {PMC8791650},
  file = {/Users/dkapitan/Zotero/storage/XK35IJIG/de Mello et al. - 2022 - Semantic interoperability in health records standards a systematic literature review.pdf}
}

@online{dssc2025data,
  title = {Data {{Spaces Blueprint}} v2.0},
  url = {https://dssc.eu/space/BVE2/1071251457/Data+Spaces+Blueprint+v2.0+-+Home},
  urldate = {2025-06-09},
  file = {/Users/dkapitan/Zotero/storage/Q93JZ5E6/Data+Spaces+Blueprint+v2.html}
}

@software{eapen2025dermatologist,
  title = {Dermatologist/Pyomop},
  author = {Eapen, Bell},
  date = {2025-07-01T09:21:55Z},
  origdate = {2020-05-02T16:09:27Z},
  url = {https://github.com/dermatologist/pyomop},
  urldate = {2025-07-01},
  abstract = {Python package for managing OHDSI clinical data models. Includes support for LLM based plain text queries!},
  keywords = {cdm,clinical-trials,datawarehouse,hacktoberfest,health-data-analysis,health-informatics,llm,ohdsi,python,text-to-sql}
}

@online{ehds,
  title = {European {{Health Data Space Regulation}} ({{EHDS}})},
  date = {2025-06-04},
  url = {https://health.ec.europa.eu/ehealth-digital-health-and-care/european-health-data-space-regulation-ehds_en},
  urldate = {2025-06-09},
  abstract = {EHDS empowers health data control for innovation and cross-border healthcare when travelling. Secure and efficient data use.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/UZSSPXTW/european-health-data-space-regulation-ehds_en.html}
}

@incollection{elghosh2024semantic,
  title = {Towards {{Semantic Interoperability Among Heterogeneous Cancer Data Models Using}} a {{Layered Modular Hyper-Ontology}}},
  booktitle = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  author = {El Ghosh, Mirna and Kalokyri, Varvara and Sambres, Melanie and Vaterkowski, Morgan and Duclos, Catherine and Tannier, Xavier and Tsakou, Gianna and Tsiknakis, Manolis and Daniel, Christel and Dhombres, Ferdinand},
  editor = {Trojahn, Cassia and Porello, Daniele and Barcelos, Pedro Paulo Favato},
  date = {2024-12-11},
  publisher = {IOS Press},
  doi = {10.3233/FAIA241305},
  url = {https://ebooks.iospress.nl/doi/10.3233/FAIA241305},
  urldate = {2025-05-06},
  abstract = {Semantic interoperability is a growing and challenging subject in the healthcare domain. It aims to ensure a coherent and unambiguous exchange, use, and reuse of health information among different systems and applications. In the context of the EUCAIM (Cancer Image Europe) project, semantic interoperability among various heterogeneous cancer image data models is required to support the communication, integration, and sharing of data in a standardized and structured way. For this purpose, hyper-ontology is developed as a common semantic metamodel that bridges the disparate imaging and clinical knowledge of the various repositories in EUCAIM and supports their integration. EUCAIM’s hyper-ontology is also an application-based ontology targeted for federated semantic querying and image annotation. To facilitate the hyper-ontology building process and ensure the extensibility of the ontology model, an iterative hybrid well-founded approach that divides the ontology structure into layers and modules is established.},
  isbn = {978-1-64368-561-8},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/YSCKWVGD/El Ghosh et al. - 2024 - Towards Semantic Interoperability Among Heterogeneous Cancer Data Models Using a Layered Modular Hyp.pdf}
}

@article{elkordy2023federateda,
  title = {Federated {{Analytics}}: {{A Survey}}},
  shorttitle = {Federated {{Analytics}}},
  author = {Elkordy, Ahmed Roushdy and Ezzeldin, Yahya H. and Han, Shanshan and Sharma, Shantanu and He, Chaoyang and Mehrotra, Sharad and Avestimehr, Salman},
  date = {2023},
  journaltitle = {APSIPA Transactions on Signal and Information Processing},
  shortjournal = {SIP},
  volume = {12},
  number = {1},
  issn = {2048-7703},
  doi = {10.1561/116.00000063},
  url = {http://www.nowpublishers.com/article/Details/SIP-2022-0063},
  urldate = {2025-06-19},
  abstract = {Federated analytics (FA) is a privacy-preserving framework for computing data analytics over multiple remote parties (e.g., mobile devices) or silo-ed institutional entities (e.g., hospitals, banks) without sharing the data among parties. Motivated by the practical use cases of federated analytics, we follow a systematic discussion on federated analytics in this article. In particular, we discuss the unique characteristics of federated analytics and how it differs from federated learning. We also explore a wide range of FA queries and discuss various existing solutions and potential use case applications for different FA queries.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/6XTNZGAM/Elkordy et al. - 2023 - Federated Analytics A Survey.pdf}
}

@online{eosc-entrust,
  title = {European Network of Trusted Research Environments ({{EOSC-ENTRUST}}) Project},
  date = {2024-03-01},
  url = {https://eosc-entrust.eu/},
  urldate = {2025-06-26},
  abstract = {EOSC-ENTRUST aims to create a European network of Trusted Research Environments (TREs) for sensitive data.},
  langid = {english},
  organization = {EOSC-ENTRUST},
  file = {/Users/dkapitan/Zotero/storage/8MUED39X/eosc-entrust.eu.html}
}

@article{escriba-montagut2024federated,
  title = {Federated Privacy-Protected Meta- and Mega-Omics Data Analysis in Multi-Center Studies with a Fully Open-Source Analytic Platform},
  author = {Escriba-Montagut, Xavier and Marcon, Yannick and Anguita-Ruiz, Augusto and Avraam, Demetris and Urquiza, Jose and Morgan, Andrei S. and Wilson, Rebecca C. and Burton, Paul and Gonzalez, Juan R.},
  date = {2024-12-09},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {20},
  number = {12},
  pages = {e1012626},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1012626},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012626},
  urldate = {2025-06-11},
  abstract = {The importance of maintaining data privacy and complying with regulatory requirements is highlighted especially when sharing omic data between different research centers. This challenge is even more pronounced in the scenario where a multi-center effort for collaborative omics studies is necessary. OmicSHIELD is introduced as an open-source tool aimed at overcoming these challenges by enabling privacy-protected federated analysis of sensitive omic data. In order to ensure this, multiple security mechanisms have been included in the software. This innovative tool is capable of managing a wide range of omic data analyses specifically tailored to biomedical research. These include genome and epigenome wide association studies and differential gene expression analyses. OmicSHIELD is designed to support both meta- and mega-analysis, so that it offers a wide range of capabilities for different analysis designs. We present a series of use cases illustrating some examples of how the software addresses real-world analyses of omic data.},
  langid = {english},
  keywords = {Algorithms,Data management,Genome analysis,Genome-wide association studies,Genomics,Metaanalysis,Single nucleotide polymorphisms,Statistical data},
  file = {/Users/dkapitan/Zotero/storage/DPUFPQ2I/Escriba-Montagut et al. - 2024 - Federated privacy-protected meta- and mega-omics data analysis in multi-center studies with a fully.pdf}
}

@article{estrin2010health,
  title = {Health Care Delivery. {{Open mHealth}} Architecture: An Engine for Health Care Innovation},
  shorttitle = {Health Care Delivery. {{Open mHealth}} Architecture},
  author = {Estrin, Deborah and Sim, Ida},
  date = {2010-11-05},
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science},
  volume = {330},
  number = {6005},
  eprint = {21051617},
  eprinttype = {pubmed},
  pages = {759--760},
  issn = {1095-9203},
  doi = {10.1126/science.1196187},
  langid = {english},
  keywords = {Cell Phone,Delivery of Health Care,Humans,Internet,Medical Informatics,Software,Telemedicine},
  file = {/Users/dkapitan/Zotero/storage/9CHH5MAQ/Estrin and Sim - 2010 - Health care delivery. Open mHealth architecture a.pdf}
}

@article{feng2022clinical,
  title = {Clinical Artificial Intelligence Quality Improvement: Towards Continual Monitoring and Updating of {{AI}} Algorithms in Healthcare},
  shorttitle = {Clinical Artificial Intelligence Quality Improvement},
  author = {Feng, Jean and Phillips, Rachael V. and Malenica, Ivana and Bishara, Andrew and Hubbard, Alan E. and Celi, Leo A. and Pirracchio, Romain},
  date = {2022-05-31},
  journaltitle = {npj Digital Medicine},
  shortjournal = {npj Digit. Med.},
  volume = {5},
  number = {1},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {2398-6352},
  doi = {10.1038/s41746-022-00611-y},
  url = {https://www.nature.com/articles/s41746-022-00611-y},
  urldate = {2025-04-15},
  abstract = {Machine learning (ML) and artificial intelligence (AI) algorithms have the potential to derive insights from clinical data and improve patient outcomes. However, these highly complex systems are sensitive to changes in the environment and liable to performance decay. Even after their successful integration into clinical practice, ML/AI algorithms should be continuously monitored and updated to ensure their long-term safety and effectiveness. To bring AI into maturity in clinical care, we advocate for the creation of hospital units responsible for quality assurance and improvement of these algorithms, which we refer to as “AI-QI” units. We discuss how tools that have long been used in hospital quality assurance and quality improvement can be adapted to monitor static ML algorithms. On the other hand, procedures for continual model updating are still nascent. We highlight key considerations when choosing between existing methods and opportunities for methodological innovation.},
  langid = {english},
  keywords = {Public health,Statistics},
  file = {/Users/dkapitan/Zotero/storage/46VZPAEQ/Feng et al. - 2022 - Clinical artificial intelligence quality improvement towards continual monitoring and updating of A.pdf}
}

@article{finster2025etl,
  title = {{{ETL}}: {{From}} the {{German Health Data Lab}} Data Formats to the {{OMOP Common Data Model}}},
  shorttitle = {{{ETL}}},
  author = {Finster, Melissa and Moinat, Maxim and Taghizadeh, Elham},
  date = {2025-01-06},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {20},
  number = {1},
  pages = {e0311511},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0311511},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0311511},
  urldate = {2025-07-01},
  abstract = {Objective The German Health Data Lab is going to provide access to German statutory health insurance claims data ranging from 2009 to the present for research purposes. Due to evolving data formats within the German Health Data Lab, there is a need to standardize this data into a Common Data Model to facilitate collaborative health research and minimize the need for researchers to adapt to multiple data formats. For this purpose we selected transforming the data to the Observational Medical Outcomes Partnership Common Data Model. Methods We developed an Extract, Transform, and Load (ETL) pipeline for two distinct German Health Data Lab data formats: Format 1 (2009-2016) and Format 3 (2019 onwards). Due to the identical format structure of Format 1 and Format 2 (2017 -2018), the ETL pipeline of Format 1 can be applied on Format 2 as well. Our ETL process, supported by Observational Health Data Sciences and Informatics tools, includes specification development, SQL skeleton creation, and concept mapping. We detail the process characteristics and present a quality assessment that includes field coverage and concept mapping accuracy using example data. Results For Format 1, we achieved a field coverage of 92.7\%. The Data Quality Dashboard showed 100.0\% conformance and 80.6\% completeness, although plausibility checks were disabled. The mapping coverage for the Condition domain was low at 18.3\% due to invalid codes and missing mappings in the provided example data. For Format 3, the field coverage was 86.2\%, with Data Quality Dashboard reporting 99.3\% conformance and 75.9\% completeness. The Procedure domain had very low mapping coverage (2.2\%) due to the use of mocked data and unmapped local concepts The Condition domain results with 99.8\% of unique codes mapped. The absence of real data limits the comprehensive assessment of quality. Conclusion The ETL process effectively transforms the data with high field coverage and conformance. It simplifies data utilization for German Health Data Lab users and enhances the use of OHDSI analysis tools. This initiative represents a significant step towards facilitating cross-border research in Europe by providing publicly available, standardized ETL processes (https://github.com/FraunhoferMEVIS/ETLfromHDLtoOMOP) and evaluations of their performance.},
  langid = {english},
  keywords = {Blood,Health informatics,Health insurance,Inpatients,Outpatients,Physicians,Rabbits,Source code},
  file = {/Users/dkapitan/Zotero/storage/8MMWDKEX/Finster et al. - 2025 - ETL From the German Health Data Lab data formats to the OMOP Common Data Model.pdf}
}

@article{gbadegeshin2022overcoming,
  title = {Overcoming the {{Valley}} of {{Death}}: {{A New Model}} for {{High Technology Startups}}},
  shorttitle = {Overcoming the {{Valley}} of {{Death}}},
  author = {Gbadegeshin, Saheed A. and Natsheh, Anas Al and Ghafel, Kawtar and Mohammed, Omar and Koskela, Ashten and Rimpiläinen, Antti and Tikkanen, Joonas and Kuoppala, Antti},
  date = {2022},
  journaltitle = {Sustainable Futures},
  shortjournal = {Sustainable Futures},
  volume = {4},
  pages = {100077},
  issn = {26661888},
  doi = {10.1016/j.sftr.2022.100077},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2666188822000119},
  urldate = {2025-01-21},
  abstract = {The Valley of Death (VoD) reflects a series of challenges facing technology-based companies during their early development stages. Extant literature highlights the need for startups to equip themselves with the tools and resources to manage this turbulent transition. However, the existing frameworks propounded by fellow scholars and practitioners regarding VoD are fragmented, each covering only a few issues in the chasm. Thus, the current article proposes a new and comprehensive model for high technology-based startups. The new model emerged from an in-depth review of 128 scholarly materials and empirical data collected from 30 startups (from artificial intelligence, virtual and augmented realities, internet of things, medical, and cleantech industrial sectors). The model was piloted in three pre-startups. The model adds on the existing VoD frameworks to provide a holistic baseline for future research in this field by presenting different challenges underlying the pre-establishment years of a company while addressing courses of action needed to overcome this perilous transition.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/5ZTEG4R2/Gbadegeshin et al. - 2022 - Overcoming the Valley of Death A New Model for High Technology Startups.pdf}
}

@article{gbadegeshin2022overcominga,
  title = {Overcoming the {{Valley}} of {{Death}}: {{A New Model}} for {{High Technology Startups}}},
  shorttitle = {Overcoming the {{Valley}} of {{Death}}},
  author = {Gbadegeshin, Saheed A. and Natsheh, Anas Al and Ghafel, Kawtar and Mohammed, Omar and Koskela, Ashten and Rimpiläinen, Antti and Tikkanen, Joonas and Kuoppala, Antti},
  date = {2022},
  journaltitle = {Sustainable Futures},
  shortjournal = {Sustainable Futures},
  volume = {4},
  pages = {100077},
  issn = {26661888},
  doi = {10.1016/j.sftr.2022.100077},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2666188822000119},
  urldate = {2025-05-27},
  abstract = {The Valley of Death (VoD) reflects a series of challenges facing technology-based companies during their early development stages. Extant literature highlights the need for startups to equip themselves with the tools and resources to manage this turbulent transition. However, the existing frameworks propounded by fellow scholars and practitioners regarding VoD are fragmented, each covering only a few issues in the chasm. Thus, the current article proposes a new and comprehensive model for high technology-based startups. The new model emerged from an in-depth review of 128 scholarly materials and empirical data collected from 30 startups (from artificial intelligence, virtual and augmented realities, internet of things, medical, and cleantech industrial sectors). The model was piloted in three pre-startups. The model adds on the existing VoD frameworks to provide a holistic baseline for future research in this field by presenting different challenges underlying the pre-establishment years of a company while addressing courses of action needed to overcome this perilous transition.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/A7HDS9ER/Gbadegeshin et al. - 2022 - Overcoming the Valley of Death A New Model for High Technology Startups.pdf}
}

@article{gentner2023data,
  title = {Data {{Lakes}} in {{Healthcare}}: {{Applications}} and {{Benefits}} from the {{Perspective}} of {{Data Sources}} and {{Players}}},
  shorttitle = {Data {{Lakes}} in {{Healthcare}}},
  author = {Gentner, Tobias and Neitzel, Timon and Schulze, Jacob and Gerschner, Felix and Theissler, Andreas},
  date = {2023},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  volume = {225},
  pages = {1302--1311},
  issn = {18770509},
  doi = {10.1016/j.procs.2023.10.118},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050923012760},
  urldate = {2024-12-02},
  abstract = {As the amount of available data in healthcare has increased significantly and only 20\% of electronic health record data are in a structured format, data lakes have become a common solution for managing heterogeneous data in the healthcare domain. Nowadays, these are utilized far below their capabilities in medical research. Since previous reviews only partly address data lakes in the healthcare domain, a systematic literature review on this topic is missing. Therefore, this paper provides an overview of applications in the healthcare domain that benefit from data lakes. We review the literature and structure it according to data sources and players, and we identify applications and future research needs of data lakes in the healthcare domain. Overall, it turned out that all players could benefit from the capabilities of data lakes. We found that data lakes are currently not broadly implemented in the field, and the viewpoint of hospital operators and healthcare insurers seems to be an underresearched topic compared to the other players.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/55AX3GRC/Gentner et al. - 2023 - Data Lakes in Healthcare Applications and Benefits from the Perspective of Data Sources and Players.pdf}
}

@article{gonzalez-gonzalo2022trustworthy,
  title = {Trustworthy {{AI}}: {{Closing}} the Gap between Development and Integration of {{AI}} Systems in Ophthalmic Practice},
  shorttitle = {Trustworthy {{AI}}},
  author = {González-Gonzalo, Cristina and Thee, Eric F. and Klaver, Caroline C. W. and Lee, Aaron Y. and Schlingemann, Reinier O. and Tufail, Adnan and Verbraak, Frank and Sánchez, Clara I.},
  date = {2022-09-01},
  journaltitle = {Progress in Retinal and Eye Research},
  shortjournal = {Progress in Retinal and Eye Research},
  volume = {90},
  pages = {101034},
  issn = {1350-9462},
  doi = {10.1016/j.preteyeres.2021.101034},
  url = {https://www.sciencedirect.com/science/article/pii/S1350946221000951},
  urldate = {2025-04-15},
  abstract = {An increasing number of artificial intelligence (AI) systems are being proposed in ophthalmology, motivated by the variety and amount of clinical and imaging data, as well as their potential benefits at the different stages of patient care. Despite achieving close or even superior performance to that of experts, there is a critical gap between development and integration of AI systems in ophthalmic practice. This work focuses on the importance of trustworthy AI to close that gap. We identify the main aspects or challenges that need to be considered along the AI design pipeline so as to generate systems that meet the requirements to be deemed trustworthy, including those concerning accuracy, resiliency, reliability, safety, and accountability. We elaborate on mechanisms and considerations to address those aspects or challenges, and define the roles and responsibilities of the different stakeholders involved in AI for ophthalmic care, i.e., AI developers, reading centers, healthcare providers, healthcare institutions, ophthalmological societies and working groups or committees, patients, regulatory bodies, and payers. Generating trustworthy AI is not a responsibility of a sole stakeholder. There is an impending necessity for a collaborative approach where the different stakeholders are represented along the AI design pipeline, from the definition of the intended use to post-market surveillance after regulatory approval. This work contributes to establish such multi-stakeholder interaction and the main action points to be taken so that the potential benefits of AI reach real-world ophthalmic settings.},
  keywords = {Artificial intelligence,Deep learning,Integration,Machine learning,Ophthalmic care,Trustworthiness},
  file = {/Users/dkapitan/Zotero/storage/M4YGKBFM/González-Gonzalo et al. - 2022 - Trustworthy AI Closing the gap between development and integration of AI systems in ophthalmic prac.pdf;/Users/dkapitan/Zotero/storage/4SYP5W9B/S1350946221000951.html}
}

@article{gonzalez-gonzalo2022trustworthya,
  title = {Trustworthy {{AI}}: {{Closing}} the Gap between Development and Integration of {{AI}} Systems in Ophthalmic Practice},
  shorttitle = {Trustworthy {{AI}}},
  author = {González-Gonzalo, Cristina and Thee, Eric F. and Klaver, Caroline C.W. and Lee, Aaron Y. and Schlingemann, Reinier O. and Tufail, Adnan and Verbraak, Frank and Sánchez, Clara I.},
  date = {2022-09},
  journaltitle = {Progress in Retinal and Eye Research},
  shortjournal = {Progress in Retinal and Eye Research},
  volume = {90},
  pages = {101034},
  issn = {13509462},
  doi = {10.1016/j.preteyeres.2021.101034},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1350946221000951},
  urldate = {2025-05-27},
  abstract = {An increasing number of artificial intelligence (AI) systems are being proposed in ophthalmology, motivated by the variety and amount of clinical and imaging data, as well as their potential benefits at the different stages of patient care. Despite achieving close or even superior performance to that of experts, there is a critical gap between development and integration of AI systems in ophthalmic practice. This work focuses on the importance of trustworthy AI to close that gap. We identify the main aspects or challenges that need to be considered along the AI design pipeline so as to generate systems that meet the requirements to be deemed trustworthy, including those concerning accuracy, resiliency, reliability, safety, and accountability. We elaborate on mechanisms and considerations to address those aspects or challenges, and define the roles and responsibilities of the different stakeholders involved in AI for ophthalmic care, i.e., AI developers, reading centers, healthcare providers, healthcare institutions, ophthalmological societies and working groups or committees, patients, regulatory bodies, and payers. Generating trustworthy AI is not a responsibility of a sole stakeholder. There is an impending necessity for a collaborative approach where the different stakeholders are represented along the AI design pipeline, from the definition of the intended use to post-market surveillance after regulatory approval. This work contributes to establish such multi-stakeholder interaction and the main action points to be taken so that the potential benefits of AI reach real-world ophthalmic settings.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/HMMK9XXL/González-Gonzalo et al. - 2022 - Trustworthy AI Closing the gap between development and integration of AI systems in ophthalmic prac.pdf}
}

@inproceedings{gorod2008paradox,
  title = {Paradox: {{Holarchical}} View of System of Systems Engineering Management},
  shorttitle = {Paradox},
  booktitle = {2008 {{IEEE International Conference}} on {{System}} of {{Systems Engineering}}},
  author = {Gorod, Alex and Sauser, Brian and Boardman, John},
  date = {2008-06},
  pages = {1--6},
  doi = {10.1109/SYSOSE.2008.4724171},
  url = {https://ieeexplore.ieee.org/abstract/document/4724171},
  urldate = {2025-06-23},
  abstract = {This paper focuses on a method of developing a framework for effective System of Systems Engineering (SoSE) management.While developing the management process in dealing with SoSE, we are searching for ways to engineer multiple integrated complex systems, which can be concurrently, highly emergent and effectively governable. The authors propose to utilize the "holarchical view" methodology to identify and examine this essential phenomenon of paradoxes of SoSE management. The proposed method is based on the Boardman-Sauser five distinguishing characteristics of Autonomy, Belonging, Connectivty, Diversity, and Emergence. The outcome of this research would influence further studies on the topic and greatly contribute to the SoSE body of knowledge.},
  eventtitle = {2008 {{IEEE International Conference}} on {{System}} of {{Systems Engineering}}},
  keywords = {Autonomy,Belonging,Chaos,Character recognition,Connectivity,Disaster management,Diversity,Emergence,Engineering management,Glass,Holarchical view,Military computing,Paradox,Production systems,Research and development management,SoSE Management,Systems engineering and theory,Technology management},
  file = {/Users/dkapitan/Zotero/storage/47EGSQFJ/Gorod et al. - 2008 - Paradox Holarchical view of system of systems engineering management.pdf}
}

@article{gu2022systematic,
  title = {A Systematic Overview of Data Federation Systems},
  author = {Gu, Zhenzhen and Corcoglioniti, Francesco and Lanti, Davide and Mosca, Alessandro and Xiao, Guohui and Xiong, Jing and Calvanese, Diego},
  date = {2022-12-06},
  journaltitle = {Semantic Web},
  volume = {15},
  number = {1},
  pages = {107--165},
  publisher = {IOS Press},
  issn = {1570-0844},
  doi = {10.3233/SW-223201},
  url = {https://content.iospress.com/articles/semantic-web/sw223201},
  urldate = {2024-05-27},
  abstract = {Data federation addresses the problem of uniformly accessing multiple, possibly heterogeneous data sources, by mapping them into a unified schema, such as an RDF(S)/OWL ontology or a relational schema, and by supporting the execution of queries, like},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/8FWFTGCM/Gu et al. - 2024 - A systematic overview of data federation systems.pdf}
}

@article{guerin2021osiris,
  title = {{{OSIRIS}}: {{A Minimum Data Set}} for {{Data Sharing}} and {{Interoperability}} in {{Oncology}}},
  shorttitle = {{{OSIRIS}}},
  author = {Guérin, Julien and Laizet, Yec'han and Le Texier, Vincent and Chanas, Laetitia and Rance, Bastien and Koeppel, Florence and Lion, François and Gourgou, Sophie and Martin, Anne-Laure and Tejeda, Manuel and Toulmonde, Maud and Cox, Stéphanie and Hess, Elisabeth and Rousseau-Tsangaris, Marina and Jouhet, Vianney and Saintigny, Pierre},
  date = {2021-03},
  journaltitle = {JCO Clinical Cancer Informatics},
  shortjournal = {JCO Clin Cancer Inform},
  number = {5},
  pages = {256--265},
  publisher = {Wolters Kluwer},
  doi = {10.1200/CCI.20.00094},
  url = {https://ascopubs.org/doi/10.1200/CCI.20.00094},
  urldate = {2025-03-12},
  abstract = {PurposeMany institutions throughout the world have launched precision medicine initiatives in oncology, and a large amount of clinical and genomic data is being produced. Although there have been attempts at data sharing with the community, initiatives are still limited. In this context, a French task force composed of Integrated Cancer Research Sites (SIRICs), comprehensive cancer centers from the Unicancer network (one of Europe's largest cancer research organization), and university hospitals launched an initiative to improve and accelerate retrospective and prospective clinical and genomic data sharing in oncology.Materials and MethodsFor 5 years, the OSIRIS group has worked on structuring data and identifying technical solutions for collecting and sharing them. The group used a multidisciplinary approach that included weekly scientific and technical meetings over several months to foster a national consensus on a minimal data set.ResultsThe resulting OSIRIS set and event-based data model, which is able to capture the disease course, was built with 67 clinical and 65 omics items. The group made it compatible with the HL7 Fast Healthcare Interoperability Resources (FHIR) format to maximize interoperability. The OSIRIS set was reviewed, approved by a National Plan Strategic Committee, and freely released to the community. A proof-of-concept study was carried out to put the OSIRIS set and Common Data Model into practice using a cohort of 300 patients.ConclusionUsing a national and bottom-up approach, the OSIRIS group has defined a model including a minimal set of clinical and genomic data that can be used to accelerate data sharing produced in oncology. The model relies on clear and formally defined terminologies and, as such, may also benefit the larger international community.},
  file = {/Users/dkapitan/Zotero/storage/73Z7ZZ58/Guérin et al. - 2021 - OSIRIS A Minimum Data Set for Data Sharing and Interoperability in Oncology.pdf}
}

@article{hai2023data,
  title = {Data {{Lakes}}: {{A Survey}} of {{Functions}} and {{Systems}}},
  shorttitle = {Data {{Lakes}}},
  author = {Hai, Rihan and Koutras, Christos and Quix, Christoph and Jarke, Matthias},
  date = {2023-12},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {35},
  number = {12},
  pages = {12571--12590},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2023.3270101},
  url = {https://ieeexplore.ieee.org/abstract/document/10107808},
  urldate = {2024-01-11},
  abstract = {Data lakes are becoming increasingly prevalent for Big Data management and data analytics. In contrast to traditional ‘schema-on-write’ approaches such as data warehouses, data lakes are repositories storing raw data in its original formats and providing a common access interface. Despite the strong interest raised from both academia and industry, there is a large body of ambiguity regarding the definition, functions and available technologies for data lakes. A complete, coherent picture of data lake challenges and solutions is still missing. This survey reviews the development, architectures, and systems of data lakes. We provide a comprehensive overview of research questions for designing and building data lakes. We classify the existing approaches and systems based on their provided functions for data lakes, which makes this survey a useful technical reference for designing, implementing and deploying data lakes. We hope that the thorough comparison of existing solutions and the discussion of open research challenges in this survey will motivate the future development of data lake research and practice.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  file = {/Users/dkapitan/Zotero/storage/R87AQA44/Hai et al. - 2023 - Data Lakes A Survey of Functions and Systems.pdf}
}

@online{hall2021syft,
  title = {Syft 0.5: {{A Platform}} for {{Universally Deployable Structured Transparency}}},
  shorttitle = {Syft 0.5},
  author = {Hall, Adam James and Jay, Madhava and Cebere, Tudor and Cebere, Bogdan and family=Veen, given=Koen Lennart, prefix=van der, useprefix=false and Muraru, George and Xu, Tongye and Cason, Patrick and Abramson, William and Benaissa, Ayoub and Shah, Chinmay and Aboudib, Alan and Ryffel, Théo and Prakash, Kritika and Titcombe, Tom and Khare, Varun Kumar and Shang, Maddie and Junior, Ionesio and Gupta, Animesh and Paumier, Jason and Kang, Nahua and Manannikov, Vova and Trask, Andrew},
  date = {2021-04-27},
  eprint = {2104.12385},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2104.12385},
  url = {http://arxiv.org/abs/2104.12385},
  urldate = {2025-06-30},
  abstract = {We present Syft 0.5, a general-purpose framework that combines a core group of privacy-enhancing technologies that facilitate a universal set of structured transparency systems. This framework is demonstrated through the design and implementation of a novel privacy-preserving inference information flow where we pass homomorphically encrypted activation signals through a split neural network for inference. We show that splitting the model further up the computation chain significantly reduces the computation time of inference and the payload size of activation signals at the cost of model secrecy. We evaluate our proposed flow with respect to its provision of the core structural transparency principles.},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {/Users/dkapitan/Zotero/storage/X86GMIQD/Hall et al. - 2021 - Syft 0.5 A Platform for Universally Deployable Structured Transparency.pdf;/Users/dkapitan/Zotero/storage/L4BLDQ3V/2104.html}
}

@article{hanser2025datadriven,
  title = {Data-Driven Federated Learning in Drug Discovery with Knowledge Distillation},
  author = {Hanser, Thierry and Ahlberg, Ernst and Amberg, Alexander and Anger, Lennart T. and Barber, Chris and Brennan, Richard J. and Brigo, Alessandro and Delaunois, Annie and Glowienke, Susanne and Greene, Nigel and Johnston, Laura and Kuhn, Daniel and Kuhnke, Lara and Marchaland, Jean-François and Muster, Wolfgang and Plante, Jeffrey and Rippmann, Friedrich and Sabnis, Yogesh and Schmidt, Friedemann and family=Deursen, given=Ruud, prefix=van, useprefix=true and Werner, Stéphane and White, Angela and Wichard, Joerg and Yukawa, Tomoya},
  date = {2025-03},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {7},
  number = {3},
  pages = {423--436},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-025-00991-2},
  url = {https://www.nature.com/articles/s42256-025-00991-2},
  urldate = {2025-06-30},
  abstract = {A main challenge for artificial intelligence in scientific research is ensuring access to sufficient, high-quality data for the development of impactful models. Despite the abundance of public data, the most valuable knowledge often remains embedded within confidential corporate data silos. Although industries are increasingly open to sharing non-competitive insights, such collaboration is often constrained by the confidentiality of the underlying data. Federated learning makes it possible to share knowledge without compromising data privacy, but it has notable limitations. Here, we introduce FLuID (federated learning using information distillation), a data-centric application of federated distillation tailored to drug discovery aiming to preserve data privacy. We validate FLuID in two experiments, first involving public data simulating a virtual consortium and second in a real-world research collaboration between eight pharmaceutical companies. Although the alignment of the models with the partner specific domain remains challenging, the data-driven nature of FLuID offers several avenues to mitigate domain shift. FLuID fosters knowledge sharing among pharmaceutical organizations, paving the way for a new generation of models with enhanced performance and an expanded applicability domain in biological activity predictions.},
  langid = {english},
  keywords = {Chemical tools,Cheminformatics,Computational chemistry,Drug safety},
  file = {/Users/dkapitan/Zotero/storage/K86DFKMK/Hanser et al. - 2025 - Data-driven federated learning in drug discovery with knowledge distillation.pdf}
}

@article{harby2025data,
  title = {Data {{Lakehouse}}: {{A}} Survey and Experimental Study},
  shorttitle = {Data {{Lakehouse}}},
  author = {Harby, Ahmed A. and Zulkernine, Farhana},
  date = {2025-01},
  journaltitle = {Information Systems},
  shortjournal = {Information Systems},
  volume = {127},
  pages = {102460},
  issn = {03064379},
  doi = {10.1016/j.is.2024.102460},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0306437924001182},
  urldate = {2025-03-16},
  abstract = {Efficient big data management is a dire necessity to manage the exponential growth in data generated by digital information systems to produce usable knowledge. Structured databases, data lakes, and warehouses have each provided a solution with varying degrees of success. However, a new and superior solution, the data Lakehouse, has emerged to extract actionable insights from unstructured data ingested from distributed sources. By combining the strengths of data warehouses and data lakes, the data Lakehouse can process and merge data quickly while ingesting and storing high-speed unstructured data with post-storage transformation and analytics capabilities. The Lakehouse architecture offers the necessary features for optimal functionality and has gained significant attention in the big data management research community. In this paper, we compare data lake, warehouse, and lakehouse systems, highlight their strengths and shortcomings, identify the desired features to handle the evolving challenges in big data management and analysis and propose an advanced data Lakehouse architecture. We also demonstrate the performance of three state-of-the-art data management systems namely HDFS data lake, Hive data warehouse, and Delta lakehouse in managing data for analytical query responses through an experimental study.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/YG5UJM8Z/Harby and Zulkernine - 2025 - Data Lakehouse A survey and experimental study.pdf}
}

@online{homepage,
  title = {Homepage - {{Leidraad-ai}}},
  url = {https://guideline-ai-healthcare.com/},
  urldate = {2025-01-20},
  abstract = {Waardevolle AI Hoe beoordeel je voorspellende artificiële intelligentie (AI) algoritmen voor gezondheid en zorg op kwaliteit en effectiviteit? De Leidraad kwaliteit AI in de zorg geeft u een overzicht van de belangrijkste eisen en aanbevelingen per fase, van ontwikkeling tot implementatie. Lees meer berichten over de leidraad op datavoorgezondheid.nl Vragen/opmerkingen? Deze kunt u delen via},
  langid = {english},
  organization = {Leidraad-ai -},
  file = {/Users/dkapitan/Zotero/storage/QKXMWPDW/guideline-ai-healthcare.com.html}
}

@article{hosch2023fhirpyrate,
  title = {{{FHIR-PYrate}}: A Data Science Friendly {{Python}} Package to Query {{FHIR}} Servers},
  shorttitle = {{{FHIR-PYrate}}},
  author = {Hosch, René and Baldini, Giulia and Parmar, Vicky and Borys, Katarzyna and Koitka, Sven and Engelke, Merlin and Arzideh, Kamyar and Ulrich, Moritz and Nensa, Felix},
  date = {2023-07-06},
  journaltitle = {BMC Health Services Research},
  shortjournal = {BMC Health Serv Res},
  volume = {23},
  number = {1},
  pages = {734},
  issn = {1472-6963},
  doi = {10.1186/s12913-023-09498-1},
  url = {https://doi.org/10.1186/s12913-023-09498-1},
  urldate = {2025-05-06},
  abstract = {We present FHIR-PYrate, a Python package to handle the full clinical data collection and extraction process. The software is to be plugged into a modern hospital domain, where electronic patient records are used to handle the entire patient’s history. Most research institutes follow the same procedures to build study cohorts, but mainly in a non-standardized and repetitive way. As a result, researchers spend time writing boilerplate code, which could be used for more challenging tasks.},
  langid = {english},
  keywords = {Dataframe,Dicom,Electronic patient record,FHIR,Information extraction,Python},
  file = {/Users/dkapitan/Zotero/storage/WE6FZEL3/Hosch et al. - 2023 - FHIR-PYrate a data science friendly Python package to query FHIR servers.pdf}
}

@online{interactivea,
  title = {An {{Interactive Introduction}} to {{Model-Agnostic Meta-Learning}} 👩‍🔬},
  url = {https://interactive-maml.github.io/first-order.html},
  urldate = {2025-06-30},
  file = {/Users/dkapitan/Zotero/storage/X74R3KCY/first-order.html}
}

@online{jmirc,
  title = {{{JMIR AI}} - {{Advancing Privacy-Preserving Health Care Analytics}} and {{Implementation}} of the {{Personal Health Train}}: {{Federated Deep Learning Study}}},
  url = {https://ai.jmir.org/2025/1/e60847},
  urldate = {2025-06-24},
  file = {/Users/dkapitan/Zotero/storage/UB8FREI6/e60847.html}
}

@article{johnson2021isa,
  title = {{{ISA API}}: {{An}} Open Platform for Interoperable Life Science Experimental Metadata},
  shorttitle = {{{ISA API}}},
  author = {Johnson, David and Batista, Dominique and Cochrane, Keeva and Davey, Robert P and Etuk, Anthony and Gonzalez-Beltran, Alejandra and Haug, Kenneth and Izzo, Massimiliano and Larralde, Martin and Lawson, Thomas N and Minotto, Alice and Moreno, Pablo and Nainala, Venkata Chandrasekhar and O'Donovan, Claire and Pireddu, Luca and Roger, Pierrick and Shaw, Felix and Steinbeck, Christoph and Weber, Ralf J M and Sansone, Susanna-Assunta and Rocca-Serra, Philippe},
  date = {2021-09-01},
  journaltitle = {GigaScience},
  shortjournal = {GigaScience},
  volume = {10},
  number = {9},
  pages = {giab060},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giab060},
  url = {https://doi.org/10.1093/gigascience/giab060},
  urldate = {2025-06-23},
  abstract = {The Investigation/Study/Assay (ISA) Metadata Framework is an established and widely used set of open source community specifications and software tools for enabling discovery, exchange, and publication of metadata from experiments in the life sciences. The original ISA software suite provided a set of user-facing Java tools for creating and manipulating the information structured in ISA-Tab—a now widely used tabular format. To make the ISA framework more accessible to machines and enable programmatic manipulation of experiment metadata, the JSON serialization ISA-JSON was developed.In this work, we present the ISA API, a Python library for the creation, editing, parsing, and validating of ISA-Tab and ISA-JSON formats by using a common data model engineered as Python object classes. We describe the ISA API feature set, early adopters, and its growing user community.The ISA API provides users with rich programmatic metadata-handling functionality to support automation, a common interface, and an interoperable medium between the 2 ISA formats, as well as with other life science data formats required for depositing data in public databases.},
  file = {/Users/dkapitan/Zotero/storage/BPDN8CDA/Johnson et al. - 2021 - ISA API An open platform for interoperable life science experimental metadata.pdf;/Users/dkapitan/Zotero/storage/D5CZY3RD/6371038.html}
}

@article{kahn2006framework,
  title = {A Framework for Distributed Digital Object Services},
  author = {Kahn, Robert and Wilensky, Robert},
  date = {2006-04},
  journaltitle = {International Journal on Digital Libraries},
  shortjournal = {Int J Digit Libr},
  volume = {6},
  number = {2},
  pages = {115--123},
  issn = {1432-5012, 1432-1300},
  doi = {10.1007/s00799-005-0128-x},
  url = {http://link.springer.com/10.1007/s00799-005-0128-x},
  urldate = {2025-06-19},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/X42TYRC3/Kahn and Wilensky - 2006 - A framework for distributed digital object services.pdf}
}

@inproceedings{kancharla2023breaking,
  title = {Breaking {{Down Data Silos}}: {{Data Mesh}} to {{Achieve Effective Aggregation}} in {{Data Localization}}},
  shorttitle = {Breaking {{Down Data Silos}}},
  booktitle = {2023 {{International Conference}} on {{Computer}}, {{Electronics}} \& {{Electrical Engineering}} \& Their {{Applications}} ({{IC2E3}})},
  author = {Kancharla, Jaganmohan Reddy and Madhu Kumar, S. D.},
  date = {2023-06},
  pages = {1--5},
  doi = {10.1109/IC2E357697.2023.10262765},
  url = {https://ieeexplore.ieee.org/document/10262765},
  urldate = {2025-06-30},
  abstract = {Data localization laws are becoming more common, which makes it hard for companies to manage and combine data that is spread out in different parts of the world. This is especially hard because data is scattered and there are limits on how data can be sent across borders. Data Mesh, a new way of thinking about data architecture, offers a solution to this problem by offering a decentralized way of managing data that can make it easier to put together data in a local context. In this paper, we discuss the problems that organizations face when trying to manage data localization with respect to the data regulations in different regions, the problems with traditional approaches to data management, and the benefits of using a data mesh architecture to gather data. We also discuss a region-based unified data mesh architecture that was made with data localization in mind, pointing out its most important parts and benefits. Our proposed unified data mesh abstraction model can help organizations to deal with the problems caused by data localization and use their data assets to make better decisions and get better insights.},
  eventtitle = {2023 {{International Conference}} on {{Computer}}, {{Electronics}} \& {{Electrical Engineering}} \& Their {{Applications}} ({{IC2E3}})},
  keywords = {Analytics,Companies,Data Aggregation,Data Architecture,Data localization,Data mesh,Data models,Data Silos,Faces,Location awareness,Region oriented,Regulation},
  file = {/Users/dkapitan/Zotero/storage/FJURBEL5/Kancharla and Madhu Kumar - 2023 - Breaking Down Data Silos Data Mesh to Achieve Effective Aggregation in Data Localization.pdf;/Users/dkapitan/Zotero/storage/GZPT56U5/10262765.html}
}

@article{kapitan2025data,
  title = {Data {{Interoperability}} in {{Context}}: {{The Importance}} of {{Open-Source Implementations When Choosing Open Standards}}},
  shorttitle = {Data {{Interoperability}} in {{Context}}},
  author = {Kapitan, Daniel and Heddema, Femke and Dekker, André and Sieswerda, Melle and Verhoeff, Bart-Jan and Berg, Matt},
  date = {2025-04-15},
  journaltitle = {Journal of Medical Internet Research},
  volume = {27},
  number = {1},
  pages = {e66616},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/66616},
  url = {https://www.jmir.org/2025/1/e66616},
  urldate = {2025-04-15},
  abstract = {Following the proposal by Tsafnat et al (2024) to converge on three open health data standards, this viewpoint offers a critical reflection on their proposed alignment of openEHR, Fast Health Interoperability Resources (FHIR), and Observational Medical Outcomes Partnership (OMOP) as default data standards for clinical care and administration, data exchange, and longitudinal analysis, respectively. We argue that open standards are a necessary but not sufficient condition to achieve health data interoperability. The ecosystem of open-source software needs to be considered when choosing an appropriate standard for a given context. We discuss two specific contexts, namely standardization of (1) health data for federated learning, and (2) health data sharing in low- and middle-income countries. Specific design principles, practical considerations, and implementation choices for these two contexts are described, based on ongoing work in both areas. In the case of federated learning, we observe convergence toward OMOP and FHIR, where the two standards can effectively be used side-by-side given the availability of mediators between the two. In the case of health information exchanges in low and middle-income countries, we see a strong convergence toward FHIR as the primary standard. We propose practical guidelines for context-specific adaptation of open health data standards.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/MFF97PKZ/e66616.html}
}

@book{kleppmann2026designing,
  title = {Designing Data-Intensive Applications, 2nd Edtion (Early Release)},
  author = {Kleppmann, Martin and Riccomini, Chris},
  date = {2026-01-01},
  publisher = {O'Reilly}
}

@report{krewer2024digital,
  title = {Digital {{Commons}} as {{Providers}} of {{Public Digital Infrastructures}}},
  author = {Krewer, Jan and Warso, Zuzanna},
  date = {2024-11-13},
  institution = {Open Future Foundation},
  url = {https://openfuture.eu/publication/digital-commons-as-providers-of-public-digital-infrastructures},
  urldate = {2025-06-15},
  abstract = {This paper examines literature on public digital infrastructures and current global debates. It presents five case studies demonstrating how Digital Commons can support and improve these infrastructures.},
  langid = {american},
  file = {/Users/dkapitan/Zotero/storage/QJSMLMF5/Digital Commons as Providers of Public Digital Infrastructures.pdf;/Users/dkapitan/Zotero/storage/W9N8CT3J/digital-commons-as-providers-of-public-digital-infrastructures.html}
}

@online{laboratoryofmedicalinformaticsandknowledgeengineeringine-healthlimics2025eucaims,
  title = {{{EUCAIM}}'s {{Hyper-Ontology}}\_{{V1}}.2},
  author = {{Laboratory of Medical Informatics and Knowledge Engineering in e-Health (LIMICS)}},
  namea = {{Foundation for Research and Technology Hellas (FORTH)} and {Hospital Universitari i Politècnic La Fe} and {German Cancer Research Center (DKFZ)} and {Assistance publique - Hôpitaux de Paris (APHP)} and {Gdański Uniwersytet Medyczny (GUMed)} and {INCISIVE} and {ProCAncer-I} and {CHAIMELEON} and {EuCanImage}},
  nameatype = {collaborator},
  date = {2025-01-29},
  eprinttype = {Zenodo},
  doi = {10.5281/ZENODO.14765570},
  url = {https://zenodo.org/doi/10.5281/zenodo.14765570},
  urldate = {2025-05-06},
  abstract = {An updated version of EUCAIM's Hyper-Ontology (min-FIF). {$>>>$} This effort is part of the EUCAIM project {$>>>$} The ontology documentation is generated using~WIDOCO},
  pubstate = {prepublished}
}

@article{ladewig2023ga4gh,
  title = {{{GA4GH Phenopackets}}: {{A Practical Introduction}}},
  shorttitle = {{{GA4GH Phenopackets}}},
  author = {Ladewig, Markus S. and Jacobsen, Julius O. B. and Wagner, Alex H. and Danis, Daniel and El Kassaby, Baha and Gargano, Michael and Groza, Tudor and Baudis, Michael and Steinhaus, Robin and Seelow, Dominik and Bechrakis, Nikolaos E. and Mungall, Christopher J. and Schofield, Paul N. and Elemento, Olivier and Smith, Lindsay and McMurry, Julie A. and Munoz-Torres, Monica and Haendel, Melissa A. and Robinson, Peter N.},
  date = {2023},
  journaltitle = {Advanced Genetics},
  volume = {4},
  number = {1},
  pages = {2200016},
  issn = {2641-6573},
  doi = {10.1002/ggn2.202200016},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ggn2.202200016},
  urldate = {2025-06-23},
  abstract = {The Global Alliance for Genomics and Health (GA4GH) is developing a suite of coordinated standards for genomics for healthcare. The Phenopacket is a new GA4GH standard for sharing disease and phenotype information that characterizes an individual person, linking that individual to detailed phenotypic descriptions, genetic information, diagnoses, and treatments. A detailed example is presented that illustrates how to use the schema to represent the clinical course of a patient with retinoblastoma, including demographic information, the clinical diagnosis, phenotypic features and clinical measurements, an examination of the extirpated tumor, therapies, and the results of genomic analysis. The Phenopacket Schema, together with other GA4GH data and technical standards, will enable data exchange and provide a foundation for the computational analysis of disease and phenotype information to improve our ability to diagnose and conduct research on all types of disorders, including cancer and rare diseases.},
  langid = {english},
  keywords = {deep phenotyping,FAIR data,Global Alliance for Genomics and Health,Human Phenotype Ontology,Phenopacket Schema},
  file = {/Users/dkapitan/Zotero/storage/CEZQNW8L/Ladewig et al. - 2023 - GA4GH Phenopackets A Practical Introduction.pdf;/Users/dkapitan/Zotero/storage/9PDDJBQE/ggn2.html}
}

@article{lehvaslaiho2025spe,
  title = {{{SPE}} and {{TRE}} Terminology for Sensitive Data Processing},
  author = {Lehväslaiho, Heikki},
  date = {2025-06-10},
  doi = {10.5281/zenodo.15696511},
  url = {https://zenodo.org/records/15696511},
  urldate = {2025-06-26},
  abstract = {This white paper summarises the finding of the first version of the EOSC-ENTRUST Architecture Blueprint about terminology used to describe computing environments for sensitive data processing. They are commonly used interchangeably, but in professional context they can have different scope and need to be used correctly.},
  keywords = {ELIXIR,EOSC-ENTRUST,SPE,TRE}
}

@article{leiner2021bringing,
  title = {Bringing {{AI}} to the Clinic: Blueprint for a Vendor-Neutral {{AI}} Deployment Infrastructure},
  shorttitle = {Bringing {{AI}} to the Clinic},
  author = {Leiner, Tim and Bennink, Edwin and Mol, Christian P. and Kuijf, Hugo J. and Veldhuis, Wouter B.},
  date = {2021-12},
  journaltitle = {Insights into Imaging},
  shortjournal = {Insights Imaging},
  volume = {12},
  number = {1},
  pages = {11},
  issn = {1869-4101},
  doi = {10.1186/s13244-020-00931-1},
  url = {https://insightsimaging.springeropen.com/articles/10.1186/s13244-020-00931-1},
  urldate = {2025-04-08},
  abstract = {AI provides tremendous opportunities for improving patient care, but at present there is little evidence of real-world uptake. An important barrier is the lack of well-designed, vendor-neutral and future-proof infrastructures for deployment. Because current AI algorithms are very narrow in scope, it is expected that a typical hospital will deploy many algorithms concurrently. Managing stand-alone point solutions for all of these algorithms will be unmanageable. A solution to this problem is a dedicated platform for deployment of AI. Here we describe a blueprint for such a platform and the high-level design and implementation considerations of such a system that can be used clinically as well as for research and development. Close collaboration between radiologists, data scientists, software developers and experts in hospital IT as well as involvement of patients is crucial in order to successfully bring AI to the clinic.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/KQYILQDC/Leiner et al. - 2021 - Bringing AI to the clinic blueprint for a vendor-neutral AI deployment infrastructure.pdf}
}

@article{leroux2017achieving,
  title = {Towards Achieving Semantic Interoperability of Clinical Study Data with {{FHIR}}},
  author = {Leroux, Hugo and Metke-Jimenez, Alejandro and Lawley, Michael J.},
  date = {2017-12},
  journaltitle = {Journal of Biomedical Semantics},
  shortjournal = {J Biomed Semant},
  volume = {8},
  number = {1},
  pages = {41},
  issn = {2041-1480},
  doi = {10.1186/s13326-017-0148-7},
  url = {http://jbiomedsem.biomedcentral.com/articles/10.1186/s13326-017-0148-7},
  urldate = {2025-03-24},
  abstract = {Background: Observational clinical studies play a pivotal role in advancing medical knowledge and patient healthcare. To lessen the prohibitive costs of conducting these studies and support evidence-based medicine, results emanating from these studies need to be shared and compared to one another. Current approaches for clinical study management have limitations that prohibit the effective sharing of clinical research data. Methods: The objective of this paper is to present a proposal for a clinical study architecture to not only facilitate the communication of clinical study data but also its context so that the data that is being communicated can be unambiguously understood at the receiving end. Our approach is two-fold. First we outline our methodology to map clinical data from Clinical Data Interchange Standards Consortium Operational Data Model (ODM) to the Fast Healthcare Interoperable Resource (FHIR) and outline the strengths and weaknesses of this approach. Next, we propose two FHIR-based models, to capture the metadata and data from the clinical study, that not only facilitate the syntactic but also semantic interoperability of clinical study data. Conclusions: This work shows that our proposed FHIR resources provide a good fit to semantically enrich the ODM data. By exploiting the rich information model in FHIR, we can organise clinical data in a manner that preserves its organisation but captures its context. Our implementations demonstrate that FHIR can natively manage clinical data. Furthermore, by providing links at several levels, it improves the traversal and querying of the data. The intended benefits of this approach is more efficient and effective data exchange that ultimately will allow clinicians to switch their focus back to decision-making and evidence-based medicines.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/336XH4TF/Leroux et al. - 2017 - Towards achieving semantic interoperability of clinical study data with FHIR.pdf}
}

@book{li2024challenges,
  title = {From {{Challenges}} and {{Pitfalls}} to {{Recommendations}} and {{Opportunities}}: {{Implementing Federated Learning}} in {{Healthcare}}},
  shorttitle = {From {{Challenges}} and {{Pitfalls}} to {{Recommendations}} and {{Opportunities}}},
  author = {Li, Ming and Xu, Pengcheng and Hu, Junjie and Tang, Zeyu and Yang, Guang},
  date = {2024-09-15},
  doi = {10.48550/arXiv.2409.09727},
  abstract = {Federated learning holds great potential for enabling large-scale healthcare research and collaboration across multiple centres while ensuring data privacy and security are not compromised. Although numerous recent studies suggest or utilize federated learning based methods in healthcare, it remains unclear which ones have potential clinical utility. This review paper considers and analyzes the most recent studies up to May 2024 that describe federated learning based methods in healthcare. After a thorough review, we find that the vast majority are not appropriate for clinical use due to their methodological flaws and/or underlying biases which include but are not limited to privacy concerns, generalization issues, and communication costs. As a result, the effectiveness of federated learning in healthcare is significantly compromised. To overcome these challenges, we provide recommendations and promising opportunities that might be implemented to resolve these problems and improve the quality of model development in federated learning with healthcare.},
  file = {/Users/dkapitan/Zotero/storage/7LYW3Y58/Li et al. - 2024 - From Challenges and Pitfalls to Recommendations and Opportunities Implementing Federated Learning i.pdf}
}

@article{li2025evolution,
  title = {Evolution of {{Artificial Intelligence}} in {{Medical Education From}} 2000 to 2024: {{Bibliometric Analysis}}},
  shorttitle = {Evolution of {{Artificial Intelligence}} in {{Medical Education From}} 2000 to 2024},
  author = {Li, Rui and Wu, Tong},
  date = {2025-01-30},
  journaltitle = {Interactive Journal of Medical Research},
  volume = {14},
  number = {1},
  pages = {e63775},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/63775},
  url = {https://www.i-jmr.org/2025/1/e63775},
  urldate = {2025-02-25},
  abstract = {Background: Incorporating artificial intelligence (AI) into medical education has gained significant attention for its potential to enhance teaching and learning outcomes. However, it lacks a comprehensive study depicting the academic performance and status of AI in the medical education domain. Objective: This study aims to analyze the social patterns, productive contributors, knowledge structure, and clusters since the 21st century. Methods: Documents were retrieved from the Web of Science Core Collection database from 2000 to 2024. VOSviewer, Incites, and Citespace were used to analyze the bibliometric metrics, which were categorized by country, institution, authors, journals, and keywords. The variables analyzed encompassed counts, citations, H-index, impact factor, and collaboration metrics. Results: Altogether, 7534 publications were initially retrieved and 2775 were included for analysis. The annual count and citation of papers exhibited exponential trends since 2018. The United States emerged as the lead contributor due to its high productivity and recognition levels. Stanford University, Johns Hopkins University, National University of Singapore, Mayo Clinic, University of Arizona, and University of Toronto were representative institutions in their respective fields. Cureus, JMIR Medical Education, Medical Teacher, and BMC Medical Education ranked as the top four most productive journals. The resulting heat map highlighted several high-frequency keywords, including performance, education, AI, and model. The citation burst time of terms revealed that AI technologies shifted from imaging processing (2000), augmented reality (2013), and virtual reality (2016) to decision-making (2020) and model (2021). Keywords such as mortality and robotic surgery persisted into 2023, suggesting the ongoing recognition and interest in these areas. Conclusions: This study provides valuable insights and guidance for researchers who are interested in educational technology, as well as recommendations for pioneering institutions and journal submissions. Along with the rapid growth of AI, medical education is expected to gain much more benefits.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/TY4E8WQN/e63775.html}
}

@article{liao2024fair,
  title = {{{FAIR Data Cube}}, a {{FAIR}} Data Infrastructure for Integrated Multi-Omics Data Analysis},
  author = {Liao, Xiaofeng and Ederveen, Thomas~H.A. and Niehues, Anna and {de~Visser}, Casper and Huang, Junda and Badmus, Firdaws and Doornbos, Cenna and Orlova, Yuliia and Kulkarni, Purva and {van~der~Velde}, K. Joeri and Swertz, Morris A. and Brandt, Martin and {van~Gool}, Alain J. and ’T Hoen, Peter A. C.},
  date = {2024-12-28},
  journaltitle = {Journal of Biomedical Semantics},
  shortjournal = {J Biomed Semant},
  volume = {15},
  number = {1},
  pages = {20},
  issn = {2041-1480},
  doi = {10.1186/s13326-024-00321-2},
  url = {https://jbiomedsem.biomedcentral.com/articles/10.1186/s13326-024-00321-2},
  urldate = {2025-01-04},
  abstract = {Motivation We are witnessing an enormous growth in the amount of molecular profiling (-omics) data. The integration of multi-omics data is challenging. Moreover, human multi-omics data may be privacy-sensitive and can be misused to de-anonymize and (re-)identify individuals. Hence, most biomedical data is kept in secure and protected silos. Therefore, it remains a challenge to re-use these data without infringing the privacy of the individuals from which the data were derived. Federated analysis of Findable, Accessible, Interoperable, and Reusable (FAIR) data is a privacypreserving solution to make optimal use of these multi-omics data and transform them into actionable knowledge. Results The Netherlands X-omics Initiative is a National Roadmap Large-Scale Research Infrastructure aiming for efficient integration of data generated within X-omics and external datasets. To facilitate this, we developed the FAIR Data Cube (FDCube), which adopts and applies the FAIR principles and helps researchers to create FAIR data and metadata, to facilitate re-use of their data, and to make their data analysis workflows transparent, and in the meantime ensure data security and privacy.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/SWMD5FTR/Liao et al. - 2024 - FAIR Data Cube, a FAIR data infrastructure for integrated multi-omics data analysis.pdf}
}

@article{mancohealer,
  title = {{{HEALER}}: {{A Data Lake Architecture}} for {{Healthcare}}},
  author = {Manco, Carlo and Dolci, Tommaso and Azzalini, Fabio and Barbierato, Enrico and Gribaudo, Marco and Tanca, Letizia},
  abstract = {With the growth of the Internet of Things and the rapid progress of social networks, everything appears to generate data. The ever-increasing number of connected devices is accompanied by a growth of the volume of data, produced at an ever-increasing rate, and this massive flow includes data types that are difficult to process using standard database techniques. One of the most critical scenarios is healthcare, whose activities need to store and manage a variety of data types – reports written in natural language, medical images, genomic data and waveforms of vital signs – which do not have a well-defined structure. In order to benefit from this large amount of complex data, Data Lakes have recently emerged as a solution to grant central storage and flexible analysis for all types of data. However, there is no Data Lake architecture that fits all the possible scenarios, since the architecture depends heavily on the application domain and, so far, there are no Data Lake architectures that support the specific needs of the healthcare domain. This work proposes HEALER: a Data Lake architecture that effectively performs data ingestion, data storage, and data access with the aim of providing a single central repository for efficient storage of different types of healthcare data. The architecture also enables the analysis and querying of the data, which can be loaded into the Data Lake regardless of their format and type. To verify the effectiveness of the architecture, a proof-of-concept of HEALER has been developed, that allows ingestion of various data, performs waveforms processing to make them more interpretable to researchers and analysts, grants access to the saved data and allows the analysis of natural language reports. Finally we studied the performance of the system in each of its main phases: ingestion, processing, data access and analysis. The results lead us to some important considerations to be taken into account when using and configuring the system components.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/TWCJ2CUD/Manco et al. - HEALER A Data Lake Architecture for Healthcare.pdf}
}

@report{mannotimpactanalyse,
  title = {Impactanalyse  AI-verordening},
  author = {Mannot, Pascal and family=Boer, given=Mona, prefix=de, useprefix=false},
  langid = {dutch},
  file = {/Users/dkapitan/Zotero/storage/S2CESI7J/Mannot - Met vriendelijke groet, PricewaterhouseCoopers Advisory N.V..pdf}
}

@article{mansouri-benssassi2023disclosure,
  title = {Disclosure Control of Machine Learning Models from Trusted Research Environments ({{TRE}}): {{New}} Challenges and Opportunities},
  shorttitle = {Disclosure Control of Machine Learning Models from Trusted Research Environments ({{TRE}})},
  author = {Mansouri-Benssassi, Esma and Rogers, Simon and Reel, Smarti and Malone, Maeve and Smith, Jim and Ritchie, Felix and Jefferson, Emily},
  date = {2023-04-01},
  journaltitle = {Heliyon},
  shortjournal = {Heliyon},
  volume = {9},
  number = {4},
  pages = {e15143},
  issn = {2405-8440},
  doi = {10.1016/j.heliyon.2023.e15143},
  url = {https://www.sciencedirect.com/science/article/pii/S2405844023023502},
  urldate = {2025-06-11},
  abstract = {Introduction Artificial intelligence (AI) applications in healthcare and medicine have increased in recent years. To enable access to personal data, Trusted Research Environments (TREs) (otherwise known as Safe Havens) provide safe and secure environments in which researchers can access sensitive personal data and develop AI (in particular machine learning (ML)) models. However, currently few TREs support the training of ML models in part due to a gap in the practical decision-making guidance for TREs in handling model disclosure. Specifically, the training of ML models creates a need to disclose new types of outputs from TREs. Although TREs have clear policies for the disclosure of statistical outputs, the extent to which trained models can leak personal training data once released is not well understood. Background We review, for a general audience, different types of ML models and their applicability within healthcare. We explain the outputs from training a ML model and how trained ML models can be vulnerable to external attacks to discover personal data encoded within the model. Risks We present the challenges for disclosure control of trained ML models in the context of training and exporting models from TREs. We provide insights and analyse methods that could be introduced within TREs to mitigate the risk of privacy breaches when disclosing trained models. Discussion Although specific guidelines and policies exist for statistical disclosure controls in TREs, they do not satisfactorily address these new types of output requests; i.e., trained ML models. There is significant potential for new interdisciplinary research opportunities in developing and adapting policies and tools for safely disclosing ML outputs from TREs.},
  keywords = {AI,Data privacy,Disclosure control,Machine learning,Safe haven,Trusted research environment},
  file = {/Users/dkapitan/Zotero/storage/3KFCB3T9/Mansouri-Benssassi et al. - 2023 - Disclosure control of machine learning models from trusted research environments (TRE) New challeng.pdf}
}

@online{martella2025designing,
  title = {Designing {{Data Spaces}}: {{Navigating}} the {{European Initiatives Along Technical Specifications}}},
  shorttitle = {Designing {{Data Spaces}}},
  author = {Martella, Angelo and Martella, Cristian and Longo, Antonella},
  date = {2025-03-20},
  eprint = {2503.15993},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2503.15993},
  url = {http://arxiv.org/abs/2503.15993},
  urldate = {2025-06-12},
  abstract = {The emerging paradigm of data economy can constitute an unmissable and attractive opportunity for companies that aim to consider their data as valuable assets. To fully leverage this opportunity, data owners need to have specific and precise guarantees regarding the protection of data they share from unauthorized access, but also from their misuse. Thus, it becomes crucial to provide mechanisms for secure and trusted data sharing capable of protecting data ownership rights and specifying agreed-upon methods of use. In this sense, data space technology can represent a promising and innovative solution in data management that aims to promote effective and trusted data exchange and sharing. By providing standardized technologies and legal frameworks, data spaces seek to eliminate barriers to data sharing among companies and organizations and, ultimately, fostering the development of innovative value-added services. By promoting interoperability and data sovereignty, data spaces play a crucial role in enhancing collaboration and innovation in the data economy. In this paper, the key European initiatives are collected and organized, with the goal of identifying the most recent advances in the direction of harmonizing the specifications, to facilitate the seamless integration between different solutions and foster secure, flexible and scalable data spaces implementations. The results of this study provide guidelines that can support data space designers in driving the choice of the most proper technical specifications to adopt, among the available open-source solutions.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases},
  file = {/Users/dkapitan/Zotero/storage/FFL78BU9/Martella et al. - 2025 - Designing Data Spaces Navigating the European Initiatives Along Technical Specifications.pdf}
}

@inproceedings{martinez2025framework,
  title = {A {{Framework}} for {{Staging Personal Health Trains}} in the {{Cloud}}},
  author = {Martinez, Virginia Graciano and Pires, Luís Ferreira and Santos, Luiz Olavo Bonino da Silva and Moreira, João Luiz Rebelo and Souza, Renata Guizzardi-Silva},
  date = {2025-06-11},
  pages = {133--144},
  url = {https://www.scitepress.org/Link.aspx?doi=10.5220/0010712800003058},
  urldate = {2025-06-11},
  abstract = {Digital Library},
  eventtitle = {17th {{International Conference}} on {{Web Information Systems}} and {{Technologies}}},
  isbn = {978-989-758-536-4},
  file = {/Users/dkapitan/Zotero/storage/NMUDIEWN/Martinez et al. - 2025 - A Framework for Staging Personal Health Trains in the Cloud.pdf;/Users/dkapitan/Zotero/storage/YRB8D83A/Link.html}
}

@online{mazumdar2023data,
  title = {The {{Data Lakehouse}}: {{Data Warehousing}} and {{More}}},
  shorttitle = {The {{Data Lakehouse}}},
  author = {Mazumdar, Dipankar and Hughes, Jason and Onofre, J. B.},
  date = {2023-10-12},
  eprint = {2310.08697},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.08697},
  urldate = {2024-01-11},
  abstract = {Relational Database Management Systems designed for Online Analytical Processing (RDBMS-OLAP) have been foundational to democratizing data and enabling analytical use cases such as business intelligence and reporting for many years. However, RDBMS-OLAP systems present some well-known challenges. They are primarily optimized only for relational workloads, lead to proliferation of data copies which can become unmanageable, and since the data is stored in proprietary formats, it can lead to vendor lock-in, restricting access to engines, tools, and capabilities beyond what the vendor offers. As the demand for data-driven decision making surges, the need for a more robust data architecture to address these challenges becomes ever more critical. Cloud data lakes have addressed some of the shortcomings of RDBMS-OLAP systems, but they present their own set of challenges. More recently, organizations have often followed a two-tier architectural approach to take advantage of both these platforms, leveraging both cloud data lakes and RDBMS-OLAP systems. However, this approach brings additional challenges, complexities, and overhead. This paper discusses how a data lakehouse, a new architectural approach, achieves the same benefits of an RDBMS-OLAP and cloud data lake combined, while also providing additional advantages. We take today's data warehousing and break it down into implementation independent components, capabilities, and practices. We then take these aspects and show how a lakehouse architecture satisfies them. Then, we go a step further and discuss what additional capabilities and benefits a lakehouse architecture provides over an RDBMS-OLAP.},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases},
  file = {/Users/dkapitan/Zotero/storage/IV9Y5T4V/Mazumdar et al. - 2023 - The Data Lakehouse Data Warehousing and More.pdf;/Users/dkapitan/Zotero/storage/AIKBHRKJ/2310.html}
}

@article{mcmurry2024cumulusa,
  title = {Cumulus: A Federated Electronic Health Record-Based Learning System Powered by {{Fast Healthcare Interoperability Resources}} and Artificial Intelligence},
  shorttitle = {Cumulus},
  author = {McMurry, Andrew J and Gottlieb, Daniel I and Miller, Timothy A and Jones, James R and Atreja, Ashish and Crago, Jennifer and Desai, Pankaja M and Dixon, Brian E and Garber, Matthew and Ignatov, Vladimir and Kirchner, Lyndsey A and Payne, Philip R O and Saldanha, Anil J and Shankar, Prabhu R V and Solad, Yauheni V and Sprouse, Elizabeth A and Terry, Michael and Wilcox, Adam B and Mandl, Kenneth D},
  date = {2024-08-01},
  journaltitle = {Journal of the American Medical Informatics Association},
  shortjournal = {Journal of the American Medical Informatics Association},
  volume = {31},
  number = {8},
  pages = {1638--1647},
  issn = {1527-974X},
  doi = {10.1093/jamia/ocae130},
  url = {https://doi.org/10.1093/jamia/ocae130},
  urldate = {2025-06-26},
  abstract = {To address challenges in large-scale electronic health record (EHR) data exchange, we sought to develop, deploy, and test an open source, cloud-hosted app “listener” that accesses standardized data across the SMART/HL7 Bulk FHIR Access application programming interface (API).We advance a model for scalable, federated, data sharing and learning. Cumulus software is designed to address key technology and policy desiderata including local utility, control, and administrative simplicity as well as privacy preservation during robust data sharing, and artificial intelligence (AI) for processing unstructured text.Cumulus relies on containerized, cloud-hosted software, installed within a healthcare organization’s security envelope. Cumulus accesses EHR data via the Bulk FHIR interface and streamlines automated processing and sharing. The modular design enables use of the latest AI and natural language processing tools and supports provider autonomy and administrative simplicity. In an initial test, Cumulus was deployed across 5 healthcare systems each partnered with public health. Cumulus output is patient counts which were aggregated into a table stratifying variables of interest to enable population health studies. All code is available open source. A policy stipulating that only aggregate data leave the institution greatly facilitated data sharing agreements.Cumulus addresses barriers to data sharing based on (1) federally required support for standard APIs, (2) increasing use of cloud computing, and (3) advances in AI. There is potential for scalability to support learning across myriad network configurations and use cases.},
  file = {/Users/dkapitan/Zotero/storage/D3T6DUWZ/ocae130.html}
}

@article{mehl2021who,
  title = {{{WHO SMART}} Guidelines: Optimising Country-Level Use of Guideline Recommendations in the Digital Age},
  shorttitle = {{{WHO SMART}} Guidelines},
  author = {Mehl, Garrett and Tunçalp, Özge and Ratanaprayul, Natschja and Tamrat, Tigest and Barreix, María and Lowrance, David and Bartolomeos, Kidist and Say, Lale and Kostanjsek, Nenad and Jakob, Robert and Grove, John and Mariano, Bernardo and Swaminathan, Soumya},
  date = {2021-04-01},
  journaltitle = {The Lancet Digital Health},
  shortjournal = {The Lancet Digital Health},
  volume = {3},
  number = {4},
  eprint = {33610488},
  eprinttype = {pubmed},
  pages = {e213-e216},
  publisher = {Elsevier},
  issn = {2589-7500},
  doi = {10.1016/S2589-7500(21)00038-8},
  url = {https://www.thelancet.com/journals/landig/article/PIIS2589-7500(21)00038-8/fulltext},
  urldate = {2023-06-21},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/ZQH6V9GJ/Mehl et al. - 2021 - WHO SMART guidelines optimising country-level use.pdf}
}

@article{mehl2023fullstac,
  title = {A Full-{{STAC}} Remedy for Global Digital Health Transformation: Open Standards, Technologies, Architectures and Content},
  shorttitle = {A Full-{{STAC}} Remedy for Global Digital Health Transformation},
  author = {Mehl, Garrett L and Seneviratne, Martin G and Berg, Matt L and Bidani, Suhel and Distler, Rebecca L and Gorgens, Marelize and Kallander, Karin E and Labrique, Alain B and Landry, Mark S and Leitner, Carl and Lubell-Doughtie, Peter B and Marcelo, Alvin D and Matias, Yossi and Nelson, Jennifer and Nguyen, Von and Nsengimana, Jean Philbert and Orton, Maeghan and Otzoy Garcia, Daniel R and Oyaole, Daniel R and Ratanaprayul, Natschja and Roth, Susann and Schaefer, Merrick P and Settle, Dykki and Tang, Jing and Tien-Wahser, Barakissa and Wanyee, Steven and Hersch, Fred},
  date = {2023-01-01},
  journaltitle = {Oxford Open Digital Health},
  shortjournal = {Oxford Open Digital Health},
  volume = {1},
  pages = {oqad018},
  issn = {2754-4591},
  doi = {10.1093/oodh/oqad018},
  url = {https://doi.org/10.1093/oodh/oqad018},
  urldate = {2024-02-09},
  abstract = {The global digital health ecosystem is project-centric: point solutions are developed for vertical health programs and financed through vertical funding allocations. This results in data fragmentation and technology lock-in, compromising health care delivery. A convergence of trends enabled by interoperability and digital governance makes possible a shift towards person-focused health. Together, open Standards, open Technologies, open Architectures and open Content represent a next-generation ‘full-STAC’ remedy for digital health transformation. Local developers and implementers can avoid reinventing the wheel, and instead build digital tools suited to local needs—where data travels with an individual over time, evidence-based practice is easily integrated, and insights are gleaned from harmonized data. This is the culmination of the vision endorsed by 194 WHO Member States in the Global Strategy on Digital Health 2020 to 2025.},
  file = {/Users/dkapitan/Zotero/storage/4D3EIB6H/Mehl et al. - 2023 - A full-STAC remedy for global digital health trans.pdf;/Users/dkapitan/Zotero/storage/9ILKUCUU/7475299.html}
}

@article{milne2022concentric,
  title = {A Concentric Circles View of Health Data Relations Facilitates Understanding of Sociotechnical Challenges for Learning Health Systems and the Role of Federated Data Networks},
  author = {Milne, Richard and Sheehan, Mark and Barnes, Brendan and Kapper, Janek and Lea, Nathan and N'Dow, James and Singh, Gurparkash and Martín-Uranga, Amelia and Hughes, Nigel},
  date = {2022-09-16},
  journaltitle = {Frontiers in Big Data},
  shortjournal = {Front. Big Data},
  volume = {5},
  publisher = {Frontiers},
  issn = {2624-909X},
  doi = {10.3389/fdata.2022.945739},
  url = {https://www.frontiersin.org/journals/big-data/articles/10.3389/fdata.2022.945739/full},
  urldate = {2025-03-11},
  abstract = {{$<$}p{$>$}The ability to use clinical and research data at scale is central to hopes for data-driven medicine. However, in using such data researchers often encounter hurdles–both technical, such as differing data security requirements, and social, such as the terms of informed consent, legal requirements and patient and public trust. Federated or distributed data networks have been proposed and adopted in response to these hurdles. However, to date there has been little consideration of how FDNs respond to both technical and social constraints on data use. In this Perspective we propose an approach to thinking about data in terms that make it easier to navigate the health data space and understand the value of differing approaches to data collection, storage and sharing. We set out a {$<$}italic{$>$}socio-technical{$<$}/italic{$>$} model of data systems that we call the “Concentric Circles View” (CCV) of data-relationships. The aim is to enable a consistent understanding of the fit between the local relationships within which data are produced and the extended socio-technical systems that enable their use. The paper suggests this model can help understand and tackle challenges associated with the use of real-world data in the health setting. We use the model to understand not only how but {$<$}italic{$>$}why{$<$}/italic{$>$} federated networks may be well placed to address emerging issues and adapt to the evolving needs of health research for patient benefit. We conclude that the CCV provides a useful model with broader application in mapping, understanding, and tackling the major challenges associated with using real world data in the health setting.{$<$}/p{$>$}},
  langid = {english},
  keywords = {Consent,Data,Distributed data access,Ethics,Federated data access},
  file = {/Users/dkapitan/Zotero/storage/EGIDJMR8/Milne et al. - 2022 - A concentric circles view of health data relations facilitates understanding of sociotechnical chall.pdf}
}

@article{milosevic2016open,
  title = {An Open Architecture for Event-Based Analytics},
  author = {Milosevic, Zoran and Chen, Weisi and Berry, Andrew and Rabhi, Fethi A.},
  date = {2016-12-01},
  journaltitle = {International Journal of Data Science and Analytics},
  shortjournal = {Int J Data Sci Anal},
  volume = {2},
  number = {1},
  pages = {13--27},
  issn = {2364-4168},
  doi = {10.1007/s41060-016-0029-7},
  url = {https://doi.org/10.1007/s41060-016-0029-7},
  urldate = {2025-06-30},
  abstract = {Event-based analytics is increasingly gaining prominence in business and social applications. Despite the availability of many solutions specializing in event processing systems (e.g. CEP technology), there is currently no commonly agreed way of describing event and event pattern types, and thus no standardized method for interchange of event pattern instances between systems. This paper advocates an open architecture for event-based analytics comprising a common model that supports interoperability of data between different systems. It introduces the foundational concepts for describing event patterns including events, event pattern types and event pattern occurrences. The event pattern meta-model is also formalized using a UML meta-model to facilitate its adoption and usage across the event analytics community. The paper provides a case study introducing several event pattern types from the financial market data analytics domain. This case study illustrates a number of specific event pattern types used by finance experts and an application that requires interoperability between two separate software component frameworks (a rule-based front-end and a CEP). Results show that the meta-model concepts are sufficient to represent and implement a class of real-life business analytics solutions. The paper also identified a number of semantic challenges in developing interoperability solutions for the event-based processing, in spite of the fact that we needed to merge only two separately developed event-based conceptual models.},
  langid = {english},
  keywords = {ADAGE,Building Information Modeling,Business Analytics,Complex event processing,Data Analytics,Data modelling,Enterprise Architecture,Event-based analytics,Information Model,Real-time analytics,Service-oriented architecture,Sport Analytics},
  file = {/Users/dkapitan/Zotero/storage/VMWDXMYN/Milosevic et al. - 2016 - An open architecture for event-based analytics.pdf}
}

@article{moncada-torres2021vantage6,
  title = {{{VANTAGE6}}: An Open Source {{priVAcy preserviNg federaTed leArninG infrastructurE}} for {{Secure Insight eXchange}}},
  shorttitle = {{{VANTAGE6}}},
  author = {Moncada-Torres, Arturo and Martin, Frank and Sieswerda, Melle and Van Soest, Johan and Geleijnse, Gijs},
  date = {2021-01-25},
  journaltitle = {AMIA Annual Symposium Proceedings},
  shortjournal = {AMIA Annu Symp Proc},
  volume = {2020},
  eprint = {33936462},
  eprinttype = {pubmed},
  pages = {870--877},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8075508/},
  urldate = {2024-09-21},
  abstract = {Answering many of the research questions in the field of cancer informatics requires incorporating and centralizing data that are hosted by different parties. Federated Learning (FL) has emerged as a new approach in which a global model can be generated without disclosing private patient data by keeping them at their original location. Flexible, user-friendly, and robust infrastructures are crucial for bringing FL solutions to the day-to-day work of the cancer epidemiologist. In this paper, we present an open source priVAcy preserviNg federaTed leArninG infrastructurE for Secure Insight eXchange, VANTAGE6. We provide a detailed description of its conceptual design, modular architecture, and components. We also show a few examples where VANTAGE6 has been successfully used in research on observational cancer data. Developing and deploying technology to support federated analyses~– such as VANTAGE6~– will pave the way for the adoption and mainstream practice of this new approach for analyzing decentralized data.},
  pmcid = {PMC8075508},
  file = {/Users/dkapitan/Zotero/storage/IBF6X9ZZ/Moncada-Torres et al. - 2021 - VANTAGE6 an open source priVAcy preserviNg federa.pdf}
}

@article{moore2023omezarr,
  title = {{{OME-Zarr}}: A Cloud-Optimized Bioimaging File Format with International Community Support},
  shorttitle = {{{OME-Zarr}}},
  author = {Moore, Josh and Basurto-Lozada, Daniela and Besson, Sébastien and Bogovic, John and Bragantini, Jordão and Brown, Eva M. and Burel, Jean-Marie and Casas Moreno, Xavier and family=Medeiros, given=Gustavo, prefix=de, useprefix=true and Diel, Erin E. and Gault, David and Ghosh, Satrajit S. and Gold, Ilan and Halchenko, Yaroslav O. and Hartley, Matthew and Horsfall, Dave and Keller, Mark S. and Kittisopikul, Mark and Kovacs, Gabor and Küpcü Yoldaş, Aybüke and Kyoda, Koji and family=Tournoulx de la Villegeorges, given=Albane, prefix=le, useprefix=true and Li, Tong and Liberali, Prisca and Lindner, Dominik and Linkert, Melissa and Lüthi, Joel and Maitin-Shepard, Jeremy and Manz, Trevor and Marconato, Luca and McCormick, Matthew and Lange, Merlin and Mohamed, Khaled and Moore, William and Norlin, Nils and Ouyang, Wei and Özdemir, Bugra and Palla, Giovanni and Pape, Constantin and Pelkmans, Lucas and Pietzsch, Tobias and Preibisch, Stephan and Prete, Martin and Rzepka, Norman and Samee, Sameeul and Schaub, Nicholas and Sidky, Hythem and Solak, Ahmet Can and Stirling, David R. and Striebel, Jonathan and Tischer, Christian and Toloudis, Daniel and Virshup, Isaac and Walczysko, Petr and Watson, Alan M. and Weisbart, Erin and Wong, Frances and Yamauchi, Kevin A. and Bayraktar, Omer and Cimini, Beth A. and Gehlenborg, Nils and Haniffa, Muzlifah and Hotaling, Nathan and Onami, Shuichi and Royer, Loic A. and Saalfeld, Stephan and Stegle, Oliver and Theis, Fabian J. and Swedlow, Jason R.},
  date = {2023-09-01},
  journaltitle = {Histochemistry and Cell Biology},
  shortjournal = {Histochem Cell Biol},
  volume = {160},
  number = {3},
  pages = {223--251},
  issn = {1432-119X},
  doi = {10.1007/s00418-023-02209-1},
  url = {https://doi.org/10.1007/s00418-023-02209-1},
  urldate = {2025-04-04},
  abstract = {A growing community is constructing a next-generation file format (NGFF) for bioimaging to overcome problems of scalability and heterogeneity. Organized by the Open Microscopy Environment (OME), individuals and institutes across diverse modalities facing these problems have designed a format specification process (OME-NGFF) to address these needs. This paper brings together a wide range of those community members to describe the cloud-optimized format itself—OME-Zarr—along with tools and data resources available today to increase FAIR access and remove barriers in the scientific process. The current momentum offers an opportunity to unify a key component of the bioimaging domain—the file format that underlies so many personal, institutional, and global data management and analysis tasks.},
  langid = {english},
  keywords = {Bioimaging,Cloud,Community,Data,FAIR,Format},
  file = {/Users/dkapitan/Zotero/storage/6WG992Q9/Moore et al. - 2023 - OME-Zarr a cloud-optimized bioimaging file format with international community support.pdf}
}

@report{mxi2024ai,
  title = {AI Monitor Ziekenhuizen 2024},
  author = {Gude, Wouter and family=Eekeren, given=Patrick, prefix=van, useprefix=true and Vasseur, Jordan},
  date = {2024},
  institution = {M\&I Partners},
  url = {https://mxi.nl/uploads/files/publication/ai-monitor-2024.pdf},
  langid = {dutch},
  file = {/Users/dkapitan/Zotero/storage/XUI9A4M3/Zeist - 2024 - AI Monitor Ziekenhuizen 2024.pdf}
}

@inproceedings{nahrstedt2024empirical,
  title = {An {{Empirical Study}} on the {{Energy Usage}} and {{Performance}} of {{Pandas}} and {{Polars Data Analysis Python Libraries}}},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{Evaluation}} and {{Assessment}} in {{Software Engineering}}},
  author = {Nahrstedt, Felix and Karmouche, Mehdi and Bargieł, Karolina and Banijamali, Pouyeh and Nalini Pradeep Kumar, Apoorva and Malavolta, Ivano},
  date = {2024-06-18},
  pages = {58--68},
  publisher = {ACM},
  location = {Salerno Italy},
  doi = {10.1145/3661167.3661203},
  url = {https://dl.acm.org/doi/10.1145/3661167.3661203},
  urldate = {2025-06-09},
  abstract = {Method. We performed four separate experiment blocks including 8 Data Analysis Tasks (DATs) from an official TPCH Benchmark done by Polars and 6 Synthetic DATs. Both DATs groups are run with small and large dataframes and for both libraries. Results. Polars is more energy-efficient than Pandas when manipulating large dataframes. For small dataframes, the TPCH Benchmarking DATs does not show significant differences, while for the Synthetic DATs, Polars performs significantly better. We identified strong positive correlations between energy usage and execution time, as well as memory usage for Pandas, while Polars did not show significant memory usage correlations for the majority of runs. There is a significantly negative correlation between energy usage and CPU usage for Pandas. Conclusions. We recommend using Polars for energy-efficient and fast data analysis, emphasizing the importance of CPU core utilization in library selection. ACM Reference Format: Felix Nahrstedt, Mehdi Karmouche, Karolina Bargieł, Pouyeh Banijamali, Apoorva Nalini Pradeep Kumar, and Ivano Malavolta. 2024. An Empirical Study on the Energy Usage and Performance of Pandas and Polars Data ∗These authors contributed equally to the study Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.},
  eventtitle = {{{EASE}} 2024: 28th {{International Conference}} on {{Evaluation}} and {{Assessment}} in {{Software Engineering}}},
  isbn = {979-8-4007-1701-7},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/8MRIRW27/Nahrstedt et al. - 2024 - An Empirical Study on the Energy Usage and Performance of Pandas and Polars Data Analysis Python Lib.pdf}
}

@article{nguyen2024preserving,
  title = {Preserving {{Privacy}} and {{Security}} in {{Federated Learning}}},
  author = {Nguyen, Truc and Thai, My T.},
  date = {2024-02},
  journaltitle = {IEEE/ACM Transactions on Networking},
  volume = {32},
  number = {1},
  pages = {833--843},
  issn = {1558-2566},
  doi = {10.1109/TNET.2023.3302016},
  url = {https://ieeexplore.ieee.org/abstract/document/10230990?casa_token=zDfZVLOccjEAAAAA:0j-V9O7Y4L36ELDLhYvO_8AKBb_p2GvVgChFfwoVialkWULXR4LDNA3XQA_aSIHwWCo4pVY-ag},
  urldate = {2025-02-26},
  abstract = {Federated learning is known to be vulnerable to both security and privacy issues. Existing research has focused either on preventing poisoning attacks from users or on concealing the local model updates from the server, but not both. However, integrating these two lines of research remains a crucial challenge since they often conflict with one another with respect to the threat model. In this work, we develop a principle framework that offers both privacy guarantees for users and detection against poisoning attacks from them. With a new threat model that includes both an honest-but-curious server and malicious users, we first propose a secure aggregation protocol using homomorphic encryption for the server to combine local model updates in a private manner. Then, a zero-knowledge proof protocol is leveraged to shift the task of detecting attacks in the local models from the server to the users. The key observation here is that the server no longer needs access to the local models for attack detection. Therefore, our framework enables the central server to identify poisoned model updates without violating the privacy guarantees of secure aggregation.},
  eventtitle = {{{IEEE}}/{{ACM Transactions}} on {{Networking}}},
  keywords = {Computational modeling,Federated learning,homomorphic encryption,model poisoning,Privacy,Protocols,Security,Servers,Training,zero-knowledge proof},
  file = {/Users/dkapitan/Zotero/storage/3LXNYXIL/Nguyen and Thai - 2024 - Preserving Privacy and Security in Federated Learning.pdf;/Users/dkapitan/Zotero/storage/NU95CMZW/10230990.html}
}

@article{nijsse2022fair,
  title = {{{FAIR}} Data Station for Lightweight Metadata Management and Validation of Omics Studies},
  author = {Nijsse, Bart and Schaap, Peter J. and Koehorst, Jasper J.},
  date = {2022-12-28},
  journaltitle = {GigaScience},
  shortjournal = {Gigascience},
  volume = {12},
  publisher = {Oxford Academic},
  doi = {10.1093/gigascience/giad014},
  url = {https://dx.doi.org/10.1093/gigascience/giad014},
  urldate = {2025-06-10},
  abstract = {AbstractBackground. The life sciences are one of the biggest suppliers of scientific data. Reusing and connecting these data can uncover hidden insights an},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/6ZMHAH44/Nijsse et al. - 2022 - FAIR data station for lightweight metadata management and validation of omics studies.pdf}
}

@online{odrl,
  title = {{{ODRL Information Model}} 2.2},
  url = {https://www.w3.org/TR/odrl-model/},
  urldate = {2025-06-30},
  file = {/Users/dkapitan/Zotero/storage/TN69EZEM/odrl-model.html}
}

@article{opend,
  title = {Open {{Business Data Lake}} ({{O-BDL}})},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/TM7LK39E/Open Business Data Lake (O-BDL).pdf}
}

@online{padme,
  title = {{{PADME}} | {{Platform}} for {{Analytics}} and {{Distributed Machine Learning}} for {{Enterprises}}},
  url = {https://padme-analytics.de/},
  urldate = {2025-06-30},
  file = {/Users/dkapitan/Zotero/storage/YSIUR7E7/padme-analytics.de.html}
}

@article{pedreira2023composable,
  title = {The {{Composable Data Management System Manifesto}}},
  author = {Pedreira, Pedro and Erling, Orri and Karanasos, Konstantinos and Schneider, Scott and McKinney, Wes and Valluri, Satya R and Zait, Mohamed and Nadeau, Jacques},
  date = {2023-06},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {16},
  number = {10},
  pages = {2679--2685},
  issn = {2150-8097},
  doi = {10.14778/3603581.3603604},
  url = {https://dl.acm.org/doi/10.14778/3603581.3603604},
  urldate = {2023-12-27},
  abstract = {The requirement for specialization in data management systems has evolved faster than our software development practices. After decades of organic growth, this situation has created a siloed landscape composed of hundreds of products developed and maintained as monoliths, with limited reuse between systems. This fragmentation has resulted in developers often reinventing the wheel, increased maintenance costs, and slowed down innovation. It has also affected the end users, who are often required to learn the idiosyncrasies of dozens of incompatible SQL and non-SQL API dialects, and settle for systems with incomplete functionality and inconsistent semantics. In this vision paper, considering the recent popularity of open source projects aimed at standardizing different aspects of the data stack, we advocate for a paradigm shift in how data management systems are designed. We believe that by decomposing these into a modular stack of reusable components, development can be streamlined while creating a more consistent experience for users. Towards that goal, we describe the state-ofthe-art, principal open source technologies, and highlight open questions and areas where additional research is needed. We hope this work will foster collaboration, motivate further research, and promote a more composable future for data management.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/SVVTZQSR/Pedreira et al. - 2023 - The Composable Data Management System Manifesto.pdf}
}

@inproceedings{pereira2025comparison,
  title = {Comparison of~{{eHealth Interoperability Standards}}: {{HL7 FHIR}}, {{OpenEHR}}, and~{{CDISC}}},
  shorttitle = {Comparison of~{{eHealth Interoperability Standards}}},
  booktitle = {The 18th {{International Conference Interdisciplinarity}} in {{Engineering}}},
  author = {Pereira, José D. and Frade, Samuel and Ribeiro, Rui and Santos, Manuel and Brito, Miguel A. and Machado, Ricardo J.},
  editor = {Moldovan, Liviu and Gligor, Adrian},
  date = {2025},
  pages = {241--249},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-81685-7_18},
  abstract = {This paper is a complete description and comparison of some of the most cited eHealth interoperability standards in the literature, openEHR, HL7 FHIR and CDISC. We searched the Scopus database using the keywords interoperability, information systems, and health. It was found that standards are needed to develop interoperability platforms for eHealth. We carried out additional research on the most cited standards, allowing us to analyze the characteristics and particularities of each one and make comparisons. As a result of this work, we defined a list of comparison criteria and evaluated the differences between these standards based on these criteria. The standards compared have some common characteristics, but they also have unique features for each of them, so the selection of the standard to use will depend on the characteristics and requirements of the eHealth platform you want to develop.},
  isbn = {978-3-031-81685-7},
  langid = {english},
  keywords = {CDISC,Comparison,EHealth,HL7 FHIR,openEHR,Standards},
  file = {/Users/dkapitan/Zotero/storage/L8IELE5M/Pereira et al. - 2025 - Comparison of eHealth Interoperability Standards HL7 FHIR, OpenEHR, and CDISC.pdf}
}

@article{prainsack2023beyond,
  title = {Beyond {{Individual Rights}}: {{How Data Solidarity Gives People Meaningful Control}} over {{Data}}},
  shorttitle = {Beyond {{Individual Rights}}},
  author = {Prainsack, Barbara and El-Sayed, Seliem},
  date = {2023-11-02},
  journaltitle = {The American Journal of Bioethics},
  shortjournal = {The American Journal of Bioethics},
  volume = {23},
  number = {11},
  pages = {36--39},
  issn = {1526-5161, 1536-0075},
  doi = {10.1080/15265161.2023.2256267},
  url = {https://www.tandfonline.com/doi/full/10.1080/15265161.2023.2256267},
  urldate = {2023-11-11},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/T542DFXH/prainsack2023beyond.pdf}
}

@article{queralt-rosinach2022applying,
  title = {Applying the {{FAIR}} Principles to Data in a Hospital: Challenges and Opportunities in a Pandemic},
  shorttitle = {Applying the {{FAIR}} Principles to Data in a Hospital},
  author = {Queralt-Rosinach, Núria and Kaliyaperumal, Rajaram and Bernabé, César H. and Long, Qinqin and Joosten, Simone A. and family=Wijk, given=Henk Jan, prefix=van der, useprefix=true and Flikkenschild, Erik L.A. and Burger, Kees and Jacobsen, Annika and Mons, Barend and Roos, Marco and {BEAT-COVID Group} and {COVID-19 LUMC Group}},
  date = {2022-04-25},
  journaltitle = {Journal of Biomedical Semantics},
  shortjournal = {Journal of Biomedical Semantics},
  volume = {13},
  number = {1},
  pages = {12},
  issn = {2041-1480},
  doi = {10.1186/s13326-022-00263-7},
  url = {https://doi.org/10.1186/s13326-022-00263-7},
  urldate = {2025-06-11},
  abstract = {The COVID-19 pandemic has challenged healthcare systems and research worldwide. Data is collected all over the world and needs to be integrated and made available to other researchers quickly. However, the various heterogeneous information systems that are used in hospitals can result in fragmentation of health data over multiple data ‘silos’ that are not interoperable for analysis. Consequently, clinical observations in hospitalised patients are not prepared to be reused efficiently and timely. There is a need to adapt the research data management in hospitals to make COVID-19 observational patient data machine actionable, i.e. more Findable, Accessible, Interoperable and Reusable (FAIR) for humans and machines. We therefore applied the FAIR principles in the hospital to make patient data more FAIR.},
  keywords = {FAIR,Hospital,Ontologies,Open science,Patient data,Research data management},
  file = {/Users/dkapitan/Zotero/storage/TNNJGUKZ/Queralt-Rosinach et al. - 2022 - Applying the FAIR principles to data in a hospital challenges and opportunities in a pandemic.pdf;/Users/dkapitan/Zotero/storage/S579ATQU/s13326-022-00263-7.html}
}

@article{quiroz2022extract,
  title = {Extract, Transform, Load Framework for the Conversion of Health Databases to {{OMOP}}},
  author = {Quiroz, Juan C. and Chard, Tim and Sa, Zhisheng and Ritchie, Angus and Jorm, Louisa and Gallego, Blanca},
  date = {2022-04-11},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS One},
  volume = {17},
  number = {4},
  eprint = {35404974},
  eprinttype = {pubmed},
  pages = {e0266911},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0266911},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9000122/},
  urldate = {2025-07-01},
  abstract = {Common data models standardize the structures and semantics of health datasets, enabling reproducibility and large-scale studies that leverage the data from multiple locations and settings. The Observational Medical Outcomes Partnership Common Data Model (OMOP CDM) is one of the leading common data models. While there is a strong incentive to convert datasets to OMOP, the conversion is time and resource-intensive, leaving the research community in need of tools for mapping data to OMOP. We propose an extract, transform, load (ETL) framework that is metadata-driven and generic across source datasets. The ETL framework uses a new data manipulation language (DML) that organizes SQL snippets in YAML. Our framework includes a compiler that converts YAML files with mapping logic into an ETL script. Access to the ETL framework is available via a web application, allowing users to upload and edit YAML files via web editor and obtain an ETL SQL script for use in development environments. The structure of the DML maximizes readability, refactoring, and maintainability, while minimizing technical debt and standardizing the writing of ETL operations for mapping to OMOP. Our framework also supports transparency of the mapping process and reuse by different institutions.},
  pmcid = {PMC9000122},
  file = {/Users/dkapitan/Zotero/storage/HSIZSSFR/Quiroz et al. - 2022 - Extract, transform, load framework for the conversion of health databases to OMOP.pdf}
}

@article{raab2023federated,
  title = {Federated Electronic Health Records for the {{European Health Data Space}}},
  author = {Raab, René and Küderle, Arne and Zakreuskaya, Anastasiya and Stern, Ariel D. and Klucken, Jochen and Kaissis, Georgios and Rueckert, Daniel and Boll, Susanne and Eils, Roland and Wagener, Harald and Eskofier, Bjoern M.},
  date = {2023-11},
  journaltitle = {The Lancet. Digital Health},
  shortjournal = {Lancet Digit Health},
  volume = {5},
  number = {11},
  eprint = {37741765},
  eprinttype = {pubmed},
  pages = {e840-e847},
  issn = {2589-7500},
  doi = {10.1016/S2589-7500(23)00156-5},
  abstract = {The European Commission's draft for the European Health Data Space (EHDS) aims to empower citizens to access their personal health data and share it with physicians and other health-care providers. It further defines procedures for the secondary use of electronic health data for research and development. Although this planned legislation is undoubtedly a step in the right direction, implementation approaches could potentially result in centralised data silos that pose data privacy and security risks for individuals. To address this concern, we propose federated personal health data spaces, a novel architecture for storing, managing, and sharing personal electronic health records that puts citizens at the centre-both conceptually and technologically. The proposed architecture puts citizens in control by storing personal health data on a combination of personal devices rather than in centralised data silos. We describe how this federated architecture fits within the EHDS and can enable the same features as centralised systems while protecting the privacy of citizens. We further argue that increased privacy and control do not contradict the use of electronic health data for research and development. Instead, data sovereignty and transparency encourage active participation in studies and data sharing. This combination of privacy-by-design and transparent, privacy-preserving data sharing can enable health-care leaders to break the privacy-exploitation barrier, which currently limits the secondary use of health data in many cases.},
  langid = {english},
  keywords = {Computer Security,Delivery of Health Care,Electronic Health Records,Humans,Physicians,Privacy},
  file = {/Users/dkapitan/Zotero/storage/KNN6MPCE/Raab et al. - 2023 - Federated electronic health records for the European Health Data Space.pdf}
}

@inproceedings{raasveldt2019duckdb,
  title = {{{DuckDB}}: An {{Embeddable Analytical Database}}},
  shorttitle = {{{DuckDB}}},
  booktitle = {Proceedings of the 2019 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Raasveldt, Mark and Mühleisen, Hannes},
  date = {2019-06-25},
  pages = {1981--1984},
  publisher = {ACM},
  location = {Amsterdam Netherlands},
  doi = {10.1145/3299869.3320212},
  url = {https://dl.acm.org/doi/10.1145/3299869.3320212},
  urldate = {2025-06-09},
  abstract = {The immense popularity of SQLite shows that there is a need for unobtrusive in-process data management solutions. However, there is no such system yet geared towards analytical workloads. We demonstrate DuckDB, a novel data management system designed to execute analytical SQL queries while embedded in another process. In our demonstration, we pit DuckDB against other data management solutions to showcase its performance in the embedded analytics scenario. DuckDB is available as Open Source software under a permissive license.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '19: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-5643-5},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/DF6EFTJR/Raasveldt and Mühleisen - 2019 - DuckDB an Embeddable Analytical Database.pdf}
}

@article{riedel2024comparative,
  title = {Comparative Analysis of Open-Source Federated Learning Frameworks - a Literature-Based Survey and Review},
  author = {Riedel, Pascal and Schick, Lukas and family=Schwerin, given=Reinhold, prefix=von, useprefix=true and Reichert, Manfred and Schaudt, Daniel and Hafner, Alexander},
  date = {2024-11-01},
  journaltitle = {International Journal of Machine Learning and Cybernetics},
  shortjournal = {Int. J. Mach. Learn. \& Cyber.},
  volume = {15},
  number = {11},
  pages = {5257--5278},
  issn = {1868-808X},
  doi = {10.1007/s13042-024-02234-z},
  url = {https://doi.org/10.1007/s13042-024-02234-z},
  urldate = {2025-03-12},
  abstract = {While Federated Learning (FL) provides a privacy-preserving approach to analyze sensitive data without centralizing training data, the field lacks an detailed comparison of emerging open-source FL frameworks. Furthermore, there is currently no standardized, weighted evaluation scheme for a fair comparison of FL frameworks that would support the selection of a suitable FL framework. This study addresses these research gaps by conducting a comparative analysis of 15 individual open-source FL frameworks filtered by two selection criteria, using the literature review methodology proposed by Webster and Watson. These framework candidates are compared using a novel scoring schema with 15 qualitative and quantitative evaluation criteria, focusing on features, interoperability, and user friendliness. The evaluation results show that the FL framework Flower outperforms its peers with an overall score of 84.75\%, while Fedlearner lags behind with a total score of 24.75\%. The proposed comparison suite offers valuable initial guidance for practitioners and researchers in selecting an FL framework for the design and development of FL-driven systems. In addition, the FL framework comparison suite is designed to be adaptable and extendable accommodating the inclusion of new FL frameworks and evolving requirements.},
  langid = {english},
  keywords = {Artificial Intelligence,Federated learning,Framework comparison,Machine learning,Open source,Privacy},
  file = {/Users/dkapitan/Zotero/storage/UQ59Z4XJ/Riedel et al. - 2024 - Comparative analysis of open-source federated learning frameworks - a literature-based survey and re.pdf}
}

@article{rieke2020future,
  title = {The Future of Digital Health with Federated Learning},
  author = {Rieke, Nicola and Hancox, Jonny and Li, Wenqi and Milletarì, Fausto and Roth, Holger R. and Albarqouni, Shadi and Bakas, Spyridon and Galtier, Mathieu N. and Landman, Bennett A. and Maier-Hein, Klaus and Ourselin, Sébastien and Sheller, Micah and Summers, Ronald M. and Trask, Andrew and Xu, Daguang and Baust, Maximilian and Cardoso, M. Jorge},
  date = {2020-09-14},
  journaltitle = {npj Digital Medicine},
  shortjournal = {npj Digit. Med.},
  volume = {3},
  number = {1},
  pages = {1--7},
  publisher = {Nature Publishing Group},
  issn = {2398-6352},
  doi = {10.1038/s41746-020-00323-1},
  url = {https://www.nature.com/articles/s41746-020-00323-1},
  urldate = {2023-04-23},
  abstract = {Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing medical data is not fully exploited by ML primarily because it sits in data silos and privacy concerns restrict access to this data. However, without access to sufficient data, ML will be prevented from reaching its full potential and, ultimately, from making the transition from research to clinical practice. This paper considers key factors contributing to this issue, explores how federated learning (FL) may provide a solution for the future of digital health and highlights the challenges and considerations that need to be addressed.},
  issue = {1},
  langid = {english},
  keywords = {Medical imaging,Medical research},
  file = {/Users/dkapitan/Zotero/storage/DJI9BHQP/Rieke et al. - 2020 - The future of digital health with federated learni.pdf}
}

@incollection{rinaldi2023international,
  title = {International {{Clinical Research Data Ecosystem}}: {{From Data Standardization}} to {{Federated Analysis}}},
  shorttitle = {International {{Clinical Research Data Ecosystem}}},
  booktitle = {Telehealth {{Ecosystems}} in {{Practice}}},
  author = {Rinaldi, Eugenia and Dellacasa, Chiara and Puskaric, Miroslav and Osmo, Thomas and Gorska, Anna and Stellmach, Caroline},
  date = {2023},
  pages = {133--134},
  publisher = {IOS Press},
  doi = {10.3233/SHTI230757},
  url = {https://ebooks.iospress.nl/doi/10.3233/SHTI230757},
  urldate = {2025-06-11},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/V9I4G94C/Rinaldi et al. - 2023 - International Clinical Research Data Ecosystem From Data Standardization to Federated Analysis.pdf}
}

@article{riviera2023felebrities,
  title = {{{FeLebrities}}: {{A User-Centric Assessment}} of {{Federated Learning Frameworks}}},
  shorttitle = {{{FeLebrities}}},
  author = {Riviera, Walter and Galazzo, Ilaria Boscolo and Menegaz, Gloria},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {96865--96878},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3312579},
  url = {https://ieeexplore.ieee.org/ielx7/6287639/10005208/10242027.pdf},
  urldate = {2025-06-24},
  abstract = {Federated Learning (FL) is a new paradigm aimed at solving data access problems. It provides a solution by moving the focus from sharing data to sharing models. The FL paradigm involves different entities (institutions) holding proprietary datasets that, contributing with each other to train a global Artificial Intelligence (AI) model using their own locally available data. Although several studies have proposed methods to distribute the computation or aggregate results, few efforts have been made to cover on how to implement FL pipelines. With the aim of accelerating the exploitation of FL frameworks, this paper proposes a survey of public tools that are currently available for building FL pipelines, an objective ranking based on the current state of user preferences, and an assessment of the growing trend of the tool’s popularity over a one year time window, with measurements performed every six months. These measurements include objective metrics, like the number of “Watch,” “Star” and “Follow” available from software repositories as well as thirteen custom metrics grouped into three main categories: Usability, Portability, and Flexibility. Finally, a ranking of the maturity of the tools is derived based on the key aspects to consider when building a FL pipeline.},
  keywords = {AI at scale,Artificial intelligence,Computational modeling,Data models,Distributed management,distributed systems,Federated learning,Federated learning tools,Guidelines,Surveys},
  file = {/Users/dkapitan/Zotero/storage/H3KEUTSJ/Riviera et al. - 2023 - FeLebrities A User-Centric Assessment of Federated Learning Frameworks.pdf}
}

@incollection{rosenau2024structured,
  title = {Structured {{Queries}} to {{AQL}}: {{Querying OpenEHR Data Leveraging}} a {{FHIR-Based Infrastructure}} for {{Federated Feasibility Queries}}},
  shorttitle = {Structured {{Queries}} to {{AQL}}},
  booktitle = {{{MEDINFO}} 2023 — {{The Future Is Accessible}}},
  author = {Rosenau, Lorenz and Ingenerf, Josef},
  date = {2024},
  pages = {33--37},
  publisher = {IOS Press},
  doi = {10.3233/SHTI230922},
  url = {https://ebooks.iospress.nl/doi/10.3233/SHTI230922},
  urldate = {2025-04-10},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/KH87VJ5J/Rosenau and Ingenerf - 2024 - Structured Queries to AQL Querying OpenEHR Data Leveraging a FHIR-Based Infrastructure for Federate.pdf}
}

@incollection{rosenau2024structureda,
  title = {Structured {{Queries}} to {{AQL}}: {{Querying OpenEHR Data Leveraging}} a {{FHIR-Based Infrastructure}} for {{Federated Feasibility Queries}}},
  shorttitle = {Structured {{Queries}} to {{AQL}}},
  booktitle = {Studies in {{Health Technology}} and {{Informatics}}},
  author = {Rosenau, Lorenz and Ingenerf, Josef},
  editor = {Bichel-Findlay, Jen and Otero, Paula and Scott, Philip and Huesing, Elaine},
  date = {2024-01-25},
  publisher = {IOS Press},
  doi = {10.3233/SHTI230922},
  url = {https://ebooks.iospress.nl/doi/10.3233/SHTI230922},
  urldate = {2025-06-11},
  abstract = {In digital healthcare, data heterogeneity is a reoccurring issue caused by proprietary source systems. It is often overcome by utilizing ETL processes resulting in data warehouses, which ensure common data models for interoperability. Unfortunately, the achieved interoperability is usually limited to an institutional level. The broad solution space to achieve interoperability with different health data standards is part of the problem, resulting in different standards used at various institutions. For cross-institutional use cases like federated feasibility queries, the issue of heterogeneity is reintroduced. This work showcases how the existing German infrastructure for federated feasibility queries based on Hl7 FHIR can be extended to support openEHR without further data transformation. By utilizing an intermediate query format that can be transferred to FHIR Search, CQL, and AQL.},
  isbn = {978-1-64368-456-7 978-1-64368-457-4},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/CX272RB6/Rosenau and Ingenerf - 2024 - Structured Queries to AQL Querying OpenEHR Data Leveraging a FHIR-Based Infrastructure for Federate.pdf}
}

@report{royalsociety2023privacy,
  title = {From Privacy to Partnership},
  date = {2023-01},
  institution = {The Royal Society},
  file = {/Users/dkapitan/Zotero/storage/N7XUTWRD/From Privacy to Partnership.pdf}
}

@article{saeed2025comprehensive,
  title = {Comprehensive Review of Federated Learning Challenges: A Data Preparation Viewpoint},
  shorttitle = {Comprehensive Review of Federated Learning Challenges},
  author = {Saeed, Nawraz and Ashour, Mohamed and Mashaly, Maggie},
  date = {2025-06-23},
  journaltitle = {Journal of Big Data},
  shortjournal = {Journal of Big Data},
  volume = {12},
  number = {1},
  pages = {153},
  issn = {2196-1115},
  doi = {10.1186/s40537-025-01195-6},
  url = {https://doi.org/10.1186/s40537-025-01195-6},
  urldate = {2025-06-30},
  abstract = {Machine learning model accuracy, generalization, and reliability are greatly affected by the training data quality. High-quality data-characterized by completeness, consistency, accuracy, representativeness and homogeneity enables meaningful pattern learning and robust prediction. In federated learning (FL), the learning process is collaborative and conducted across decentralized and locally private data nodes. The heterogeneity of data across these nodes degrade model performance and may lead to overfitting, underfitting, and erroneous decision-making. Heterogeneity is caused by inconsistent labeling, missing values, and class imbalances across these nodes. Proper data preparation, including cleaning, normalization, and augmentation, is essential to mitigate these issues and ensure that these distributed datasets reflect the problem domain accurately. The raw data, which is generated from diverse sources with the fundamental constraint that this data cannot be shared among learning nodes exacerbates these challenges. Although data preparation has received great interest in recent years; little attention has been given to data challenges posed when FL is used. Although some surveys mention FL challenges, it is discussed superficially. These papers predominantly focus on one aspect of data challenges such as quality, homogeneity or balance discussing FL within the context of these specific challenges. No recent survey examine all data-related challenges in FL, including their interdependencies and interactions. To address these limitations, the main contribution of this paper is providing a comprehensive overview of data challenges in FL, encompassing data heterogeneity, skewness, representation, quality, bias, and fairness. The paper begins by identifying the data challenges highlighted in the existing literature, with a particular focus on the interrelationships among these challenges, which are categorized into two main groups: non-independently and non-identically distributed (Non-IID) data issues and data quality issues. Subsequently, the paper reviews and compares recognized data challenges solution approaches exploring additional data preparation techniques that could serve as candidate solutions. The paper aims to define the necessary work to optimize the effectiveness of these techniques with respect to distributed and isolated data in FL.},
  keywords = {Data preparation,Distributed data,Federated learning,Heterogeneity},
  file = {/Users/dkapitan/Zotero/storage/STZIXEQ7/Saeed et al. - 2025 - Comprehensive review of federated learning challenges a data preparation viewpoint.pdf;/Users/dkapitan/Zotero/storage/JZ6WTCR8/s40537-025-01195-6.html}
}

@article{sansone2012interoperable,
  title = {Toward Interoperable Bioscience Data},
  author = {Sansone, Susanna-Assunta and Rocca-Serra, Philippe and Field, Dawn and Maguire, Eamonn and Taylor, Chris and Hofmann, Oliver and Fang, Hong and Neumann, Steffen and Tong, Weida and Amaral-Zettler, Linda and Begley, Kimberly and Booth, Tim and Bougueleret, Lydie and Burns, Gully and Chapman, Brad and Clark, Tim and Coleman, Lee-Ann and Copeland, Jay and Das, Sudeshna and family=Daruvar, given=Antoine, prefix=de, useprefix=true and family=Matos, given=Paula, prefix=de, useprefix=true and Dix, Ian and Edmunds, Scott and Evelo, Chris T. and Forster, Mark J. and Gaudet, Pascale and Gilbert, Jack and Goble, Carole and Griffin, Julian L. and Jacob, Daniel and Kleinjans, Jos and Harland, Lee and Haug, Kenneth and Hermjakob, Henning and Sui, Shannan J. Ho and Laederach, Alain and Liang, Shaoguang and Marshall, Stephen and McGrath, Annette and Merrill, Emily and Reilly, Dorothy and Roux, Magali and Shamu, Caroline E. and Shang, Catherine A. and Steinbeck, Christoph and Trefethen, Anne and Williams-Jones, Bryn and Wolstencroft, Katherine and Xenarios, Ioannis and Hide, Winston},
  date = {2012-02},
  journaltitle = {Nature Genetics},
  shortjournal = {Nat Genet},
  volume = {44},
  number = {2},
  pages = {121--126},
  publisher = {Nature Publishing Group},
  issn = {1546-1718},
  doi = {10.1038/ng.1054},
  url = {https://www.nature.com/articles/ng.1054},
  urldate = {2025-06-23},
  abstract = {To make full use of research data, the bioscience community needs to adopt technologies and reward mechanisms that support interoperability and promote the growth of an open 'data commoning' culture. Here we describe the prerequisites for data commoning and present an established and growing ecosystem of solutions using the shared 'Investigation-Study-Assay' framework to support that vision.},
  langid = {english},
  keywords = {Research data},
  file = {/Users/dkapitan/Zotero/storage/7CEPP88H/Sansone et al. - 2012 - Toward interoperable bioscience data.pdf}
}

@article{schmidt2024mappinga,
  title = {Mapping the Regulatory Landscape for Artificial Intelligence in Health within the {{European Union}}},
  author = {Schmidt, Jelena and Schutte, Nienke M. and Buttigieg, Stefan and Novillo-Ortiz, David and Sutherland, Eric and Anderson, Michael and family=Witte, given=Bart, prefix=de, useprefix=true and Peolsson, Michael and Unim, Brigid and Pavlova, Milena and Stern, Ariel Dora and Mossialos, Elias and family=Kessel, given=Robin, prefix=van, useprefix=true},
  date = {2024-08-27},
  journaltitle = {npj Digital Medicine},
  shortjournal = {npj Digit. Med.},
  volume = {7},
  number = {1},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {2398-6352},
  doi = {10.1038/s41746-024-01221-6},
  url = {https://www.nature.com/articles/s41746-024-01221-6},
  urldate = {2025-01-18},
  abstract = {Regulatory frameworks for artificial intelligence (AI) are needed to mitigate risks while ensuring the ethical, secure, and effective implementation of AI technology in healthcare and population health. In this article, we present a synthesis of 141 binding policies applicable to AI in healthcare and population health in the EU and 10 European countries. The EU AI Act sets the overall regulatory framework for AI, while other legislations set social, health, and human rights standards, address the safety of technologies and the implementation of innovation, and ensure the protection and safe use of data. Regulation specifically pertaining to AI is still nascent and scarce, though a combination of data, technology, innovation, and health and human rights policy has already formed a baseline regulatory framework for AI in health. Future work should explore specific regulatory challenges, especially with respect to AI medical devices, data protection, and data enablement.},
  langid = {english},
  keywords = {Health policy,Information technology,Law,Public health},
  file = {/Users/dkapitan/Zotero/storage/8QTTM7QB/Schmidt et al. - 2024 - Mapping the regulatory landscape for artificial intelligence in health within the European Union.pdf}
}

@article{schneider2024lakehouse,
  title = {The {{Lakehouse}}: {{State}} of the {{Art}} on {{Concepts}} and {{Technologies}}},
  shorttitle = {The {{Lakehouse}}},
  author = {Schneider, Jan and Gröger, Christoph and Lutsch, Arnold and Schwarz, Holger and Mitschang, Bernhard},
  date = {2024-04-18},
  journaltitle = {SN Computer Science},
  shortjournal = {SN COMPUT. SCI.},
  volume = {5},
  number = {5},
  pages = {449},
  issn = {2661-8907},
  doi = {10.1007/s42979-024-02737-0},
  url = {https://doi.org/10.1007/s42979-024-02737-0},
  urldate = {2025-03-16},
  abstract = {In the context of data analytics, so-called lakehouses refer to novel variants of data platforms that attempt to combine characteristics of data warehouses and data lakes. In this way, lakehouses promise to simplify enterprise analytics architectures, which often suffer from high operational costs, slow analytical processes and further shortcomings resulting from data replication. However, different views and notions on the lakehouse paradigm exist, which are commonly driven by individual technologies and varying analytical use cases. Therefore, it remains unclear what challenges lakehouses address, how they can be characterized and which technologies can be leveraged to implement them. This paper addresses these issues by providing an extensive overview of concepts and technologies that are related to the lakehouse paradigm and by outlining lakehouses as a distinct architectural approach for data platforms. Concepts and technologies from literature with regard to lakehouses are discussed, based on which a conceptual foundation for lakehouses is established. In addition, several popular technologies are evaluated regarding their suitability for the building of lakehouses. All findings are supported and demonstrated with the help of a representative analytics scenario. Typical challenges of conventional data platforms are identified, a new, sharper definition for lakehouses is proposed and technical requirements for lakehouses are derived. As part of an evaluation, these requirements are applied to several popular technologies, of which frameworks for data lakes turn out to be particularly helpful for the construction of lakehouses. Our work provides an overview of the state of the art and a conceptual foundation for the lakehouse paradigm, which can support future research.},
  langid = {english},
  keywords = {Data analytics,Data lake,Data lakehouse,Data platform},
  file = {/Users/dkapitan/Zotero/storage/PKXBJ9LC/Schneider et al. - 2024 - The Lakehouse State of the Art on Concepts and Technologies.pdf}
}

@article{schoonderbeek2024ontology,
  title = {Toward an Ontology for {{EA}} Modeling and {{EA}} Model Quality},
  author = {Schoonderbeek, Jan A. H. and Proper, Henderik A.},
  date = {2024-06-01},
  journaltitle = {Software and Systems Modeling},
  shortjournal = {Softw Syst Model},
  volume = {23},
  number = {3},
  pages = {535--558},
  issn = {1619-1374},
  doi = {10.1007/s10270-023-01146-w},
  url = {https://doi.org/10.1007/s10270-023-01146-w},
  urldate = {2025-06-30},
  abstract = {Models have long since been used, in different shapes and forms, to understand, communicate about, and (re)shape, the world around us; including many different social, economic, biological, chemical, physical, and digital aspects. This is also the case in the context of enterprise architecture (EA), where we see a wide range of models in many different shapes and forms being used as well. Researchers in EA modeling usually introduce their own lexicon, and perspective of what a model actually is, while accepting (often implicitly) the accompanying ontological commitments. Similarly, practitioners of EA modeling implicitly also commit to (different) ontologies, resulting in models that have an uncertain ontological standing. This is because, for the subject domain of enterprise architecture models (as opposed to the content of such models), no single ontology has gained major traction. As a result, studies into aspects of enterprise architecture models, such as “model quality” and “return on modeling effort”, are fragmented, and cannot readily be compared or combined. This paper proposes a comprehensive applied ontology, specifically geared to enterprise architecture modeling. Ontologies represent structured knowledge about a particular subject domain. It allows for study into, and reasoning about, that subject domain. Our ontology is derived from a theory of modeling, while clarifying concepts such as “enterprise architecture model”, and introduces novel concepts such as “model audience” and “model objective”. Furthermore, the relevant interrelations between these different concepts are identified and defined. The resulting ontology for enterprise architecture models is represented in OntoUML, and shown to be consistent with the foundational ontology for modeling, Unified Foundational Ontology.},
  langid = {english},
  keywords = {Architecture,Building Information Modeling,Domain model,Enterprise architecture,Enterprise Architecture,Enterprise architecture model,Enterprise architecture modeling,Gene ontology,Information Model,Model quality,Model Theory,Ontology},
  file = {/Users/dkapitan/Zotero/storage/WYKZDA9P/Schoonderbeek and Proper - 2024 - Toward an ontology for EA modeling and EA model quality.pdf}
}

@article{schultes2023fair,
  title = {The {{FAIR}} Hourglass: {{A}} Framework for {{FAIR}} Implementation},
  shorttitle = {The {{FAIR}} Hourglass},
  author = {Schultes, Erik},
  editor = {Magagna, Barbara},
  date = {2023-01-09},
  journaltitle = {FAIR Connect},
  shortjournal = {FC},
  volume = {1},
  number = {1},
  pages = {13--17},
  issn = {2949799X},
  doi = {10.3233/FC-221514},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/FC-221514},
  urldate = {2023-04-04},
  abstract = {The FAIR Hourglass provides a framework to organize two general phases of FAIR implementation: FAIRification (top) and FAIR Orchestration (bottom). The center of the hourglass represents the use of widely agreed-upon open, minimal standards ensuring machine-actionability.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/C79VBWCR/Schultes - 2023 - The FAIR hourglass A framework for FAIR implement.pdf}
}

@article{sein2011action,
  title = {Action {{Design Research}}},
  author = {Sein, Maung and Henfridsson, Ola and Purao, Sandeep and Rossi, Matti and Lindgren, Rikard},
  date = {2011-03-01},
  journaltitle = {MIS Quarterly},
  shortjournal = {MIS Quarterly},
  volume = {35},
  pages = {37--56},
  doi = {10.2307/23043488},
  abstract = {Design research (DR) positions information technology artifacts at the core of the Information Systems discipline. However, dominant DR thinking takes a technological view of the IT artifact, paying scant attention to its shaping by the organizational context. Consequently, existing DR methods focus on building the artifact and relegate evaluation to a subsequent and separate phase. They value technological rigor at the cost of organizational relevance, and fail to recognize that the artifact emerges from interaction with the organizational context even when its initial design is guided by the researchers' intent. We propose action design research (ADR) as a new DR method to address this problem. ADR reflects the premise that IT artifacts are ensembles shaped by the organizational context during development and use. The method conceptualizes the research process as containing the inseparable and inherently interwoven activities of building the IT artifact, intervening in the organization, and evaluating it concurrently. The essay describes the stages of ADR and associated principles that encapsulate its underlying beliefs and values. We illustrate ADR through a case of competence management at Volvo IT.},
  file = {/Users/dkapitan/Zotero/storage/GUUY9RV9/Sein-ActionDesignResearch-2011.pdf}
}

@online{sharma2025hubs,
  title = {Hubs and {{Spokes Learning}}: {{Efficient}} and {{Scalable Collaborative Machine Learning}}},
  shorttitle = {Hubs and {{Spokes Learning}}},
  author = {Sharma, Atul and Herath, Kavindu and Bagchi, Saurabh and Liu, Chaoyue and Chaterji, Somali},
  date = {2025-04-29},
  eprint = {2504.20988},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2504.20988},
  url = {http://arxiv.org/abs/2504.20988},
  urldate = {2025-06-30},
  abstract = {We introduce the Hubs and Spokes Learning (HSL) framework, a novel paradigm for collaborative machine learning that combines the strengths of Federated Learning (FL) and Decentralized Learning (P2PL). HSL employs a two-tier communication structure that avoids the single point of failure inherent in FL and outperforms the state-of-the-art P2PL framework, Epidemic Learning Local (ELL). At equal communication budgets (total edges), HSL achieves higher performance than ELL, while at significantly lower communication budgets, it can match ELL's performance. For instance, with only 400 edges, HSL reaches the same test accuracy that ELL achieves with 1000 edges for 100 peers (spokes) on CIFAR-10, demonstrating its suitability for resource-constrained systems. HSL also achieves stronger consensus among nodes after mixing, resulting in improved performance with fewer training rounds. We substantiate these claims through rigorous theoretical analyses and extensive experimental results, showcasing HSL's practicality for large-scale collaborative learning.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning},
  file = {/Users/dkapitan/Zotero/storage/UM88KZJ2/Sharma et al. - 2025 - Hubs and Spokes Learning Efficient and Scalable Collaborative Machine Learning.pdf;/Users/dkapitan/Zotero/storage/BNHYHUAH/2504.html}
}

@article{sheller2020federated,
  title = {Federated Learning in Medicine: Facilitating Multi-Institutional Collaborations without Sharing Patient Data},
  shorttitle = {Federated Learning in Medicine},
  author = {Sheller, Micah J. and Edwards, Brandon and Reina, G. Anthony and Martin, Jason and Pati, Sarthak and Kotrotsou, Aikaterini and Milchenko, Mikhail and Xu, Weilin and Marcus, Daniel and Colen, Rivka R. and Bakas, Spyridon},
  date = {2020-07-28},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {10},
  number = {1},
  pages = {12598},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-69250-1},
  url = {https://www.nature.com/articles/s41598-020-69250-1},
  urldate = {2025-03-12},
  abstract = {Several studies underscore the potential of deep learning in identifying complex patterns, leading to diagnostic and prognostic biomarkers. Identifying sufficiently large and diverse datasets, required for training, is a significant challenge in medicine and can rarely be found in individual institutions. Multi-institutional collaborations based on centrally-shared patient data face privacy and ownership challenges. Federated learning is a novel paradigm for data-private multi-institutional collaborations, where model-learning leverages all available data without sharing data between institutions, by distributing the model-training to the data-owners and aggregating their results. We show that federated learning among 10 institutions results in models reaching 99\% of the model quality achieved with centralized data, and evaluate generalizability on data from institutions outside the federation. We further investigate the effects of data distribution across collaborating institutions on model quality and learning patterns, indicating that increased access to data through data private multi-institutional collaborations can benefit model quality more than the errors introduced by the collaborative method. Finally, we compare with other collaborative-learning approaches demonstrating the superiority of federated learning, and discuss practical implementation considerations. Clinical adoption of federated learning is expected to lead to models trained on datasets of unprecedented size, hence have a catalytic impact towards precision/personalized medicine.},
  langid = {english},
  keywords = {Biomedical engineering,Brain imaging,Cancer,CNS cancer,Computational science,Health care,Medical imaging,Scientific data},
  file = {/Users/dkapitan/Zotero/storage/C2UB2PZW/Sheller et al. - 2020 - Federated learning in medicine facilitating multi-institutional collaborations without sharing pati.pdf}
}

@online{simpl,
  title = {Simpl {{Programme}}},
  url = {https://simpl-programme.ec.europa.eu/},
  urldate = {2025-06-09},
  abstract = {.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/TQDIVTR8/simpl-programme.ec.europa.eu.html}
}

@online{smart-guidelines-webpage,
  title = {{{SMART Guidelines}}},
  url = {https://www.who.int/teams/digital-health-and-innovation/smart-guidelines},
  urldate = {2025-01-20},
  abstract = {As a landmark effort to accelerating the digitization of global public health resources, digitalizing the countries increasingly invest in digital technologies for health, WHO  need to build support for digital health across its core functions. To date, there is no documentation of procedures for systematically translating WHO’s recommendations into digital health systems in a software-neutral manner.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/2VTW64HD/smart-guidelines.html}
}

@online{sphn,
  title = {{{SPHN}} - {{Swiss Personalized Health Network}} ({{SPHN}})},
  url = {https://sphn.ch/},
  urldate = {2025-06-09},
  abstract = {Swiss Personalized Health Network (SPHN). Infrastructure building to enable nationwide use and exchange of health data for research.},
  langid = {british},
  organization = {SPHN},
  file = {/Users/dkapitan/Zotero/storage/YXNRLBE6/sphn.ch.html}
}

@article{tabari2024stateoftheart,
  title = {State-of-the-{{Art Fast Healthcare Interoperability Resources}} ({{FHIR}})–{{Based Data Model}} and {{Structure Implementations}}: {{Systematic Scoping Review}}},
  shorttitle = {State-of-the-{{Art Fast Healthcare Interoperability Resources}} ({{FHIR}})–{{Based Data Model}} and {{Structure Implementations}}},
  author = {Tabari, Parinaz and Costagliola, Gennaro and Rosa, Mattia De and Boeker, Martin},
  date = {2024-09-24},
  journaltitle = {JMIR Medical Informatics},
  volume = {12},
  number = {1},
  pages = {e58445},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/58445},
  url = {https://medinform.jmir.org/2024/1/e58445},
  urldate = {2025-04-04},
  abstract = {Background: Data models are crucial for clinical research as they enable researchers to fully use the vast amount of clinical data stored in medical systems. Standardized data and well-defined relationships between data points are necessary to guarantee semantic interoperability. Using the Fast Healthcare Interoperability Resources (FHIR) standard for clinical data representation would be a practical methodology to enhance and accelerate interoperability and data availability for research. Objective: This research aims to provide a comprehensive overview of the state-of-the-art and current landscape in FHIR-based data models and structures. In addition, we intend to identify and discuss the tools, resources, limitations, and other critical aspects mentioned in the selected research papers. Methods: To ensure the extraction of reliable results, we followed the instructions of the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) checklist. We analyzed the indexed articles in PubMed, Scopus, Web of Science, IEEE Xplore, the ACM Digital Library, and Google Scholar. After identifying, extracting, and assessing the quality and relevance of the articles, we synthesized the extracted data to identify common patterns, themes, and variations in the use of FHIR-based data models and structures across different studies. Results: On the basis of the reviewed articles, we could identify 2 main themes: dynamic (pipeline-based) and static data models. The articles were also categorized into health care use cases, including chronic diseases, COVID-19 and infectious diseases, cancer research, acute or intensive care, random and general medical notes, and other conditions. Furthermore, we summarized the important or common tools and approaches of the selected papers. These items included FHIR-based tools and frameworks, machine learning approaches, and data storage and security. The most common resource was “Observation” followed by “Condition” and “Patient.” The limitations and challenges of developing data models were categorized based on the issues of data integration, interoperability, standardization, performance, and scalability or generalizability. Conclusions: FHIR serves as a highly promising interoperability standard for developing real-world health care apps. The implementation of FHIR modeling for electronic health record data facilitates the integration, transmission, and analysis of data while also advancing translational research and phenotyping. Generally, FHIR-based exports of local data repositories improve data interoperability for systems and data warehouses across different settings. However, ongoing efforts to address existing limitations and challenges are essential for the successful implementation and integration of FHIR data models.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/I9S64U5Q/e58445.html}
}

@online{tagliabue2023building,
  title = {Building a Serverless {{Data Lakehouse}} from Spare Parts},
  author = {Tagliabue, Jacopo and Greco, Ciro and Bigon, Luca},
  date = {2023-08-10},
  eprint = {2308.05368},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2308.05368},
  url = {http://arxiv.org/abs/2308.05368},
  urldate = {2025-01-29},
  abstract = {The recently proposed Data Lakehouse architecture is built on open file formats, performance, and first-class support for data transformation, BI and data science: while the vision stresses the importance of lowering the barrier for data work, existing implementations often struggle to live up to user expectations. At Bauplan, we decided to build a new serverless platform to fulfill the Lakehouse vision. Since building from scratch is a challenge unfit for a startup, we started by re-using (sometimes unconventionally) existing projects, and then investing in improving the areas that would give us the highest marginal gains for the developer experience. In this work, we review user experience, high-level architecture and tooling decisions, and conclude by sharing plans for future development.},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Software Engineering},
  file = {/Users/dkapitan/Zotero/storage/HH33FNWB/Tagliabue et al. - 2023 - Building a serverless Data Lakehouse from spare parts.pdf;/Users/dkapitan/Zotero/storage/QMGVJ8H9/2308.html}
}

@article{tang2023creating,
  title = {Creating a {{Medical Imaging Workflow Based}} on {{FHIR}}, {{DICOMweb}}, and {{SVG}}},
  author = {Tang, Shih-Tsang and Tjia, Victoria and Noga, Thalia and Febri, Jeshika and Lien, Chung-Yueh and Chu, Woei-Chyn and Chen, Chin-Yu and Hsiao, Chia-Hung},
  date = {2023-06-01},
  journaltitle = {Journal of Digital Imaging},
  shortjournal = {J Digit Imaging},
  volume = {36},
  number = {3},
  pages = {794--803},
  issn = {1618-727X},
  doi = {10.1007/s10278-021-00522-6},
  url = {https://doi.org/10.1007/s10278-021-00522-6},
  urldate = {2025-04-08},
  abstract = {This paper proposes a web-based workflow scheme for the organization of medical images using FHIR and DICOM servers equipped with standard RESTful APIs. In our integrated workflow, the client systems (including order placer, scheduler, imaging modality, viewer, and report creator) use standard FHIR and DICOMweb APIs. The proposed scheme also facilitates the creation of reports formatted as standard FHIR resources. This paper leverages W3C Scalable Vector Graphics (SVG) to record the image graphic annotations, and encapsulates the SVG image annotation in FHIR observation. FHIR DiagnosticReports and Observations are used to encapsulate reports, findings, and annotations, thereby facilitating the implementation and integration of the scheme within existing structures. The proposed scheme also provides the potential to make it possible to convert results of Computer Aided Detection/Diagnosis from medical images into FHIR DiagnosticReports and Observations to be stored on a FHIR server. The resulting web-based solution uses FHIR XML and/or JSON data to record and exchange information related to imaging workflow. It can also be used to store imaging reports, findings, and annotations linked to the images using the DICOM WADO-RS protocol. As a result, it is possible to integrate all information that is created in medical imaging workflow. Finally, the proposed scheme is easily integrated with other FHIR systems.},
  langid = {english},
  keywords = {DICOMweb,FHIR,RESTful,Scalable Vector Graphics (SVG)},
  file = {/Users/dkapitan/Zotero/storage/KMBJTMUZ/Tang et al. - 2023 - Creating a Medical Imaging Workflow Based on FHIR, DICOMweb, and SVG.pdf}
}

@report{tarkowski2025data,
  title = {Data {{Governance}} in {{Open Source AI}}},
  author = {Tarkowski, Alek},
  date = {2025-01-22},
  institution = {Open Future Foundation},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/X8XDXHKI/Tarkowski - Data Governance in Open Source AI.pdf}
}

@online{tehdas2,
  title = {{{TEHDAS2}}},
  url = {https://tehdas.eu/},
  urldate = {2025-06-09},
  abstract = {The TEHDAS2 joint action prepares the ground for the harmonised implementation of the secondary use of health data in the European Health Data Space – EHDS.},
  langid = {american},
  organization = {Tehdas},
  file = {/Users/dkapitan/Zotero/storage/QRLE3XYU/tehdas.eu.html}
}

@article{teo2024federated,
  title = {Federated Machine Learning in Healthcare: {{A}} Systematic Review on Clinical Applications and Technical Architecture},
  shorttitle = {Federated Machine Learning in Healthcare},
  author = {Teo, Zhen Ling and Jin, Liyuan and Liu, Nan and Li, Siqi and Miao, Di and Zhang, Xiaoman and Ng, Wei Yan and Tan, Ting Fang and Lee, Deborah Meixuan and Chua, Kai Jie and Heng, John and Liu, Yong and Goh, Rick Siow Mong and Ting, Daniel Shu Wei},
  date = {2024-02},
  journaltitle = {Cell Reports Medicine},
  shortjournal = {Cell Reports Medicine},
  volume = {5},
  number = {2},
  pages = {101419},
  issn = {26663791},
  doi = {10.1016/j.xcrm.2024.101419},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2666379124000429},
  urldate = {2024-06-03},
  abstract = {Federated learning (FL) is a distributed machine learning framework that is gaining traction in view of increasing health data privacy protection needs. By conducting a systematic review of FL applications in healthcare, we identify relevant articles in scientific, engineering, and medical journals in English up to August 31st, 2023. Out of a total of 22,693 articles under review, 612 articles are included in the final analysis. The majority of articles are proof-of-concepts studies, and only 5.2\% are studies with real-life application of FL. Radiology and internal medicine are the most common specialties involved in FL. FL is robust to a variety of machine learning models and data types, with neural networks and medical imaging being the most common, respectively. We highlight the need to address the barriers to clinical translation and to assess its realworld impact in this new digital data-driven healthcare scene.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/84BC73II/Teo et al. - 2024 - Federated machine learning in healthcare A system.pdf}
}

@article{thurin2022inception,
  title = {From {{Inception}} to {{ConcePTION}}: {{Genesis}} of a {{Network}} to {{Support Better Monitoring}} and {{Communication}} of {{Medication Safety During Pregnancy}} and {{Breastfeeding}}},
  shorttitle = {From {{Inception}} to {{ConcePTION}}},
  author = {Thurin, Nicolas H. and Pajouheshnia, Romin and Roberto, Giuseppe and Dodd, Caitlin and Hyeraci, Giulia and Bartolini, Claudia and Paoletti, Olga and Nordeng, Hedvig and Wallach‐Kildemoes, Helle and Ehrenstein, Vera and Dudukina, Elena and MacDonald, Thomas and De Paoli, Giorgia and Loane, Maria and Damase‐Michel, Christine and Beau, Anna‐Belle and Droz‐Perroteau, Cécile and Lassalle, Régis and Bergman, Jorieke and Swart, Karin and Schink, Tania and Cavero‐Carbonell, Clara and Barrachina‐Bonet, Laia and Gomez‐Lumbreras, Ainhoa and Giner‐Soriano, Maria and Aragón, María and Neville, Amanda J. and Puccini, Aurora and Pierini, Anna and Ientile, Valentina and Trifirò, Gianluca and Rissmann, Anke and Leinonen, Maarit K. and Martikainen, Visa and Jordan, Sue and Thayer, Daniel and Scanlon, Ieuan and Georgiou, Mary E. and Cunnington, Marianne and Swertz, Morris and Sturkenboom, Miriam and Gini, Rosa},
  date = {2022-01},
  journaltitle = {Clinical Pharmacology and Therapeutics},
  shortjournal = {Clin Pharmacol Ther},
  volume = {111},
  number = {1},
  eprint = {34826340},
  eprinttype = {pubmed},
  pages = {321--331},
  issn = {0009-9236},
  doi = {10.1002/cpt.2476},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9299060/},
  urldate = {2025-06-02},
  abstract = {In 2019, the Innovative Medicines Initiative (IMI) funded the ConcePTION project—Building an ecosystem for better monitoring and communicating safety of medicines use in pregnancy and breastfeeding: validated and regulatory endorsed workflows for fast, optimised evidence generation—with the vision that there is a societal obligation to rapidly reduce uncertainty about the safety of medication use in pregnancy and breastfeeding. The present paper introduces the set of concepts used to describe the European data sources involved in the ConcePTION project and illustrates the ConcePTION Common Data Model (CDM), which serves as the keystone of the federated ConcePTION network. Based on data availability and content analysis of 21 European data sources, the ConcePTION CDM has been structured with six tables designed to capture data from routine healthcare, three tables for data from public health surveillance activities, three curated tables for derived data on population (e.g., observation time and mother‐child linkage), plus four metadata tables. By its first anniversary, the ConcePTION CDM has enabled 13 data sources to run common scripts to contribute to major European projects, demonstrating its capacity to facilitate effective and transparent deployment of distributed analytics, and its potential to address questions about utilization, effectiveness, and safety of medicines in special populations, including during pregnancy and breastfeeding, and, more broadly, in the general population.},
  pmcid = {PMC9299060},
  file = {/Users/dkapitan/Zotero/storage/9XSBRUCZ/Thurin et al. - 2022 - From Inception to ConcePTION Genesis of a Network to Support Better Monitoring and Communication of.pdf}
}

@online{togaf,
  title = {The {{TOGAF}}® {{Standard}}, {{Version}} 9.2},
  url = {https://pubs.opengroup.org/architecture/togaf9-doc/arch/index.html},
  urldate = {2025-07-07},
  file = {/Users/dkapitan/Zotero/storage/PHABB93X/index.html}
}

@article{toure2025sphn,
  title = {The {{SPHN Schema Forge}} – Transform Healthcare Semantics from Human-Readable to Machine-Readable by Leveraging Semantic Web Technologies},
  author = {Touré, Vasundra and Unni, Deepak and Krauss, Philip and Abdelwahed, Abdelhamid and Buchhorn, Jascha and Hinderling, Leon and Geiger, Thomas R. and Österle, Sabine},
  date = {2025-05-08},
  journaltitle = {Journal of Biomedical Semantics},
  shortjournal = {Journal of Biomedical Semantics},
  volume = {16},
  number = {1},
  pages = {9},
  issn = {2041-1480},
  doi = {10.1186/s13326-025-00330-9},
  url = {https://doi.org/10.1186/s13326-025-00330-9},
  urldate = {2025-05-22},
  abstract = {The Swiss Personalized Health Network (SPHN) adopted the Resource Description Framework (RDF), a core component of the Semantic Web technology stack, for the formal encoding and exchange of healthcare data in a medical knowledge graph. The SPHN RDF Schema defines the semantics on how data elements should be represented. While RDF is proven to be machine readable and interpretable, it can be challenging for individuals without specialized background to read and understand the knowledge represented in RDF. For this reason, the semantics described in the SPHN RDF Schema are primarily defined in a user-accessible tabular format, the SPHN Dataset, before being translated into its RDF representation. However, this translation process was previously manual, time-consuming and labor-intensive.},
  keywords = {Conversion,FAIR,Healthcare,RDF,Schema,Semantic Web,Semantics,Spreadsheet,Web Service},
  file = {/Users/dkapitan/Zotero/storage/FGV3AHEL/Touré et al. - 2025 - The SPHN Schema Forge – transform healthcare semantics from human-readable to machine-readable by le.pdf;/Users/dkapitan/Zotero/storage/97848I6X/s13326-025-00330-9.html}
}

@online{trask2024privacy,
  title = {Beyond {{Privacy Trade-offs}} with {{Structured Transparency}}},
  author = {Trask, Andrew and Bluemke, Emma and Collins, Teddy and Drexler, Ben Garfinkel Eric and Cuervas-Mons, Claudia Ghezzou and Gabriel, Iason and Dafoe, Allan and Isaac, William},
  date = {2024-03-12},
  eprint = {2012.08347},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2012.08347},
  url = {http://arxiv.org/abs/2012.08347},
  urldate = {2025-06-30},
  abstract = {Successful collaboration involves sharing information. However, parties may disagree on how the information they need to share should be used. We argue that many of these concerns reduce to 'the copy problem': once a bit of information is copied and shared, the sender can no longer control how the recipient uses it. From the perspective of each collaborator, this presents a dilemma that can inhibit collaboration. The copy problem is often amplified by three related problems which we term the bundling, edit, and recursive enforcement problems. We find that while the copy problem is not solvable, aspects of these amplifying problems have been addressed in a variety of disconnected fields. We observe that combining these efforts could improve the governability of information flows and thereby incentivise collaboration. We propose a five-part framework which groups these efforts into specific capabilities and offers a foundation for their integration into an overarching vision we call "structured transparency". We conclude by surveying an array of use-cases that illustrate the structured transparency principles and their related capabilities.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computers and Society,Computer Science - Cryptography and Security},
  file = {/Users/dkapitan/Zotero/storage/S4XKFKJZ/Trask et al. - 2024 - Beyond Privacy Trade-offs with Structured Transparency.pdf;/Users/dkapitan/Zotero/storage/6V6FE5H5/2012.html}
}

@article{tsafnat2024converge,
  title = {Converge or {{Collide}}? {{Making Sense}} of a {{Plethora}} of {{Open Data Standards}} in {{Health Care}}},
  shorttitle = {Converge or {{Collide}}?},
  author = {Tsafnat, Guy and Dunscombe, Rachel and Gabriel, Davera and Grieve, Grahame and Reich, Christian},
  date = {2024-04-09},
  journaltitle = {Journal of Medical Internet Research},
  volume = {26},
  number = {1},
  pages = {e55779},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/55779},
  url = {https://www.jmir.org/2024/1/e55779},
  urldate = {2024-09-21},
  abstract = {Practitioners of digital health are familiar with disjointed data environments that often inhibit effective communication among different elements of the ecosystem. This fragmentation leads in turn to issues such as inconsistencies in services versus payments, wastage, and notably, care delivered being less than best-practice. Despite the long-standing recognition of interoperable data as a potential solution, efforts in achieving interoperability have been disjointed and inconsistent, resulting in numerous incompatible standards, despite the widespread agreement that fewer standards would enhance interoperability. This paper introduces a framework for understanding health care data needs, discussing the challenges and opportunities of open data standards in the field. It emphasizes the necessity of acknowledging diverse data standards, each catering to specific viewpoints and needs, while proposing a categorization of health care data into three domains, each with its distinct characteristics and challenges, along with outlining overarching design requirements applicable to all domains and specific requirements unique to each domain.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/HCRU7DUV/e55779.html}
}

@report{un2023pet-guide,
  title = {The {{PET Guide}}},
  date = {2023},
  institution = {United Nations},
  url = {https://unstats.un.org/bigdata/task-teams/privacy/guide/},
  urldate = {2025-01-22},
  file = {/Users/dkapitan/Zotero/storage/AJP3R3G3/UN Guide on Privacy-Enhancing Technologies for Official Statistics  Task Team on Privacy Enhancing.pdf;/Users/dkapitan/Zotero/storage/CE6FUTIB/guide.html}
}

@article{vandervlist2021how,
  title = {How Partners Mediate Platform Power: {{Mapping}} Business and Data Partnerships in the Social Media Ecosystem},
  shorttitle = {How Partners Mediate Platform Power},
  author = {family=Vlist, given=Fernando N, prefix=van der, useprefix=true and Helmond, Anne},
  date = {2021-01-01},
  journaltitle = {Big Data \& Society},
  volume = {8},
  number = {1},
  pages = {20539517211025061},
  publisher = {SAGE Publications Ltd},
  issn = {2053-9517},
  doi = {10.1177/20539517211025061},
  url = {https://doi.org/10.1177/20539517211025061},
  urldate = {2025-03-28},
  abstract = {Social media platforms’ digital advertising revenues depend considerably on partnerships. Business partnerships are endemic and essential to the business of platforms, yet their role remains relatively underexplored in the literature on platformisation and platform power. This article considers the significance of partnerships in the social media ecosystem to better understand how industry platforms, and the infrastructure they build, mediate and shape platform power and governance. We argue that partners contribute to ‘platformisation’ through their collective development of business-to-business platform infrastructures. Specifically, we examine how partners have integrated social media platforms with what we call the audience economy – an exceptionally complex global and interconnected marketplace of intermediaries involved in the creation, commodification, analysis, and circulation of data audiences for purposes including but not limited to digital advertising and marketing. We determined which relationships are involved, which are exclusive or shared, and identified key ecosystem partners. Further, we found that partners build and integrate extensive infrastructures for data-sourcing and media distribution, surfacing infrastructural and strategic sources and locations, or ‘nodes’, of power in this ecosystem. The empirical findings thus highlight the significance of partnerships and partner integrations and draw attention to the powerful industry players and intermediaries that remain largely invisible.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/FNBZHXJT/van der Vlist and Helmond - 2021 - How partners mediate platform power Mapping business and data partnerships in the social media ecos.pdf}
}

@article{vandervlist2024big,
  title = {Big {{AI}}: {{Cloud}} Infrastructure Dependence and the Industrialisation of Artificial Intelligence},
  shorttitle = {Big {{AI}}},
  author = {family=Vlist, given=Fernando, prefix=van der, useprefix=true and Helmond, Anne and Ferrari, Fabian},
  date = {2024-03-01},
  journaltitle = {Big Data \& Society},
  volume = {11},
  number = {1},
  pages = {20539517241232630},
  publisher = {SAGE Publications Ltd},
  issn = {2053-9517},
  doi = {10.1177/20539517241232630},
  url = {https://doi.org/10.1177/20539517241232630},
  urldate = {2025-03-28},
  abstract = {Critical scholars contend that ‘There is no AI without Big Tech’. This study delves into the substantial role played by major technology conglomerates, including Amazon, Microsoft, and Google (Alphabet), in the ‘industrialisation of artificial intelligence’. This concept encapsulates the shift of AI technologies from the research and development stage to practical, real-world applications across diverse industry sectors, resulting in new dependencies and associated investments. We employ the term ‘Big AI’ to encapsulate the structural convergence of AI and Big Tech, characterised by the profound interdependence of AI with the infrastructure, resources, and investments of these major technology companies. Using a ‘technographic’ approach, our study scrutinises the infrastructural support and investments of Big Tech in the AI sector, focussing on corporate partnerships, acquisitions, and financial investments. Additionally, we conduct a detailed examination of the complete spectrum of cloud platform products and services offered by Amazon, Microsoft, and Google. We demonstrate that AI is not merely an abstract idea but an actual technology stack encompassing infrastructure, models, applications, and an ecosystem of applications and companies relying on this stack. Significantly, these tech giants have seamlessly integrated all three components of the stack into their cloud offerings. Furthermore, they have developed industry-focussed solutions and marketplaces aimed at attracting third-party developers and businesses, fostering the growth of a broader AI ecosystem. This analysis underscores the intricate interdependence between AI and cloud infrastructure, emphasising the industry-specific aspects of cloud AI.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/QGSP68CJ/van der Vlist et al. - 2024 - Big AI Cloud infrastructure dependence and the industrialisation of artificial intelligence.pdf}
}

@incollection{vanderwerf2025data,
  title = {Towards a {{Data Mesh Reference Architecture}}},
  booktitle = {Enterprise {{Design}}, {{Operations}}, and {{Computing}}. {{EDOC}} 2024 {{Workshops}}},
  author = {Van Der Werf, Daniel and Moreira, João and Piest, Jean Paul Sebastian},
  editor = {Kaczmarek-Heß, Monika and Rosenthal, Kristina and Suchánek, Marek and Da Silva, Miguel Mira and Proper, Henderik A. and Schnellmann, Marianne},
  date = {2025},
  volume = {537},
  pages = {339--353},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-79059-1_21},
  url = {https://link.springer.com/10.1007/978-3-031-79059-1_21},
  urldate = {2025-06-05},
  abstract = {Future work should validate the data mesh reference architecture in practice through case studies in various industries. Additionally, a study comparing the efficiency of designing a data mesh solution architecture with the RA, compared to a group not using the RA, can be performed. Research could be performed to asses if the usefulness, quality and variability of the model improve after improvements have been made to the model. Lastly, future research is needed to update this research with new findings from theory and practice, for example, regarding best practices or by identifying different archetypes.},
  isbn = {978-3-031-79058-4 978-3-031-79059-1},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/8W5W4HMS/Van Der Werf et al. - 2025 - Towards a Data Mesh Reference Architecture.pdf}
}

@incollection{vanderwerf2025dataa,
  title = {Towards a {{Data Mesh Reference Architecture}}},
  booktitle = {Enterprise {{Design}}, {{Operations}}, and {{Computing}}. {{EDOC}} 2024 {{Workshops}}},
  author = {Van Der Werf, Daniel and Moreira, João and Piest, Jean Paul Sebastian},
  editor = {Kaczmarek-Heß, Monika and Rosenthal, Kristina and Suchánek, Marek and Da Silva, Miguel Mira and Proper, Henderik A. and Schnellmann, Marianne},
  date = {2025},
  volume = {537},
  pages = {339--353},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-79059-1_21},
  url = {https://link.springer.com/10.1007/978-3-031-79059-1_21},
  urldate = {2025-07-02},
  abstract = {The increasing complexity and volume of organizational data have led to the emergence of the Data Mesh paradigm, a data architecture with a federated governance aimed at addressing the limitations of traditional monolithic data systems that has overlapping principles with the microservices architectural style. Although related work exists, the majority of architectural approaches regarding Data Mesh are conceptual, technology-centric or vendor specific. This paper introduces a Data Mesh Reference Architecture (RA) using the ArchiMate enterprise architecture modeling language, designed to assist organizations in implementing (or migrating towards) data mesh solutions. The RA comprises three main components: domain architecture, self-serve data platform architecture, and federated governance, which reflect the main Data Mesh principles. Through a systematic literature review, four data mesh archetypes (Pure, Semi-Pure, Hybrid, and Distributed) were identified, along with challenges, limitations, and motivational factors for adoption. A questionnaire-based validation among experts confirmed the RA’s utility, quality, and variability. However, practical validation was not conducted within this study. The study contributes to both literature and practice by offering a structured approach and a set of reference models for designing data mesh architectures. Future research can contribute to practical validation, assessment of RA-driven design efficiency, and extending the RA with domain-driven solution architectures.},
  isbn = {978-3-031-79058-4 978-3-031-79059-1},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/GRIM4ZZS/Van Der Werf et al. - 2025 - Towards a Data Mesh Reference Architecture.pdf}
}

@article{vangiessen2017systematic,
  title = {Systematic {{Review}} of {{Health Economic Impact Evaluations}} of {{Risk Prediction Models}}: {{Stop Developing}}, {{Start Evaluating}}},
  shorttitle = {Systematic {{Review}} of {{Health Economic Impact Evaluations}} of {{Risk Prediction Models}}},
  author = {Van Giessen, Anoukh and Peters, Jaime and Wilcher, Britni and Hyde, Chris and Moons, Carl and De Wit, Ardine and Koffijberg, Erik},
  date = {2017-04},
  journaltitle = {Value in Health},
  shortjournal = {Value in Health},
  volume = {20},
  number = {4},
  pages = {718--726},
  issn = {10983015},
  doi = {10.1016/j.jval.2017.01.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1098301516300328},
  urldate = {2025-04-15},
  abstract = {Background: Although health economic evaluations (HEEs) are increasingly common for therapeutic interventions, they appear to be rare for the use of risk prediction models (PMs). Objectives: To evaluate the current state of HEEs of PMs by performing a comprehensive systematic review. Methods: Four databases were searched for HEEs of PM-based strategies. Two reviewers independently selected eligible articles. A checklist was compiled to score items focusing on general characteristics of HEEs of PMs, model characteristics and quality of HEEs, evidence on PMs typically used in the HEEs, and the specific challenges in performing HEEs of PMs. Results: After screening 791 abstracts, 171 full texts, and reference checking, 40 eligible HEEs evaluating 60 PMs were identified. In these HEEs, PM strategies were compared with current practice (n ¼ 32; 80\%), to other stratification methods for patient management (n ¼ 19; 48\%), to an extended PM (n ¼ 9; 23\%), or to alternative PMs (n ¼ 5; 13\%). The PMs guided decisions on treatment (n ¼ 42; 70\%), further testing (n ¼ 18; 30\%), or treatment prioritization (n ¼ 4; 7\%). For 36 (60\%) PMs, only a single decision threshold was evaluated. Costs of risk prediction were ignored for 28 (46\%) PMs. Uncertainty in outcomes was assessed using probabilistic sensitivity analyses in 22 (55\%) HEEs. Conclusions: Despite the huge number of PMs in the medical literature, HEE of PMs remains rare. In addition, we observed great variety in their quality and methodology, which may complicate interpretation of HEE results and implementation of PMs in practice. Guidance on HEE of PMs could encourage and standardize their application and enhance methodological quality, thereby improving adequate use of PM strategies.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/48A7LPZ2/Van Giessen et al. - 2017 - Systematic Review of Health Economic Impact Evaluations of Risk Prediction Models Stop Developing,.pdf}
}

@report{vangool2018eenheid,
  title = {Eenheid van Taal in de Nederlandse zorg : Van eenduidige informatie-uitwisseling tot hulpmiddel voor betere zorg},
  shorttitle = {Eenheid van Taal in de Nederlandse zorg},
  author = {family=Gool, given=CH, given-i=CH, prefix=van, useprefix=true and family=Volkert, given=PA, given-i=PA and Savelkoul, M},
  date = {2018},
  institution = {RIVM},
  doi = {10.21945/RIVM-2018-0081},
  url = {https://rivm.openrepository.com/handle/10029/622206},
  urldate = {2025-01-15},
  langid = {dutch},
  file = {/Users/dkapitan/Zotero/storage/55HDPCS2/van Gool et al. - 2018 - Eenheid van Taal in de Nederlandse zorg  Van eenduidige informatie-uitwisseling tot hulpmiddel voor.pdf}
}

@article{venable2016feds,
  title = {{{FEDS}}: A {{Framework}} for {{Evaluation}} in {{Design Science Research}}},
  shorttitle = {{{FEDS}}},
  author = {Venable, John and Pries-Heje, Jan and Baskerville, Richard},
  date = {2016-01-01},
  journaltitle = {European Journal of Information Systems},
  shortjournal = {Eur J Inf Syst},
  volume = {25},
  number = {1},
  pages = {77--89},
  issn = {1476-9344},
  doi = {10.1057/ejis.2014.36},
  url = {https://doi.org/10.1057/ejis.2014.36},
  urldate = {2024-02-07},
  abstract = {Evaluation of design artefacts and design theories is a key activity in Design Science Research (DSR), as it provides feedback for further development and (if done correctly) assures the rigour of the research. However, the extant DSR literature provides insufficient guidance on evaluation to enable Design Science Researchers to effectively design and incorporate evaluation activities into a DSR project that can achieve DSR goals and objectives. To address this research gap, this research paper develops, explicates, and provides evidence for the utility of a Framework for Evaluation in Design Science (FEDS) together with a process to guide design science researchers in developing a strategy for evaluating the artefacts they develop within a DSR project. A FEDS strategy considers why, when, how, and what to evaluate. FEDS includes a two-dimensional characterisation of DSR evaluation episodes (particular evaluations), with one dimension being the functional purpose of the evaluation (formative or summative) and the other dimension being the paradigm of the evaluation (artificial or naturalistic). The FEDS evaluation design process is comprised of four steps: (1) explicate the goals of the evaluation, (2) choose the evaluation strategy or strategies, (3) determine the properties to evaluate, and (4) design the individual evaluation episode(s). The paper illustrates the framework with two examples and provides evidence of its utility via a naturalistic, summative evaluation through its use on an actual DSR project.},
  langid = {english},
  keywords = {artefact evaluation,Design Science Research,information systems evaluation,research design,research methodology,utility evaluation},
  file = {/Users/dkapitan/Zotero/storage/C42M7QGN/Venable et al. - 2016 - FEDS a Framework for Evaluation in Design Science.pdf}
}

@article{vorisek2024interoperability,
  title = {Towards an {{Interoperability Landscape}} for a {{National Research Data Infrastructure}} for {{Personal Health Data}}},
  author = {Vorisek, Carina Nina and Klopfenstein, Sophie Anne Inès and Löbe, Matthias and Schmidt, Carsten Oliver and Mayer, Paula Josephine and Golebiewski, Martin and Thun, Sylvia},
  date = {2024-07-13},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {11},
  number = {1},
  pages = {772},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/s41597-024-03615-3},
  url = {https://www.nature.com/articles/s41597-024-03615-3},
  urldate = {2025-03-08},
  abstract = {The German initiative “National Research Data Infrastructure for Personal Health Data” (NFDI4Health) focuses on research data management in health research. It aims to foster and develop harmonized informatics standards for public health, epidemiological studies, and clinical trials, facilitating access to relevant data and metadata standards. This publication lists syntactic and semantic data standards of potential use for NFDI4Health and beyond, based on interdisciplinary meetings and workshops, mappings of study questionnaires and the NFDI4Health metadata schema, and literature search. Included are 7 syntactic, 32 semantic and 9 combined syntactic and semantic standards. In addition, 101 ISO Standards from ISO/TC 215 Health Informatics and ISO/TC 276 Biotechnology could be identified as being potentially relevant. The work emphasizes the utilization of standards for epidemiological and health research data ensuring interoperability as well as the compatibility to NFDI4Health, its use cases, and to (inter-)national efforts within these sectors. The goal is to foster collaborative and inter-sectoral work in health research and initiate a debate around the potential of using common standards.},
  langid = {english},
  keywords = {Epidemiology,Public health},
  file = {/Users/dkapitan/Zotero/storage/KFECN9A7/Vorisek et al. - 2024 - Towards an Interoperability Landscape for a National Research Data Infrastructure for Personal Healt.pdf}
}

@article{wang2025survey,
  title = {A {{Survey}} on {{Federated Analytics}}: {{Taxonomy}}, {{Enabling Techniques}}, {{Applications}} and {{Open Issues}}},
  shorttitle = {A {{Survey}} on {{Federated Analytics}}},
  author = {Wang, Zibo and Ji, Haichao and Zhu, Yifei and Wang, Dan and Han, Zhu},
  date = {2025},
  journaltitle = {IEEE Communications Surveys \& Tutorials},
  shortjournal = {IEEE Commun. Surv. Tutorials},
  pages = {1--1},
  issn = {1553-877X, 2373-745X},
  doi = {10.1109/COMST.2025.3558755},
  url = {https://ieeexplore.ieee.org/document/10960683/},
  urldate = {2025-06-19},
  abstract = {The escalating influx of data generated by networked edge devices, coupled with the growing awareness of data privacy, has restricted the traditional data analytics workflow, where the edge data are gathered by a centralized server to be further utilized by data analysts. To continue leveraging vast edge data to support various data-incentive applications, computing paradigms have promoted a transformative shift from centralized data processing to privacy-preserved distributed data processing. The need to perform data analytics on private edge data motivates federated analytics (FA), an emerging technique to support collaborative data analytics among diverse data owners without centralizing the raw data. Despite the wide applications of FA in industry and academia, a comprehensive examination of existing research efforts in FA has been notably absent. This survey aims to bridge this gap by first providing an overview of FA, elucidating key concepts, and discussing its relationship with similar concepts. We then thoroughly examine FA, including its key challenges, taxonomy, and enabling techniques. Diverse FA applications, including statistical metrics, frequency-related applications, database query operations, FL-assisting FA tasks, and other wireless network applications are then carefully reviewed. We complete the survey with several open research issues, future directions, and a comprehensive lessons learned part. This survey intends to provide a holistic understanding of the emerging FA techniques and foster the continued evolution of privacy-preserving distributed data processing in the emerging networked society.},
  langid = {english},
  file = {/Users/dkapitan/Zotero/storage/FWAP8KGY/Wang et al. - 2025 - A Survey on Federated Analytics Taxonomy, Enabling Techniques, Applications and Open Issues.pdf}
}

@online{welten2024pasta4pht,
  title = {{{PASTA-4-PHT}}: {{A Pipeline}} for {{Automated Security}} and {{Technical Audits}} for the {{Personal Health Train}}},
  shorttitle = {{{PASTA-4-PHT}}},
  author = {Welten, Sascha and Kindermann, Karl and Polat, Ahmet and Görz, Martin and Jugl, Maximilian and Neumann, Laurenz and Neumann, Alexander and Lohmöller, Johannes and Pennekamp, Jan and Decker, Stefan},
  date = {2024-12-02},
  eprint = {2412.01275},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2412.01275},
  url = {http://arxiv.org/abs/2412.01275},
  urldate = {2025-06-17},
  abstract = {With the introduction of data protection regulations, the need for innovative privacy-preserving approaches to process and analyse sensitive data has become apparent. One approach is the Personal Health Train (PHT) that brings analysis code to the data and conducts the data processing at the data premises. However, despite its demonstrated success in various studies, the execution of external code in sensitive environments, such as hospitals, introduces new research challenges because the interactions of the code with sensitive data are often incomprehensible and lack transparency. These interactions raise concerns about potential effects on the data and increases the risk of data breaches. To address this issue, this work discusses a PHT-aligned security and audit pipeline inspired by DevSecOps principles. The automated pipeline incorporates multiple phases that detect vulnerabilities. To thoroughly study its versatility, we evaluate this pipeline in two ways. First, we deliberately introduce vulnerabilities into a PHT. Second, we apply our pipeline to five real-world PHTs, which have been utilised in real-world studies, to audit them for potential vulnerabilities. Our evaluation demonstrates that our designed pipeline successfully identifies potential vulnerabilities and can be applied to real-world studies. In compliance with the requirements of the GDPR for data management, documentation, and protection, our automated approach supports researchers using in their data-intensive work and reduces manual overhead. It can be used as a decision-making tool to assess and document potential vulnerabilities in code for data processing. Ultimately, our work contributes to an increased security and overall transparency of data processing activities within the PHT framework.},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Distributed Parallel and Cluster Computing},
  file = {/Users/dkapitan/Zotero/storage/23LW6353/Welten et al. - 2024 - PASTA-4-PHT A Pipeline for Automated Security and Technical Audits for the Personal Health Train.pdf;/Users/dkapitan/Zotero/storage/33YWYVIL/2412.html}
}

@article{welten2024study,
  title = {A Study on Interoperability between Two {{Personal Health Train}} Infrastructures in Leukodystrophy Data Analysis},
  author = {Welten, Sascha and family=Arruda Botelho Herr, given=Marius, prefix=de, useprefix=true and Hempel, Lars and Hieber, David and Placzek, Peter and Graf, Michael and Weber, Sven and Neumann, Laurenz and Jugl, Maximilian and Tirpitz, Liam and Kindermann, Karl and Geisler, Sandra and Bonino da Silva Santos, Luiz Olavo and Decker, Stefan and Pfeifer, Nico and Kohlbacher, Oliver and Kirsten, Toralf},
  date = {2024-06-22},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {11},
  number = {1},
  pages = {663},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/s41597-024-03450-6},
  url = {https://www.nature.com/articles/s41597-024-03450-6},
  urldate = {2025-03-31},
  abstract = {The development of platforms for distributed analytics has been driven by a growing need to comply with various governance-related or legal constraints. Among these platforms, the so-called Personal Health Train (PHT) is one representative that has emerged over the recent years. However, in projects that require data from sites featuring different PHT infrastructures, institutions are facing challenges emerging from the combination of multiple PHT ecosystems, including data governance, regulatory compliance, or the modification of existing workflows. In these scenarios, the interoperability of the platforms is preferable. In this work, we introduce a conceptual framework for the technical interoperability of the PHT covering five essential requirements: Data integration, unified station identifiers, mutual metadata, aligned security protocols, and business logic. We evaluated our concept in a feasibility study that involves two distinct PHT infrastructures: PHT-meDIC and PADME. We analyzed data on leukodystrophy from patients in the University Hospitals of Tübingen and Leipzig, and patients with differential diagnoses at the University Hospital Aachen. The results of our study demonstrate the technical interoperability between these two PHT infrastructures, allowing researchers to perform analyses across the participating institutions. Our method is more space-efficient compared to the multi-homing strategy, and it shows only a minimal time overhead.},
  langid = {english},
  keywords = {Health care,Research data},
  file = {/Users/dkapitan/Zotero/storage/GW28S4JR/Welten et al. - 2024 - A study on interoperability between two Personal Health Train infrastructures in leukodystrophy data.pdf}
}

@online{wijnbergen2024fair,
  title = {The {{FAIR Data Point Populator}}: Collaborative {{FAIRification}} and Population of {{FAIR Data Points}}},
  shorttitle = {The {{FAIR Data Point Populator}}},
  author = {Wijnbergen, Daphne and Kaliyaperumal, Rajaram and Burger, Kees and Santos, Luiz Olavo Bonino da Silva and Mons, Barend and Roos, Marco and Mina, Eleni},
  date = {2024-09-10},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.09.06.611505},
  doi = {10.1101/2024.09.06.611505},
  url = {https://www.biorxiv.org/content/10.1101/2024.09.06.611505v1},
  urldate = {2025-06-11},
  abstract = {Background Use of the FAIR principles (Findable, Accessible, Interoperable and Reusable) allows the rapidly growing number of biomedical datasets to be optimally (re)used. An important aspect of the FAIR principles is metadata. The FAIR Data Point specifications and reference implementation have been designed as an example on how to publish metadata according to the FAIR principles. Various tools to create metadata have been created, but many of these have limitations, such as interfaces that are not intuitive, metadata that does not adhere to a common metadata schema, limited scalability, and inefficient collaboration. We aim to address these limitations in the FAIR Data Point Populator. Results The FAIR Data Point Populator consists of a GitHub workflow together with Excel templates that have tooltips, validation and documentation. The Excel templates are targeted towards non-technical users, and can be used collaboratively in online spreadsheet software. A more technical user then uses the GitHub workflow to read multiple entries in the Excel sheets, and transform it into machine readable metadata. This metadata is then automatically uploaded to a connected FAIR Data Point. We applied the FAIR Data Point Populator on the metadata of two datasets, and a patient registry. We were then able to run a query on the FAIR Data Point Index, in order to retrieve one of the datasets. Conclusion The FAIR Data Point Populator addresses several limitations of other tools. It makes creating metadata easier, ensures adherence to a common metadata schema, allows bulk creation of metadata entries and increases collaboration. As a result of this, the barrier of entry for FAIRification is lower, which enables the creation of FAIR data by more people.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/dkapitan/Zotero/storage/TJ7SRJ62/Wijnbergen et al. - 2024 - The FAIR Data Point Populator collaborative FAIRification and population of FAIR Data Points.pdf}
}

@article{yang2024federated,
  title = {Federated {{Continual Learning}} via {{Knowledge Fusion}}: {{A Survey}}},
  shorttitle = {Federated {{Continual Learning}} via {{Knowledge Fusion}}},
  author = {Yang, Xin and Yu, Hao and Gao, Xin and Wang, Hao and Zhang, Junbo and Li, Tianrui},
  date = {2024-08},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {36},
  number = {8},
  pages = {3832--3850},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2024.3363240},
  url = {https://ieeexplore.ieee.org/abstract/document/10423871},
  urldate = {2025-06-30},
  abstract = {Data privacy and silos are nontrivial and greatly challenging in many real-world applications. Federated learning is a decentralized approach to training models across multiple local clients without the exchange of raw data from client devices to global servers. However, existing works focus on a static data environment and ignore continual learning from streaming data with incremental tasks. Federated Continual Learning (FCL) is an emerging paradigm to address model learning in both federated and continual learning environments. The key objective of FCL is to fuse heterogeneous knowledge from different clients and retain knowledge of previous tasks while learning on new ones. In this work, we delineate federated learning and continual learning first and then discuss their integration, i.e., FCL, and particular FCL via knowledge fusion. In summary, our motivations are four-fold: we (1) raise a fundamental problem called “spatial-temporal catastrophic forgetting” and evaluate its impact on the performance using a well-known method called federated averaging (FedAvg), (2) integrate most of the existing FCL methods into two generic frameworks, namely synchronous FCL and asynchronous FCL, (3) categorize a large number of methods according to the mechanism involved in knowledge fusion, and finally (4) showcase an outlook on the future work of FCL.},
  keywords = {Biological system modeling,Continual learning,Data models,federated continual learning,federated learning,Federated learning,knowledge fusion,Privacy,Servers,spatial-temporal catastrophic forgetting,Task analysis,Training},
  file = {/Users/dkapitan/Zotero/storage/EIZJNTXX/Yang et al. - 2024 - Federated Continual Learning via Knowledge Fusion A Survey.pdf}
}

@article{yuan2024decentralized,
  title = {Decentralized {{Federated Learning}}: {{A Survey}} and {{Perspective}}},
  shorttitle = {Decentralized {{Federated Learning}}},
  author = {Yuan, Liangqi and Wang, Ziran and Sun, Lichao and Yu, Philip S. and Brinton, Christopher G.},
  date = {2024-11},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {11},
  number = {21},
  pages = {34617--34638},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2024.3407584},
  url = {https://ieeexplore.ieee.org/abstract/document/10542323},
  urldate = {2025-06-30},
  abstract = {Federated learning (FL) has been gaining attention for its ability to share knowledge while maintaining user data, protecting privacy, increasing learning efficiency, and reducing communication overhead. Decentralized FL (DFL) is a decentralized network architecture that eliminates the need for a central server in contrast to centralized FL (CFL). DFL enables direct communication between clients, resulting in significant savings in communication resources. In this article, a comprehensive survey and profound perspective are provided for DFL. First, a review of the methodology, challenges, and variants of CFL is conducted, laying the background of DFL. Then, a systematic and detailed perspective on DFL is introduced, including iteration order, communication protocols, network topologies, paradigm proposals, and temporal variability. Next, based on the definition of DFL, several extended variants and categorizations are proposed with state-of-the-art (SOTA) technologies. Lastly, in addition to summarizing the current challenges in the DFL, some possible solutions and future research directions are also discussed.},
  keywords = {Adaptation models,Data models,Decentralized learning,federated learning (FL),Internet of Things,Internet of Things (IoT),network,privacy preservation,Protocols,Servers,Surveys,Taxonomy},
  file = {/Users/dkapitan/Zotero/storage/C6J59EIZ/Yuan et al. - 2024 - Decentralized Federated Learning A Survey and Perspective.pdf}
}

@article{zeist2024ai,
  title = {AI Monitor Ziekenhuizen 2024},
  author = {family=Zeist, given=JE, given-i=JE},
  date = {2024},
  langid = {dutch},
  file = {/Users/dkapitan/Zotero/storage/SR7IXN9A/Zeist - 2024 - AI Monitor Ziekenhuizen 2024.pdf}
}

@online{zhang2023secure,
  title = {Secure and {{Private Healthcare Analytics}}: {{A Feasibility Study}} of {{Federated Deep Learning}} with {{Personal Health Train}}},
  shorttitle = {Secure and {{Private Healthcare Analytics}}},
  author = {Zhang, Chong and Choudhury, Ananya and Volmer, Leroy and Soest, Johan and Bermejo, Inigo and Dekker, Andre and Gomes, Aiara Lobo and Wee, Leonard},
  date = {2023-07-19},
  eprinttype = {Research Square},
  issn = {2693-5015},
  doi = {10.21203/rs.3.rs-3158418/v1},
  url = {https://www.researchsquare.com/article/rs-3158418/v1},
  urldate = {2024-10-24},
  abstract = {Objective In this article, we aim to present a new open-source Federated Learning infrastructure by conducting several proof-of-concept experiments. We seek to prove the reliability of the infrastructure to develop global models without sharing private patient data.Materials and Methods We applied the Personal Health Train (PHT) principles using the Vantage6 software to train a neural network to classify head and neck cancer patients\&amp;rsquo; distant metastasis using federated learning algorithms in a privacy preserving manner. Head and neck cancer patient data from four cohorts were assigned to two data stations. During each training iteration, model weights were averaged and sent back to central node.Results We compared the area under the receiver operating characteristic curves (AUCs) and model weights between the centralized and federated learning scenarios. The results showed that our federated infrastructure was able to achieve similar predicting power as in the centralized case. Different federated learning model weights aggregation methods were tested. The experiment results showed that federated learning models reached best performance when we aggregate model weights per epoch.Discussion and Conclusion PHT and FAIR data principles can efficiently calculate quality indicators in a privacy-preserving federated approach and the work can be scaled up both nationally and internationally. Despite this, application of the methodology was largely hampered by ELSI issues. However, the lessons learned from this study can provide other hospitals and researchers to adapt to the process easily and take effective measures in building quality of care infrastructures.},
  pubstate = {prepublished},
  file = {/Users/dkapitan/Zotero/storage/QSIP8H5B/Zhang et al. - 2023 - Secure and Private Healthcare Analytics A Feasibility Study of Federated Deep Learning with Persona.pdf}
}

@article{zhang2024crossstandard,
  title = {Cross-{{Standard Health Data Harmonization}} Using {{Semantics}} of {{Data Elements}}},
  author = {Zhang, Shuxin and Cornet, Ronald and Benis, Nirupama},
  date = {2024-12-19},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {11},
  number = {1},
  pages = {1407},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/s41597-024-04168-1},
  url = {https://www.nature.com/articles/s41597-024-04168-1},
  urldate = {2025-03-07},
  abstract = {Faced with heterogeneity of healthcare data, we propose a novel approach for harmonizing data elements (i.e., attributes) across health data standards. This approach focuses on the implicit concept that is represented by a data element. The process includes the following steps: identifying concepts, clustering similar concepts and constructing mappings between the clusters using the Simple Standard for Sharing Ontological Mappings (SSSOM) and Resource Description Framework (RDF), and enabling the creation of reusable mappings. As proof-of-concept, we applied the approach to five common health data standards - HL7 FHIR, OMOP, CDISC, Phenopackets, and openEHR, across four domains, such as demographics and diagnoses, and nine topics within those domains, such as gender and vital status. These domains and topics are selected to represent the broader range of topics in the health field. For each topic, data elements were found in the health data standards after a thorough search, resulting in the analysis of 64 data elements, identification of their underlying concepts, and development of mappings. Three use cases were implemented to demonstrate the role of data element concepts in data harmonization and data querying at varying levels of granularity. The approach helps overcome the limitations of context-dependent mappings and provides valuable insight for mapping practice within the health domain.},
  langid = {english},
  keywords = {Data integration,Databases,Standards},
  file = {/Users/dkapitan/Zotero/storage/VWK3SH33/Zhang et al. - 2024 - Cross-Standard Health Data Harmonization using Semantics of Data Elements.pdf}
}

@article{zhao2025federation,
  title = {The {{Federation Strikes Back}}: {{A Survey}} of {{Federated Learning Privacy Attacks}}, {{Defenses}}, {{Applications}}, and {{Policy Landscape}}},
  shorttitle = {The {{Federation Strikes Back}}},
  author = {Zhao, Joshua and Bagchi, Saurabh and Avestimehr, Salman and Chan, Kevin and Chaterji, Somali and Dimitriadis, Dimitris and Li, Jiacheng and Li, Ninghui and Nourian, Arash and Roth, Holger},
  date = {2025-04-03},
  journaltitle = {ACM Comput. Surv.},
  volume = {57},
  number = {9},
  pages = {230:1--230:37},
  issn = {0360-0300},
  doi = {10.1145/3724113},
  url = {https://dl.acm.org/doi/10.1145/3724113},
  urldate = {2025-06-30},
  abstract = {Deep learning has shown incredible potential across a wide array of tasks, and accompanied by this growth has been an insatiable appetite for data. However, a large amount of data needed for enabling deep learning is stored on personal devices, and recent concerns on privacy have further highlighted challenges for accessing such data. As a result, federated learning (FL) has emerged as an important privacy-preserving technology that enables collaborative training of machine learning models without the need to send the raw, potentially sensitive, data to a central server. However, the fundamental premise that sending model updates to a server is privacy-preserving only holds if the updates cannot be “reverse engineered” to infer information about the private training data. It has been shown under a wide variety of settings that this privacy premise does not hold. In this article we provide a comprehensive literature review of the different privacy attacks and defense methods in FL. We identify the current limitations of these attacks and highlight the settings in which the privacy of an FL client can be broken. We further dissect some of the successful industry applications of FL and draw lessons for future successful adoption. We survey the emerging landscape of privacy regulation for FL and conclude with future directions for taking FL toward the cherished goal of generating accurate models while preserving the privacy of the data from its participants.},
  file = {/Users/dkapitan/Zotero/storage/TIQ2CRMP/Zhao et al. - 2025 - The Federation Strikes Back A Survey of Federated Learning Privacy Attacks, Defenses, Applications,.pdf}
}
